[
    {
        "title": "LLM-as-a-Judge: Toward World Models for Slate Recommendation Systems",
        "summary": "Modeling user preferences across domains remains a key challenge in slate\nrecommendation (i.e. recommending an ordered sequence of items) research. We\ninvestigate how Large Language Models (LLM) can effectively act as world models\nof user preferences through pairwise reasoning over slates. We conduct an\nempirical study involving several LLMs on three tasks spanning different\ndatasets. Our results reveal relationships between task performance and\nproperties of the preference function captured by LLMs, hinting towards areas\nfor improvement and highlighting the potential of LLMs as world models in\nrecommender systems.",
        "entry_id": "http://arxiv.org/abs/2511.04541v1",
        "pub_date": "2025-11-06",
        "translated_summary": "跨领域建模用户偏好始终是板面推荐（即推荐有序项目序列）研究中的核心挑战。我们探索了大型语言模型如何通过板面对比推理，有效构建用户偏好的世界模型。我们在涵盖三个不同数据集的实验任务中，对多种大语言模型进行了实证研究。结果表明，任务表现与大语言模型所捕捉的偏好函数特性存在关联性，这为改进方向提供了线索，同时彰显了大语言模型作为推荐系统世界模型的潜力。"
    },
    {
        "title": "RUST-BENCH: Benchmarking LLM Reasoning on Unstructured Text within Structured Tables",
        "summary": "Existing tabular reasoning benchmarks mostly test models on small, uniform\ntables, underrepresenting the complexity of real-world data and giving an\nincomplete view of Large Language Models' (LLMs) reasoning abilities. Real\ntables are long, heterogeneous, and domain-specific, mixing structured fields\nwith free text and requiring multi-hop reasoning across thousands of tokens. To\naddress this gap, we introduce RUST-BENCH, a benchmark of 7966 questions from\n2031 real-world tables spanning two domains: i) RB-Science (NSF grant records)\nand ii) RB-Sports (NBA statistics). Unlike prior work, RUST-BENCH evaluates\nLLMs jointly across scale, heterogeneity, domain specificity, and reasoning\ncomplexity. Experiments with open-source and proprietary models show that LLMs\nstruggle with heterogeneous schemas and complex multi-hop inference, revealing\npersistent weaknesses in current architectures and prompting strategies.\nRUST-BENCH establishes a challenging new testbed for advancing tabular\nreasoning research.",
        "entry_id": "http://arxiv.org/abs/2511.04491v1",
        "pub_date": "2025-11-06",
        "translated_summary": "现有的表格推理基准大多基于小型统一表格测试模型，未能充分体现现实数据的复杂性，导致对大型语言模型推理能力的评估存在局限。真实场景中的表格往往具有长篇幅、异构性和领域专有特征，既包含结构化字段又混合自由文本，需要模型在数千个标记范围内进行多跳推理。为弥补这一空白，我们推出RUST-BENCH基准数据集，涵盖2031个真实世界表格中的7966个问题，涉及两大领域：i) RB-Science（美国国家科学基金会资助记录）和ii) RB-Sports（NBA统计数据）。与先前研究不同，RUST-BENCH从数据规模、异构性、领域专有性和推理复杂性四个维度对LLMs进行联合评估。开源与商业模型的实验表明，当前LLMs在处理异构表格结构和复杂多跳推理时存在明显困难，暴露出架构设计和提示策略的持续缺陷。RUST-BENCH为推进表格推理研究建立了一个具有挑战性的新测试平台。"
    },
    {
        "title": "Ground-Truth Subgraphs for Better Training and Evaluation of Knowledge Graph Augmented LLMs",
        "summary": "Retrieval of information from graph-structured knowledge bases represents a\npromising direction for improving the factuality of LLMs. While various\nsolutions have been proposed, a comparison of methods is difficult due to the\nlack of challenging QA datasets with ground-truth targets for graph retrieval.\nWe present SynthKGQA, a framework for generating high-quality synthetic\nKnowledge Graph Question Answering datasets from any Knowledge Graph, providing\nthe full set of ground-truth facts in the KG to reason over each question. We\nshow how, in addition to enabling more informative benchmarking of KG\nretrievers, the data produced with SynthKGQA also allows us to train better\nmodels. We apply SynthKGQA to Wikidata to generate GTSQA, a new dataset\ndesigned to test zero-shot generalization abilities of KG retrievers with\nrespect to unseen graph structures and relation types, and benchmark popular\nsolutions for KG-augmented LLMs on it.",
        "entry_id": "http://arxiv.org/abs/2511.04473v1",
        "pub_date": "2025-11-06",
        "translated_summary": "从图结构知识库中检索信息是提升大语言模型事实准确性的重要方向。虽然已有多种解决方案被提出，但由于缺乏具有图检索真值标注的挑战性问答数据集，不同方法间的比较仍存在困难。我们推出了SynthKGQA框架，该框架能够基于任意知识图谱生成高质量的知识图谱问答合成数据集，并为每个问题提供知识图谱中完整的真值事实链以供推理验证。研究表明，通过SynthKGQA生成的数据不仅能实现更具信息量的知识图谱检索器基准测试，还能训练出更优质的模型。我们将该框架应用于维基数据知识图谱，构建了GTSQA数据集——该数据集专门用于测试知识图谱检索器在面对未见图结构和关系类型时的零样本泛化能力，并在此数据集上对当前主流的知识图谱增强型大语言模型解决方案进行了基准评估。"
    },
    {
        "title": "On the Brittleness of CLIP Text Encoders",
        "summary": "Multimodal co-embedding models, especially CLIP, have advanced the state of\nthe art in zero-shot classification and multimedia information retrieval in\nrecent years by aligning images and text in a shared representation space.\nHowever, such modals trained on a contrastive alignment can lack stability\ntowards small input perturbations. Especially when dealing with manually\nexpressed queries, minor variations in the query can cause large differences in\nthe ranking of the best-matching results. In this paper, we present a\nsystematic analysis of the effect of multiple classes of non-semantic query\nperturbations in an multimedia information retrieval scenario. We evaluate a\ndiverse set of lexical, syntactic, and semantic perturbations across multiple\nCLIP variants using the TRECVID Ad-Hoc Video Search queries and the V3C1 video\ncollection. Across models, we find that syntactic and semantic perturbations\ndrive the largest instabilities, while brittleness is concentrated in trivial\nsurface edits such as punctuation and case. Our results highlight robustness as\na critical dimension for evaluating vision-language models beyond benchmark\naccuracy.",
        "entry_id": "http://arxiv.org/abs/2511.04247v1",
        "pub_date": "2025-11-06",
        "translated_summary": "近年来，多模态协同嵌入模型（特别是CLIP）通过将图像与文本在共享表征空间中对齐，推动了零样本分类和多媒体信息检索领域的发展。然而，基于对比对齐训练的此类模型对输入微小扰动缺乏稳定性。尤其在处理人工表述的查询时，查询语句的细微变化可能导致最佳匹配结果的排序产生显著差异。本文系统分析了多媒体信息检索场景中多类非语义查询扰动的影响，基于TRECVID特设视频搜索查询和V3C1视频数据集，对多种CLIP变体进行了词汇、句法和语义层面的扰动测试。研究发现：所有模型均对句法和语义扰动最为敏感，而鲁棒性薄弱环节主要集中在标点符号、大小写等表层文本编辑。这一结果表明，在基准准确率之外，鲁棒性应成为评估视觉语言模型的关键维度。"
    },
    {
        "title": "Denoised Recommendation Model with Collaborative Signal Decoupling",
        "summary": "Although the collaborative filtering (CF) algorithm has achieved remarkable\nperformance in recommendation systems, it suffers from suboptimal\nrecommendation performance due to noise in the user-item interaction matrix.\nNumerous noise-removal studies have improved recommendation models, but most\nexisting approaches conduct denoising on a single graph. This may cause\nattenuation of collaborative signals: removing edges between two nodes can\ninterrupt paths between other nodes, weakening path-dependent collaborative\ninformation. To address these limitations, this study proposes a novel\nGNN-based CF model called DRCSD for denoising unstable interactions. DRCSD\nincludes two core modules: a collaborative signal decoupling module (decomposes\nsignals into distinct orders by structural characteristics) and an order-wise\ndenoising module (performs targeted denoising on each order). Additionally, the\ninformation aggregation mechanism of traditional GNN-based CF models is\nmodified to avoid cross-order signal interference until the final pooling\noperation. Extensive experiments on three public real-world datasets show that\nDRCSD has superior robustness against unstable interactions and achieves\nstatistically significant performance improvements in recommendation accuracy\nmetrics compared to state-of-the-art baseline models.",
        "entry_id": "http://arxiv.org/abs/2511.04237v1",
        "pub_date": "2025-11-06",
        "translated_summary": "尽管协同过滤算法在推荐系统中取得了显著成效，但由于用户-物品交互矩阵中的噪声干扰，其推荐性能仍存在优化空间。现有大量去噪研究通过提升推荐模型性能，但多数方法仅在单一图结构上进行去噪操作，这可能导致协同信号衰减：移除两个节点间的边会中断其他节点间的路径，从而削弱依赖路径的协同信息。针对这些局限性，本研究提出名为DRCSD的新型图神经网络协同过滤模型，专门用于处理不稳定交互的噪声问题。该模型包含两个核心模块：协同信号解耦模块（根据结构特征将信号分解为不同阶数）和分阶去噪模块（对各阶信号进行针对性去噪）。此外，本研究改进了传统基于图神经网络的协同过滤模型的信息聚合机制，避免跨阶信号干扰直至最终池化操作。在三个真实公开数据集上的大量实验表明，DRCSD对不稳定交互具有卓越的鲁棒性，且在推荐准确性指标上相比现有最优基线模型实现了统计学意义上的显著提升。"
    },
    {
        "title": "Coordination-Free Lane Partitioning for Convergent ANN Search",
        "summary": "Production vector search systems often fan out each query across parallel\nlanes (threads, replicas, or shards) to meet latency service-level objectives\n(SLOs). In practice, these lanes rediscover the same candidates, so extra\ncompute does not increase coverage. We present a coordination-free lane\npartitioner that turns duplication into complementary work at the same cost and\ndeadline. For each query we (1) build a deterministic candidate pool sized to\nthe total top-k budget, (2) apply a per-query pseudorandom permutation, and (3)\nassign each lane a disjoint slice of positions. Lanes then return different\nresults by construction, with no runtime coordination.\n  At equal cost with four lanes (total candidate budget 64), on SIFT1M (1M SIFT\nfeature vectors) with Hierarchical Navigable Small World graphs (HNSW)\nrecall@10 rises from 0.249 to 0.999 while lane overlap falls from nearly 100%\nto 0%. On MS MARCO (8.8M passages) with HNSW, hit@10 improves from 0.200 to\n0.601 and Mean Reciprocal Rank at 10 (MRR@10) from 0.133 to 0.330. For inverted\nfile (IVF) indexes we see smaller but consistent gains (for example, +11% on MS\nMARCO) by de-duplicating list routing. A microbenchmark shows planner overhead\nof ~37 microseconds per query (mean at the main setting) with linear growth in\nthe number of merged candidates.\n  These results yield a simple operational guideline: size the per-query pool\nto the total budget, deterministically partition positions across lanes, and\nturn redundant fan-out into complementary coverage without changing budget or\ndeadline.",
        "entry_id": "http://arxiv.org/abs/2511.04221v1",
        "pub_date": "2025-11-06",
        "translated_summary": "生产环境中的向量检索系统通常会将每个查询并行分发至多个执行通道（线程、副本或分片）以满足延迟服务等级目标。实践中这些通道往往会重复发现相同候选结果，导致额外计算资源无法提升结果覆盖度。我们提出一种无协调机制的通道分区策略，在保持相同成本与截止时间的前提下，将重复计算转化为互补性工作。针对每个查询，我们：（1）构建确定性的候选池，其容量与总top-k预算相匹配；（2）施加每查询专属的伪随机排列；（3）为每个通道分配互不重叠的位置区间。通过这种构造方式，各通道无需运行时协调即可返回差异化结果。\n\n在四通道配置（总候选预算64）的同等成本下，基于分层导航小世界图的SIFT1M数据集（100万SIFT特征向量）实验中，召回率@10从0.249提升至0.999，同时通道重叠率从近100%降至0%。在MS MARCO数据集（880万文本段）的HNSW实验中，命中率@10从0.200提升至0.601，平均倒数排名@10从0.133提升至0.330。对于倒排文件索引，通过列表路由去重实现了较小但稳定的增益（如在MS MARCO上提升11%）。微基准测试显示，规划器每查询开销约37微秒（主要配置下的均值），且随合并候选数线性增长。\n\n这些成果衍生出简明运维指南：将每查询候选池容量设置为总预算规模，通过确定性位置分区分配至各通道，即可在不改变预算与截止时间的前提下，将冗余分发转化为互补性覆盖。"
    },
    {
        "title": "Transforming Mentorship: An AI Powered Chatbot Approach to University Guidance",
        "summary": "University students face immense challenges during their undergraduate lives,\noften being deprived of personalized on-demand guidance that mentors fail to\nprovide at scale. Digital tools exist, but there is a serious lack of\ncustomized coaching for newcomers. This paper presents an AI-powered chatbot\nthat will serve as a mentor for the students of BRAC University. The main\ncomponent is a data ingestion pipeline that efficiently processes and updates\ninformation from diverse sources, such as CSV files and university webpages.\nThe chatbot retrieves information through a hybrid approach, combining BM25\nlexical ranking with ChromaDB semantic retrieval, and uses a Large Language\nModel, LLaMA-3.3-70B, to generate conversational responses. The generated text\nwas found to be semantically highly relevant, with a BERTScore of 0.831 and a\nMETEOR score of 0.809. The data pipeline was also very efficient, taking 106.82\nseconds for updates, compared to 368.62 seconds for new data. This chatbot will\nbe able to help students by responding to their queries, helping them to get a\nbetter understanding of university life, and assisting them to plan better\nroutines for their semester in the open-credit university.",
        "entry_id": "http://arxiv.org/abs/2511.04172v1",
        "pub_date": "2025-11-06",
        "translated_summary": "大学生在本科阶段面临诸多挑战，往往难以获得导师大规模提供的个性化即时指导。虽然现有数字化工具，但针对新生的定制化辅导严重匮乏。本文提出一款人工智能聊天机器人，将为BRAC大学学生提供导师式服务。该系统的核心组件是数据摄取管道，能高效处理并实时更新来自CSV文件和大学网页等多源信息。通过结合BM25词汇排序与ChromaDB语义检索的混合检索机制，并基于LLaMA-3.3-70B大语言模型生成对话响应，该聊天机器人展现出优异的语义相关性——BERTScore达0.831，METEOR评分达0.809。数据管道处理效率显著，更新现有数据仅需106.82秒，而处理新数据也仅需368.62秒。这款智能助手将有效解答学生疑问，帮助其深入理解大学生活，并在开放学分制下规划更合理的学期安排。"
    },
    {
        "title": "E-CARE: An Efficient LLM-based Commonsense-Augmented Framework for E-Commerce",
        "summary": "Finding relevant products given a user query plays a pivotal role in an\ne-commerce platform, as it can spark shopping behaviors and result in revenue\ngains. The challenge lies in accurately predicting the correlation between\nqueries and products. Recently, mining the cross-features between queries and\nproducts based on the commonsense reasoning capacity of Large Language Models\n(LLMs) has shown promising performance. However, such methods suffer from high\ncosts due to intensive real-time LLM inference during serving, as well as human\nannotations and potential Supervised Fine Tuning (SFT). To boost efficiency\nwhile leveraging the commonsense reasoning capacity of LLMs for various\ne-commerce tasks, we propose the Efficient Commonsense-Augmented Recommendation\nEnhancer (E-CARE). During inference, models augmented with E-CARE can access\ncommonsense reasoning with only a single LLM forward pass per query by\nutilizing a commonsense reasoning factor graph that encodes most of the\nreasoning schema from powerful LLMs. The experiments on 2 downstream tasks show\nan improvement of up to 12.1% on precision@5.",
        "entry_id": "http://arxiv.org/abs/2511.04087v1",
        "pub_date": "2025-11-06",
        "translated_summary": "在电子商务平台中，根据用户查询推荐相关商品具有关键作用，它能有效激发购物行为并带来收入增长。核心挑战在于如何准确预测查询与商品之间的关联性。近期研究显示，基于大语言模型的常识推理能力挖掘查询与商品间的交叉特征已展现出显著效果。然而，这类方法因需在服务期间进行密集的实时大语言模型推理，同时依赖人工标注及潜在的监督微调，导致成本高昂。为在提升效率的同时充分利用大语言模型的常识推理能力应对各类电商任务，我们提出高效常识增强推荐框架E-CARE。该框架通过构建常识推理因子图，将大部分来自强大语言模型的推理模式进行编码，使得增强后的模型在推理时仅需对每个查询执行单次大语言模型前向传播即可获得常识推理能力。在两项下游任务上的实验表明，该框架使精确率@5指标最高提升12.1%。"
    },
    {
        "title": "Publication Trend in DESIDOC Journal of Library and Information Technology during 2013-2017: A Scientometric Approach",
        "summary": "DESIDOC Journal of Library & Information Technology (DJLIT) formerly known as\nDESIDOC Bulletin of Information Technology is a peer-reviewed, open access,\nbimonthly journal. This paper presents a Scientometric analysis of the DESIDOC\nJournal. The paper analyses the pattern of growth of the research output\npublished in the journal, pattern of authorship, author productivity, and,\nsubjects covered to the papers over the period (2013-2017). It is found that\n227 papers were published during the period of study (2001-2012). The maximum\nnumbers of articles were collaborative in nature. The subject concentration of\nthe journal noted is Scientometrics. The maximum numbers of articles (65%) have\nranged their thought contents between 6 and 10 pages. The study applied\nstandard formula and statistical tools to bring out the factual result.",
        "entry_id": "http://arxiv.org/abs/2511.04082v1",
        "pub_date": "2025-11-06",
        "translated_summary": "《DESIDOC图书馆与信息科技杂志》（DJLIT）前身为《DESIDOC信息科技通报》，是一本经过同行评审的开放获取双月刊。本文对该期刊进行了科学计量学分析，重点研究了2013-2017年间刊载研究成果的产出增长模式、作者合作模式、作者生产力及论文主题分布。研究发现，在观测周期（2001-2012年）内共发表227篇论文，其中大多数论文为合作研究成果。该期刊的核心主题领域为科学计量学，65%的论文篇幅集中在6-10页范围内。本研究通过标准公式与统计工具得出了客观结论。"
    },
    {
        "title": "Caption Injection for Optimization in Generative Search Engine",
        "summary": "Generative Search Engines (GSEs) leverage Retrieval-Augmented Generation\n(RAG) techniques and Large Language Models (LLMs) to integrate multi-source\ninformation and provide users with accurate and comprehensive responses. Unlike\ntraditional search engines that present results in ranked lists, GSEs shift\nusers' attention from sequential browsing to content-driven subjective\nperception, driving a paradigm shift in information retrieval. In this context,\nenhancing the subjective visibility of content through Generative Search Engine\nOptimization (G-SEO) methods has emerged as a new research focus. With the\nrapid advancement of Multimodal Retrieval-Augmented Generation (MRAG)\ntechniques, GSEs can now efficiently integrate text, images, audio, and video,\nproducing richer responses that better satisfy complex information needs.\nExisting G-SEO methods, however, remain limited to text-based optimization and\nfail to fully exploit multimodal data. To address this gap, we propose Caption\nInjection, the first multimodal G-SEO approach, which extracts captions from\nimages and injects them into textual content, integrating visual semantics to\nenhance the subjective visibility of content in generative search scenarios. We\nsystematically evaluate Caption Injection on MRAMG, a benchmark for MRAG, under\nboth unimodal and multimodal settings. Experimental results show that Caption\nInjection significantly outperforms text-only G-SEO baselines under the G-Eval\nmetric, demonstrating the necessity and effectiveness of multimodal integration\nin G-SEO to improve user-perceived content visibility.",
        "entry_id": "http://arxiv.org/abs/2511.04080v1",
        "pub_date": "2025-11-06",
        "translated_summary": "生成式搜索引擎（GSEs）通过检索增强生成技术与大语言模型整合多源信息，为用户提供精准全面的回答。与传统搜索引擎呈现排序列表的方式不同，GSEs将用户注意力从顺序浏览转向内容驱动的主观感知，推动信息检索范式变革。在此背景下，如何通过生成式搜索引擎优化方法提升内容的主观可见性成为新兴研究热点。随着多模态检索增强生成技术的快速发展，GSEs已能高效整合文本、图像、音频和视频，生成更丰富的响应以满足复杂信息需求。然而现有G-SEO方法仍局限于文本优化，未能充分利用多模态数据。为此，我们提出首项多模态G-SEO方法——字幕注入，通过提取图像描述文本并将其注入文本内容，融合视觉语义以增强生成式搜索场景下内容的主观可见性。我们在多模态检索增强生成基准MRAMG上系统评估了该方法在单模态与多模态设置下的表现。实验结果表明，在G-Eval指标下，字幕注入方法显著优于纯文本G-SEO基线，验证了多模态整合在提升用户感知内容可见性方面的必要性与有效性。"
    },
    {
        "title": "Two Decades of Research at the University of Lagos (2004-2023): A Scientometric Analysis of Productivity, Collaboration, and Impact",
        "summary": "This paper presents a scientometric analysis of research output from the\nUniversity of Lagos, focusing on the two decades spanning 2004 to 2023. Using\nbibliometric data retrieved from the Web of Science, we examine trends in\npublication volume, collaboration patterns, citation impact, and the most\nprolific authors, departments, and research domains at the university. The\nstudy reveals a consistent increase in research productivity, with the highest\npublication output recorded in 2023. Health Sciences, Engineering, and Social\nSciences are identified as dominant fields, reflecting the university's\ninterdisciplinary research strengths. Collaborative efforts, both locally and\ninternationally, show a positive correlation with higher citation impact, with\nthe United States and the United Kingdom being the leading international\ncollaborators. Notably, open-access publications account for a significant\nportion of the university's research output, enhancing visibility and citation\nrates. The findings offer valuable insights into the university's research\nperformance over the past two decades, providing a foundation for strategic\nplanning and policy formulation to foster research excellence and global\nimpact.",
        "entry_id": "http://arxiv.org/abs/2511.04075v1",
        "pub_date": "2025-11-06",
        "translated_summary": "本文对拉各斯大学2004至2023二十年间的研究产出展开科学计量分析。基于Web of Science检索的文献计量数据，我们系统考察了该校的论文发表趋势、合作模式、引用影响力以及核心作者、院系和研究领域。研究表明：该校科研生产力持续增长，2023年达到发文峰值；健康科学、工程学与社会科学构成三大优势学科，彰显跨学科研究实力；本地与国际合作均与高引用影响力呈正相关，其中美国与英国为主要国际合作对象。值得关注的是，开放获取论文在全校研究成果中占比显著，有效提升了学术可见度与引用率。这些发现为评估该校近二十年的科研绩效提供了重要依据，可为优化学术发展战略与政策制定提供参考，从而进一步提升研究质量与全球影响力。"
    },
    {
        "title": "Learning Filter-Aware Distance Metrics for Nearest Neighbor Search with Multiple Filters",
        "summary": "Filtered Approximate Nearest Neighbor (ANN) search retrieves the closest\nvectors for a query vector from a dataset. It enforces that a specified set of\ndiscrete labels $S$ for the query must be included in the labels of each\nretrieved vector. Existing graph-based methods typically incorporate filter\nawareness by assigning fixed penalties or prioritizing nodes based on filter\nsatisfaction. However, since these methods use fixed, data in- dependent\npenalties, they often fail to generalize across datasets with diverse label and\nvector distributions. In this work, we propose a principled alternative that\nlearns the optimal trade-off between vector distance and filter match directly\nfrom the data, rather than relying on fixed penalties. We formulate this as a\nconstrained linear optimization problem, deriving weights that better reflect\nthe underlying filter distribution and more effectively address the filtered\nANN search problem. These learned weights guide both the search process and\nindex construction, leading to graph structures that more effectively capture\nthe underlying filter distribution and filter semantics. Our experiments\ndemonstrate that adapting the distance function to the data significantly im-\nproves accuracy by 5-10% over fixed-penalty methods, providing a more flexible\nand generalizable framework for the filtered ANN search problem.",
        "entry_id": "http://arxiv.org/abs/2511.04073v1",
        "pub_date": "2025-11-06",
        "translated_summary": "过滤式近似最近邻搜索能够从数据集中为查询向量检索最接近的向量，其核心要求是查询向量指定的离散标签集$S$必须包含于每个被检索向量的标签集合中。现有基于图的方法通常通过固定惩罚值或基于过滤条件满足程度的节点优先级机制来实现过滤感知。然而，由于这些方法采用固定且与数据无关的惩罚机制，往往难以在具有不同标签和向量分布的数据集上保持泛化能力。本研究提出一种理论严谨的替代方案：直接从数据中学习向量距离与过滤匹配之间的最优权衡，而非依赖固定惩罚机制。我们将其构建为约束线性优化问题，推导出的权重能更好反映底层过滤分布，从而更有效解决过滤式近似最近邻搜索问题。这些学习得到的权重同时指导搜索过程和索引构建，形成的图结构能更有效地捕捉底层过滤分布与过滤语义。实验表明，相较于固定惩罚方法，这种根据数据自适应调整距离函数的方式将准确率显著提升5-10%，为过滤式近似最近邻搜索问题提供了更灵活且可泛化的解决方案。"
    },
    {
        "title": "KnowThyself: An Agentic Assistant for LLM Interpretability",
        "summary": "We develop KnowThyself, an agentic assistant that advances large language\nmodel (LLM) interpretability. Existing tools provide useful insights but remain\nfragmented and code-intensive. KnowThyself consolidates these capabilities into\na chat-based interface, where users can upload models, pose natural language\nquestions, and obtain interactive visualizations with guided explanations. At\nits core, an orchestrator LLM first reformulates user queries, an agent router\nfurther directs them to specialized modules, and the outputs are finally\ncontextualized into coherent explanations. This design lowers technical\nbarriers and provides an extensible platform for LLM inspection. By embedding\nthe whole process into a conversational workflow, KnowThyself offers a robust\nfoundation for accessible LLM interpretability.",
        "entry_id": "http://arxiv.org/abs/2511.03878v1",
        "pub_date": "2025-11-05",
        "translated_summary": "我们开发了KnowThyself智能助手，这是一个推动大语言模型可解释性研究的智能辅助系统。现有工具虽能提供有用见解，但存在功能碎片化和代码依赖性强的问题。KnowThyself通过基于聊天的交互界面整合这些能力，用户可上传模型、用自然语言提问，并获得带引导说明的交互式可视化结果。其核心架构包含三层处理：协调器大模型首先重构用户查询，智能路由代理进一步将问题分发至专业模块，最终输出结果会被整合成连贯的阐释。这种设计既降低了技术门槛，又构建了可扩展的大语言模型检测平台。通过将全流程嵌入对话式工作流，KnowThyself为普及大语言模型可解释性提供了坚实基础。"
    },
    {
        "title": "CLAX: Fast and Flexible Neural Click Models in JAX",
        "summary": "CLAX is a JAX-based library that implements classic click models using modern\ngradient-based optimization. While neural click models have emerged over the\npast decade, complex click models based on probabilistic graphical models\n(PGMs) have not systematically adopted gradient-based optimization, preventing\npractitioners from leveraging modern deep learning frameworks while preserving\nthe interpretability of classic models. CLAX addresses this gap by replacing\nEM-based optimization with direct gradient-based optimization in a numerically\nstable manner. The framework's modular design enables the integration of any\ncomponent, from embeddings and deep networks to custom modules, into classic\nclick models for end-to-end optimization. We demonstrate CLAX's efficiency by\nrunning experiments on the full Baidu-ULTR dataset comprising over a billion\nuser sessions in $\\approx$ 2 hours on a single GPU, orders of magnitude faster\nthan traditional EM approaches. CLAX implements ten classic click models,\nserving both industry practitioners seeking to understand user behavior and\nimprove ranking performance at scale and researchers developing new click\nmodels. CLAX is available at: https://github.com/philipphager/clax",
        "entry_id": "http://arxiv.org/abs/2511.03620v1",
        "pub_date": "2025-11-05",
        "translated_summary": "CLAX是一个基于JAX的库，它通过现代梯度优化方法实现了经典点击模型。尽管神经点击模型在过去十年中不断涌现，但基于概率图模型的复杂点击模型尚未系统性地采用梯度优化方法，这导致从业者无法在保持经典模型可解释性的同时利用现代深度学习框架。CLAX通过以数值稳定的方式将基于EM的优化替换为直接梯度优化，成功解决了这一局限。该框架采用模块化设计，允许将嵌入层、深度网络乃至自定义模块等任何组件集成到经典点击模型中，实现端到端优化。我们在包含超十亿用户会话的完整Baidu-ULTR数据集上验证了CLAX的效率，单GPU仅需约2小时即可完成实验，比传统EM方法快数个数量级。CLAX实现了十种经典点击模型，既服务于需要理解用户行为并提升大规模排序性能的行业从业者，也助力于开发新型点击模型的研究人员。项目地址：https://github.com/philipphager/clax"
    },
    {
        "title": "A Semantic Encoding of Object Centric Event Data",
        "summary": "The Object-Centric Event Data (OCED) is a novel meta-model aimed at providing\na common ground for process data records centered around events and objects.\nOne of its objectives is to foster interoperability and process information\nexchange. In this context, the integration of data from different providers,\nthe combination of multiple processes, and the enhancement of knowledge\ninference are novel challenges. Semantic Web technologies can enable the\ncreation of a machine-readable OCED description enriched through ontology-based\nrelationships and entity categorization. In this paper, we introduce an\napproach built upon Semantic Web technologies for the realization of\nsemantic-enhanced OCED, with the aim to strengthen process data reasoning,\ninterconnect information sources, and boost expressiveness.",
        "entry_id": "http://arxiv.org/abs/2511.03351v1",
        "pub_date": "2025-11-05",
        "translated_summary": "以对象为中心的事件数据是一种新型元模型，旨在为围绕事件和对象构建的流程数据记录提供统一标准。该模型的目标之一是促进互操作性与流程信息交换。在此背景下，如何整合多源数据、融合多重流程以及增强知识推理能力成为全新挑战。语义网技术能够通过基于本体的关系定义与实体分类，构建机器可读的增强型事件数据描述。本文提出一种基于语义网技术的实现方法，旨在构建语义增强的以对象为中心的事件数据模型，从而强化流程数据推理能力，打通信息源之间的连接通道，提升系统表达能力。"
    },
    {
        "title": "Discourse-Aware Scientific Paper Recommendation via QA-Style Summarization and Multi-Level Contrastive Learning",
        "summary": "The rapid growth of open-access (OA) publications has intensified the\nchallenge of identifying relevant scientific papers. Due to privacy constraints\nand limited access to user interaction data, recent efforts have shifted toward\ncontent-based recommendation, which relies solely on textual information.\nHowever, existing models typically treat papers as unstructured text,\nneglecting their discourse organization and thereby limiting semantic\ncompleteness and interpretability. To address these limitations, we propose\nOMRC-MR, a hierarchical framework that integrates QA-style OMRC (Objective,\nMethod, Result, Conclusion) summarization, multi-level contrastive learning,\nand structure-aware re-ranking for scholarly recommendation. The QA-style\nsummarization module converts raw papers into structured and\ndiscourse-consistent representations, while multi-level contrastive objectives\nalign semantic representations across metadata, section, and document levels.\nThe final re-ranking stage further refines retrieval precision through\ncontextual similarity calibration. Experiments on DBLP, S2ORC, and the newly\nconstructed Sci-OMRC dataset demonstrate that OMRC-MR consistently surpasses\nstate-of-the-art baselines, achieving up to 7.2% and 3.8% improvements in\nPrecision@10 and Recall@10, respectively. Additional evaluations confirm that\nQA-style summarization produces more coherent and factually complete\nrepresentations. Overall, OMRC-MR provides a unified and interpretable\ncontent-based paradigm for scientific paper recommendation, advancing\ntrustworthy and privacy-aware scholarly information retrieval.",
        "entry_id": "http://arxiv.org/abs/2511.03330v1",
        "pub_date": "2025-11-05",
        "translated_summary": "开放获取（OA）文献的快速增长加剧了科学论文精准筛选的挑战。由于用户交互数据存在隐私限制与获取壁垒，近期研究重点已转向仅依赖文本信息的内容推荐方法。然而现有模型通常将论文视为非结构化文本，忽略了其论述结构，导致语义完整性受限且可解释性不足。为此，我们提出OMRC-MR分层框架，该框架融合了问答式OMRC（目标、方法、结果、结论）摘要生成、多层级对比学习与结构感知重排序技术，用于学术论文推荐。问答式摘要模块将原始论文转化为结构化的论述一致性表征，而多层级对比学习目标则在元数据、章节和文档层面实现语义表征对齐。最终的重排序阶段通过上下文相似度校准进一步提升检索精度。在DBLP、S2ORC及新建的Sci-OMRC数据集上的实验表明，OMRC-MR始终优于现有最优基线模型，在Precision@10和Recall@10指标上分别最高提升7.2%和3.8%。额外评估证实问答式摘要能生成更具连贯性与事实完整性的表征。总体而言，OMRC-MR为科学论文推荐提供了统一且可解释的内容驱动范式，推动了可信赖且保护隐私的学术信息检索发展。"
    },
    {
        "title": "Two thousand years of the oracle problem. Insights from Ancient Delphi on the future of blockchain oracles",
        "summary": "The oracle problem refers to the inability of an agent to know if the\ninformation coming from an oracle is authentic and unbiased. In ancient times,\nphilosophers and historians debated on how to evaluate, increase, and secure\nthe reliability of oracle predictions, particularly those from Delphi, which\npertained to matters of state. Today, we refer to data carriers for automatic\nmachines as oracles, but establishing a secure channel between these oracles\nand the real world still represents a challenge. Despite numerous efforts, this\nproblem remains mostly unsolved, and the recent advent of blockchain oracles\nhas added a layer of complexity because of the decentralization of blockchains.\nThis paper conceptually connects Delphic and modern blockchain oracles,\ndeveloping a comparative framework. Leveraging blockchain oracle taxonomy,\nlexical analysis is also performed on 167 Delphic queries to shed light on the\nrelationship between oracle answer quality and question type. The presented\nframework aims first at revealing commonalities between classical and\ncomputational oracles and then at enriching the oracle analysis within each\nfield. This study contributes to the computer science literature by proposing\nstrategies to improve the reliability of blockchain oracles based on insights\nfrom Delphi and to classical literature by introducing a framework that can\nalso be applied to interpret and classify other ancient oracular mechanisms.",
        "entry_id": "http://arxiv.org/abs/2511.03319v1",
        "pub_date": "2025-11-05",
        "translated_summary": "神谕问题是指行为体无法判断来自神谕的信息是否真实无偏。古代哲学家与历史学家曾就如何评估、提升并确保神谕预测（尤其是涉及国家事务的德尔斐神谕）的可靠性展开辩论。如今，我们将自动机器的数据载体称为预言机，但在这些预言机与现实世界之间建立安全通道仍具挑战。尽管付出诸多努力，该问题仍悬而未决，而近期区块链预言机的出现更因区块链的去中心化特性增添了复杂性。本文从概念层面将德尔斐神谕与现代区块链预言机相联系，构建出比较研究框架。基于区块链预言机分类法，我们对167条德尔斐神谕问询进行词法分析，以揭示神谕应答质量与问题类型之间的关联。该框架旨在首先揭示古典神谕与计算型预言机之间的共性，进而深化各自领域内的神谕分析。本研究通过借鉴德尔斐经验提出提升区块链预言机可靠性的策略，为计算机科学文献作出贡献；同时通过引入可适用于其他古代神谕机制解读与分类的分析框架，为古典文献研究提供了新视角。"
    },
    {
        "title": "KScaNN: Scalable Approximate Nearest Neighbor Search on Kunpeng",
        "summary": "Approximate Nearest Neighbor Search (ANNS) is a cornerstone algorithm for\ninformation retrieval, recommendation systems, and machine learning\napplications. While x86-based architectures have historically dominated this\ndomain, the increasing adoption of ARM-based servers in industry presents a\ncritical need for ANNS solutions optimized on ARM architectures. A naive port\nof existing x86 ANNS algorithms to ARM platforms results in a substantial\nperformance deficit, failing to leverage the unique capabilities of the\nunderlying hardware. To address this challenge, we introduce KScaNN, a novel\nANNS algorithm co-designed for the Kunpeng 920 ARM architecture. KScaNN\nembodies a holistic approach that synergizes sophisticated, data aware\nalgorithmic refinements with carefully-designed hardware specific\noptimizations. Its core contributions include: 1) novel algorithmic techniques,\nincluding a hybrid intra-cluster search strategy and an improved PQ residual\ncalculation method, which optimize the search process at a higher level; 2) an\nML-driven adaptive search module that provides adaptive, per-query tuning of\nsearch parameters, eliminating the inefficiencies of static configurations; and\n3) highly-optimized SIMD kernels for ARM that maximize hardware utilization for\nthe critical distance computation workloads. The experimental results\ndemonstrate that KScaNN not only closes the performance gap but establishes a\nnew standard, achieving up to a 1.63x speedup over the fastest x86-based\nsolution. This work provides a definitive blueprint for achieving\nleadership-class performance for vector search on modern ARM architectures and\nunderscores",
        "entry_id": "http://arxiv.org/abs/2511.03298v1",
        "pub_date": "2025-11-05",
        "translated_summary": "近似最近邻搜索（ANNS）是信息检索、推荐系统和机器学习应用的基础算法。虽然基于x86的架构历来主导该领域，但工业界对ARM服务器日益广泛的应用，亟需针对ARM架构优化的ANNS解决方案。将现有x86平台ANNS算法简单移植到ARM平台会导致显著性能损失，无法充分利用底层硬件的独特能力。为此，我们提出KScaNN——专为鲲鹏920 ARM架构协同设计的新型ANNS算法。该算法采用整体优化思路，将精密的数据感知算法改进与精心设计的硬件专用优化技术相融合，其核心创新包括：1）新型算法技术，包含混合式簇内搜索策略与改进的PQ残差计算方法，从更高维度优化搜索流程；2）基于机器学习的自适应搜索模块，实现按查询动态调整搜索参数，消除静态配置的效率瓶颈；3）针对ARM架构深度优化的SIMD内核，最大限度提升关键距离计算任务的硬件利用率。实验结果表明，KScaNN不仅弥补了性能差距，更树立了新的性能标杆，相较最快的x86解决方案实现最高1.63倍加速比。本研究为在现代ARM架构上实现领先级向量搜索性能提供了完整技术蓝图，同时印证了算法-硬件协同设计在下一代检索系统中的关键价值。"
    },
    {
        "title": "Beyond Ranked Lists: The SARAL Framework for Cross-Lingual Document Set Retrieval",
        "summary": "Machine Translation for English Retrieval of Information in Any Language\n(MATERIAL) is an IARPA initiative targeted to advance the state of\ncross-lingual information retrieval (CLIR). This report provides a detailed\ndescription of Information Sciences Institute's (ISI's) Summarization and\ndomain-Adaptive Retrieval Across Language's (SARAL's) effort for MATERIAL.\nSpecifically, we outline our team's novel approach to handle CLIR with emphasis\nin developing an approach amenable to retrieve a query-relevant document\n\\textit{set}, and not just a ranked document-list. In MATERIAL's Phase-3\nevaluations, SARAL exceeded the performance of other teams in five out of six\nevaluation conditions spanning three different languages (Farsi, Kazakh, and\nGeorgian).",
        "entry_id": "http://arxiv.org/abs/2511.03228v1",
        "pub_date": "2025-11-05",
        "translated_summary": "机器翻译英语跨语言信息检索项目（简称MATERIAL）是美国情报高级研究计划署推动跨语言信息检索技术发展的专项计划。本报告详细介绍了信息科学研究所SARAL团队在该项目中的研究成果，重点阐述了团队在跨语言检索方面的创新方法——突破传统排序文档列表模式，构建了一套能够检索查询相关文档集的解决方案。在MATERIAL第三阶段评估中，SARAL团队在涉及波斯语、哈萨克语和格鲁吉亚语三种语言的六项评测任务中，有五项性能表现超越其他参评团队。"
    },
    {
        "title": "Hybrid Fact-Checking that Integrates Knowledge Graphs, Large Language Models, and Search-Based Retrieval Agents Improves Interpretable Claim Verification",
        "summary": "Large language models (LLMs) excel in generating fluent utterances but can\nlack reliable grounding in verified information. At the same time,\nknowledge-graph-based fact-checkers deliver precise and interpretable evidence,\nyet suffer from limited coverage or latency. By integrating LLMs with knowledge\ngraphs and real-time search agents, we introduce a hybrid fact-checking\napproach that leverages the individual strengths of each component. Our system\ncomprises three autonomous steps: 1) a Knowledge Graph (KG) Retrieval for rapid\none-hop lookups in DBpedia, 2) an LM-based classification guided by a\ntask-specific labeling prompt, producing outputs with internal rule-based\nlogic, and 3) a Web Search Agent invoked only when KG coverage is insufficient.\nOur pipeline achieves an F1 score of 0.93 on the FEVER benchmark on the\nSupported/Refuted split without task-specific fine-tuning. To address Not\nenough information cases, we conduct a targeted reannotation study showing that\nour approach frequently uncovers valid evidence for claims originally labeled\nas Not Enough Information (NEI), as confirmed by both expert annotators and LLM\nreviewers. With this paper, we present a modular, opensource fact-checking\npipeline with fallback strategies and generalization across datasets.",
        "entry_id": "http://arxiv.org/abs/2511.03217v1",
        "pub_date": "2025-11-05",
        "translated_summary": "大型语言模型（LLM）在生成流畅文本方面表现出色，但可能缺乏对已验证信息的可靠依据。与此同时，基于知识图谱的事实核查系统虽能提供精确且可解释的证据，却存在覆盖范围有限或响应延迟的问题。通过将LLM与知识图谱及实时搜索智能体相结合，我们提出了一种混合式事实核查方法，充分发挥各组件的独特优势。该系统包含三个自动化步骤：1）知识图谱检索模块，用于在DBpedia中快速执行单跳查询；2）基于语言模型的分类器，通过任务特定的标注提示生成具有内部规则逻辑的输出；3）当知识图谱覆盖不足时触发的网络搜索代理。在FEVER基准测试的“支持/反驳”数据子集上，我们的流水线在不进行任务特定微调的情况下取得了0.93的F1分数。针对“信息不足”案例，我们开展了专项重标注研究，结果表明该方法能频繁为原标记为“信息不足”的声明找到有效证据，这一结论同时获得了专业标注者和LLM评审的确认。本文提出的模块化开源事实核查流水线具备故障应对策略，并展现出跨数据集的泛化能力。"
    },
    {
        "title": "TeaRAG: A Token-Efficient Agentic Retrieval-Augmented Generation Framework",
        "summary": "Retrieval-Augmented Generation (RAG) utilizes external knowledge to augment\nLarge Language Models' (LLMs) reliability. For flexibility, agentic RAG employs\nautonomous, multi-round retrieval and reasoning to resolve queries. Although\nrecent agentic RAG has improved via reinforcement learning, they often incur\nsubstantial token overhead from search and reasoning processes. This trade-off\nprioritizes accuracy over efficiency. To address this issue, this work proposes\nTeaRAG, a token-efficient agentic RAG framework capable of compressing both\nretrieval content and reasoning steps. 1) First, the retrieved content is\ncompressed by augmenting chunk-based semantic retrieval with a graph retrieval\nusing concise triplets. A knowledge association graph is then built from\nsemantic similarity and co-occurrence. Finally, Personalized PageRank is\nleveraged to highlight key knowledge within this graph, reducing the number of\ntokens per retrieval. 2) Besides, to reduce reasoning steps, Iterative\nProcess-aware Direct Preference Optimization (IP-DPO) is proposed.\nSpecifically, our reward function evaluates the knowledge sufficiency by a\nknowledge matching mechanism, while penalizing excessive reasoning steps. This\ndesign can produce high-quality preference-pair datasets, supporting iterative\nDPO to improve reasoning conciseness. Across six datasets, TeaRAG improves the\naverage Exact Match by 4% and 2% while reducing output tokens by 61% and 59% on\nLlama3-8B-Instruct and Qwen2.5-14B-Instruct, respectively. Code is available at\nhttps://github.com/Applied-Machine-Learning-Lab/TeaRAG.",
        "entry_id": "http://arxiv.org/abs/2511.05385v1",
        "pub_date": "2025-11-07",
        "translated_summary": "检索增强生成（RAG）通过引入外部知识来提升大语言模型的可靠性。为实现灵活检索，智能体化RAG采用自主多轮检索与推理机制处理查询。尽管当前基于强化学习的智能体化RAG性能有所提升，但其搜索与推理过程常伴随显著的令牌消耗，形成以效率换取准确性的权衡。为此，本文提出TeaRAG——一个能同时压缩检索内容与推理步骤的高效令牌智能体化RAG框架：1）在检索内容压缩方面，通过在图检索中引入简洁三元组增强基于语块的语义检索，构建融合语义关联与共现关系的知识图谱，进而利用个性化PageRank算法聚焦核心知识，降低单次检索的令牌数；2）在推理步骤优化方面，提出迭代过程感知直接偏好优化（IP-DPO），其奖励函数通过知识匹配机制评估知识完备性，同时对冗余推理步骤施加惩罚。该设计可生成高质量偏好对数据集，支撑迭代式DPO训练以提升推理简洁性。在六个数据集上的实验表明，在Llama3-8B-Instruct和Qwen2.5-14B-Instruct模型上，TeaRAG将精确匹配率平均提升4%与2%，同时分别减少61%和59%的输出令牌数。代码已开源：https://github.com/Applied-Machine-Learning-Lab/TeaRAG。"
    },
    {
        "title": "QUESTER: Query Specification for Generative Retrieval",
        "summary": "Generative Retrieval (GR) differs from the traditional index-then-retrieve\npipeline by storing relevance in model parameters and directly generating\ndocument identifiers. However, GR often struggles to generalize and is costly\nto scale. We introduce QUESTER (QUEry SpecificaTion gEnerative Retrieval),\nwhich reframes GR as query specification generation - in this work, a simple\nkeyword query handled by BM25 - using a (small) LLM. The policy is trained\nusing reinforcement learning techniques (GRPO). Across in- and out-of-domain\nevaluations, we show that our model is more effective than BM25, and\ncompetitive with neural IR models, while maintaining a good efficiency",
        "entry_id": "http://arxiv.org/abs/2511.05301v1",
        "pub_date": "2025-11-07",
        "translated_summary": "生成式检索与传统“先索引后检索”流程不同，其将相关性信息存储于模型参数中，并直接生成文档标识符。然而该方法常面临泛化能力不足与扩展成本高昂的问题。我们提出QUESTER框架（查询规约生成式检索），通过（轻量级）大语言模型将生成式检索重构为查询规约生成任务——本研究中体现为可由BM25处理的简易关键词查询。该策略采用强化学习技术（GRPO）进行训练。在领域内外多项评估中，我们的模型不仅效果优于BM25，更能与神经信息检索模型保持竞争力，同时维持良好的检索效率。"
    },
    {
        "title": "Mapping Research Productivity of BRICS Countries with Special Reference to Coronary Artery Disease (CAD): A Scientometric Study",
        "summary": "This study presents a comprehensive scientometric analysis of research\nproductivity on Coronary Artery Disease (CAD) among the BRICS countries,\nBrazil, Russia, India, China, and South Africa, using data retrieved from the\nWeb of Science database for the period 1990 to 2019. A total of 50,036 records\nwere analyzed to assess publication growth trends, authorship patterns,\ncollaboration levels, and citation impact. The findings reveal a steady\nincrease in CAD-related publications, with China emerging as the leading\ncontributor, followed by Brazil, Russia, India, and South Africa. English\ndominated as the primary language of communication, accounting for over 93% of\npublications. Authorship and collaboration analysis indicate a high degree of\njoint research, with 97.91% of studies being co-authored and a degree of\ncollaboration of 0.98, underscoring the collective nature of scientific inquiry\nin this domain. The study validates the applicability of Lotkas Law for author\nproductivity, Bradfords Law for journal distribution, and Zipfs Law for keyword\nfrequency, while the Price Square Root Law was found inapplicable. The\npredominant publication format was journal articles (79.7%), and Kardiologiya\n(Russia) emerged as the most prolific journal. The results demonstrate\nsignificant growth in CAD research output and collaboration within BRICS,\nthough notable disparities persist among member nations. The study recommends\nenhancing individual author productivity, expanding international\ncollaboration, and supporting CAD research through strategic institutional and\ngovernmental initiatives. These findings provide valuable insights for\npolicymakers, funding agencies, and the academic community to strengthen\ncardiovascular research capacity within developing economies.",
        "entry_id": "http://arxiv.org/abs/2511.05211v1",
        "pub_date": "2025-11-07",
        "translated_summary": "本研究通过科学计量学方法，对1990-2019年间金砖国家（巴西、俄罗斯、印度、中国、南非）在冠状动脉疾病（CAD）领域的研究产出进行全面分析。基于Web of Science数据库提取的50,036条文献记录，系统评估了论文增长趋势、作者模式、合作水平及引用影响力。研究发现：CAD相关出版物呈稳定增长态势，中国位居发文量首位，其后依次为巴西、俄罗斯、印度和南非；英文为主要交流语言（占比93%以上）；作者与合作分析显示该领域具有高度协同性——合著率达97.91%，合作强度指数达0.98，凸显科研合作的集体性特征。研究验证了洛特卡定律（作者产出分布）、布拉德福定律（期刊分布）与齐普夫定律（关键词频次）的适用性，但普赖斯平方根定律在此不适用。期刊论文是主要成果形式（79.7%），其中俄罗斯《Kardiologiya》为最高产期刊。结果表明金砖国家CAD研究产出与合作显著增长，但成员国间仍存在明显差异。建议通过机构与政府的战略性支持，提升个体作者产出、拓展国际合作网络。本研究为政策制定者、资助机构及学术界加强发展中国家心血管研究能力建设提供了重要参考依据。"
    },
    {
        "title": "Wikipedia-based Datasets in Russian Information Retrieval Benchmark RusBEIR",
        "summary": "In this paper, we present a novel series of Russian information retrieval\ndatasets constructed from the \"Did you know...\" section of Russian Wikipedia.\nOur datasets support a range of retrieval tasks, including fact-checking,\nretrieval-augmented generation, and full-document retrieval, by leveraging\ninteresting facts and their referenced Wikipedia articles annotated at the\nsentence level with graded relevance. We describe the methodology for dataset\ncreation that enables the expansion of existing Russian Information Retrieval\n(IR) resources. Through extensive experiments, we extend the RusBEIR research\nby comparing lexical retrieval models, such as BM25, with state-of-the-art\nneural architectures fine-tuned for Russian, as well as multilingual models.\nResults of our experiments show that lexical methods tend to outperform neural\nmodels on full-document retrieval, while neural approaches better capture\nlexical semantics in shorter texts, such as in fact-checking or fine-grained\nretrieval. Using our newly created datasets, we also analyze the impact of\ndocument length on retrieval performance and demonstrate that combining\nretrieval with neural reranking consistently improves results. Our contribution\nexpands the resources available for Russian information retrieval research and\nhighlights the importance of accurate evaluation of retrieval models to achieve\noptimal performance. All datasets are publicly available at HuggingFace. To\nfacilitate reproducibility and future research, we also release the full\nimplementation on GitHub.",
        "entry_id": "http://arxiv.org/abs/2511.05079v1",
        "pub_date": "2025-11-07",
        "translated_summary": "本文基于俄语维基百科\"你知道吗…\"栏目构建了一套新颖的俄语信息检索数据集。该数据集通过利用趣味性事实及其引用的维基百科文章（附带句子级分级相关性标注），支持事实核查、检索增强生成和全文档检索等多重任务。我们详细阐述了扩展现有俄语信息检索资源的数据集构建方法，并通过系列实验拓展了RusBEIR研究框架，系统比较了BM25等词汇检索模型与针对俄语优化的前沿神经架构及多语言模型。实验结果表明：在全文档检索任务中，词汇检索方法普遍优于神经模型，而在事实核查或细粒度检索等短文本场景中，神经方法更能有效捕捉词汇语义。基于新建数据集，我们进一步分析了文档长度对检索性能的影响，论证了神经重排序与检索结合的持续增效作用。本研究成果拓展了俄语信息检索的研究资源，强调精准评估检索模型对实现最优性能的重要性。所有数据集已发布于HuggingFace平台，并为确保可复现性及后续研究，我们在GitHub同步开放完整实现代码。"
    },
    {
        "title": "The use of social media among library professionals and patrons: A review of literature",
        "summary": "This paper focused on the utilization of social media by library\nprofessionals and library users. It provides an understanding of social media,\nthe most popular social media platforms utilized in the libraries. It also\nmentions the reasons for the adoption of social media in libraries be it\nacademic, public, school libraries and other types of libraries. This is a\nreview paper on the use of social media among library professionals and\npatrons. The findings reveal the contributions of social media to the\nlibraries. Social media makes things easy for library professionals and library\nusers. It enables them to connect, create awareness to new information,\ndisseminate information instantly, and helps to market the library resources\nand services. Therefore, it is recommended amongst others that the library\nmanagement board should encourage the use of social media in libraries.",
        "entry_id": "http://arxiv.org/abs/2511.05051v1",
        "pub_date": "2025-11-07",
        "translated_summary": "本文聚焦图书馆从业人员与用户对社交媒体的应用实践，系统阐释了社交媒体的概念内涵、图书馆界使用最普遍的社交平台类型，并剖析了高校图书馆、公共图书馆、中小学图书馆及各类专业图书馆采纳社交媒体技术的动因。作为针对图书馆从业者与使用者社交媒体应用的综述性研究，本文发现社交媒体为图书馆事业带来多重赋能：它显著提升馆员工作效率与用户服务体验，构建馆群与用户间的即时连接渠道，助推最新资讯的传播触达，实现馆藏资源与服务的精准推广。基于研究结论，建议图书馆管理委员会将社交媒体应用纳入发展战略，积极推动各类图书馆部署社会化媒体工具。"
    },
    {
        "title": "Query Generation Pipeline with Enhanced Answerability Assessment for Financial Information Retrieval",
        "summary": "As financial applications of large language models (LLMs) gain attention,\naccurate Information Retrieval (IR) remains crucial for reliable AI services.\nHowever, existing benchmarks fail to capture the complex and domain-specific\ninformation needs of real-world banking scenarios. Building domain-specific IR\nbenchmarks is costly and constrained by legal restrictions on using real\ncustomer data. To address these challenges, we propose a systematic methodology\nfor constructing domain-specific IR benchmarks through LLM-based query\ngeneration. As a concrete implementation of this methodology, our pipeline\ncombines single and multi-document query generation with an enhanced and\nreasoning-augmented answerability assessment method, achieving stronger\nalignment with human judgments than prior approaches. Using this methodology,\nwe construct KoBankIR, comprising 815 queries derived from 204 official banking\ndocuments. Our experiments show that existing retrieval models struggle with\nthe complex multi-document queries in KoBankIR, demonstrating the value of our\nsystematic approach for domain-specific benchmark construction and underscoring\nthe need for improved retrieval techniques in financial domains.",
        "entry_id": "http://arxiv.org/abs/2511.05000v1",
        "pub_date": "2025-11-07",
        "translated_summary": "随着大语言模型在金融领域的应用日益受到关注，精准的信息检索技术仍是确保人工智能服务可靠性的关键。然而，现有基准测试难以全面反映真实银行场景中复杂且具有领域特性的信息需求。构建领域专用信息检索基准不仅成本高昂，还受到使用真实客户数据的法律限制。为应对这些挑战，我们提出一种基于大语言模型的系统性领域检索基准构建方法。作为该方法的具体实践，我们的流程将单文档与多文档查询生成相结合，并引入增强型推理辅助可答性评估机制，相比现有方法更能契合人类判断标准。基于该方法构建的KoBankIR基准库包含从204份官方银行文件衍生的815条查询指令。实验表明，现有检索模型在应对KoBankIR中复杂的多文档查询时表现不佳，这既印证了我们系统性构建方法的有效性，也揭示了金融领域检索技术亟待提升的现实需求。"
    },
    {
        "title": "Search Is Not Retrieval: Decoupling Semantic Matching from Contextual Assembly in RAG",
        "summary": "Retrieval systems are essential to contemporary AI pipelines, although most\nconfuse two separate processes: finding relevant information and giving enough\ncontext for reasoning. We introduce the Search-Is-Not-Retrieve (SINR)\nframework, a dual-layer architecture that distinguishes between fine-grained\nsearch representations and coarse-grained retrieval contexts. SINR enhances the\ncomposability, scalability, and context fidelity of retrieval systems by\ndirectly connecting small, semantically accurate search chunks to larger,\ncontextually complete retrieve chunks, all without incurring extra processing\ncosts. This design changes retrieval from a passive step to an active one,\nmaking the system architecture more like how people process information. We\ndiscuss the SINR framework's conceptual foundation, formal structure,\nimplementation issues, and qualitative outcomes. This provides a practical\nfoundation for the next generation of AI systems that use retrieval.",
        "entry_id": "http://arxiv.org/abs/2511.04939v1",
        "pub_date": "2025-11-07",
        "translated_summary": "检索系统是现代人工智能流程的核心组件，但多数系统混淆了两个独立过程：寻找相关信息与提供充分推理语境。我们提出\"搜索非检索\"（SINR）框架，该双层级架构明确区分细粒度搜索表征与粗粒度检索语境。通过将语义精准的小型搜索块与语境完整的宏观检索块直接关联，SINR在无需额外处理成本的前提下，显著提升了检索系统的可组合性、扩展性与语境保真度。这一设计使检索从被动步骤转变为主动过程，令系统架构更贴近人类信息处理模式。我们将深入探讨SINR框架的理论基础、形式化结构、实施要点与质性成效，为下一代基于检索的人工智能系统奠定实践基础。"
    },
    {
        "title": "Association via Entropy Reduction",
        "summary": "Prior to recent successes using neural networks, term frequency-inverse\ndocument frequency (tf-idf) was clearly regarded as the best choice for\nidentifying documents related to a query. We provide a different score, aver,\nand observe, on a dataset with ground truth marking for association, that aver\ndoes do better at finding assciated pairs than tf-idf. This example involves\nfinding associated vertices in a large graph and that may be an area where\nneural networks are not currently an obvious best choice. Beyond this one\nanecdote, we observe that (1) aver has a natural threshold for declaring pairs\nas unassociated while tf-idf does not, (2) aver can distinguish between pairs\nof documents for which tf-idf gives a score of 1.0, (3) aver can be applied to\nlarger collections of documents than pairs while tf-idf cannot, and (4) that\naver is derived from entropy under a simple statistical model while tf-idf is a\nconstruction designed to achieve a certain goal and hence aver may be more\n\"natural.\" To be fair, we also observe that (1) writing down and computing the\naver score for a pair is more complex than for tf-idf and (2) that the fact\nthat the aver score is naturally scale-free makes it more complicated to\ninterpret aver scores.",
        "entry_id": "http://arxiv.org/abs/2511.04901v1",
        "pub_date": "2025-11-07",
        "translated_summary": "在神经网络取得近期成功之前，词频-逆文档频率（tf-idf）被公认为检索关联文档的最佳方法。我们提出了一种新型评分指标aver，并在具有真实关联标注的数据集上验证了其在发现关联文档对方面确实优于tf-idf。本案例涉及大型图中的关联顶点发现，这或许是神经网络目前尚未显现明显优势的领域。除该实例外，我们还发现：（1）aver具有判定非关联对的天然阈值而tf-idf不具备；（2）对于tf-idf评分均为1.0的文档对，aver能有效区分其关联强度；（3）aver可扩展应用于多文档集而tf-idf仅适用于文档对；（4）aver基于简单统计模型中的熵推导得出，而tf-idf是为实现特定目标构建的指标，因此aver可能更具“自然性”。公允而言，我们也注意到：（1）aver的计算公式与过程较tf-idf更为复杂；（2）aver天然具备无量纲特性，这使其得分解读更具挑战性。"
    },
    {
        "title": "EMO100DB: An Open Dataset of Improvised Songs with Emotion Data",
        "summary": "In this study, we introduce Emo100DB: a dataset consisting of improvised\nsongs that were recorded and transcribed with emotion data based on Russell's\ncircumplex model of emotion. The dataset was developed by collecting improvised\nsongs that consist of melody, lyrics, and an instrumental accompaniment played,\nsung, and recorded by 20 young adults. Before recording each song, the\nparticipants were asked to report their emotional state, with the axes\nrepresenting arousal and valence based on Russell's circumplex model of\nemotions. The dataset is organized into four emotion quadrants, and it includes\nthe lyrics text and MIDI file of the melody extracted from the participant\nrecordings, along with the original audio in WAV format. By providing an\nintegrated composition of data and analysis, this study aims to offer a\ncomprehensive dataset that allows for a diverse exploration of the relationship\nbetween music and emotion.",
        "entry_id": "http://arxiv.org/abs/2511.04755v1",
        "pub_date": "2025-11-06",
        "translated_summary": "本研究推出Emo100DB数据集——一个收录即兴演唱歌曲的数据库，所有曲目均基于罗素情感环状模型进行录音、文本转写及情感标注。该数据集通过采集20位青年创作者即兴创作的歌曲构建而成，每首作品包含由参与者演奏录制的旋律、人声歌词与器乐伴奏。在录制前，参与者需根据罗素情感环状模型的双轴维度（唤醒度与效价）自评当前情感状态。数据集按情感象限分为四类，除原始WAV格式音频外，还提供从录音中提取的歌词文本与旋律MIDI文件。通过整合数据资源与分析维度，本研究旨在构建一个能够支持多角度探索音乐与情感关联的综合性数据集。"
    },
    {
        "title": "On the Brittleness of CLIP Text Encoders",
        "summary": "Multimodal co-embedding models, especially CLIP, have advanced the state of\nthe art in zero-shot classification and multimedia information retrieval in\nrecent years by aligning images and text in a shared representation space.\nHowever, such modals trained on a contrastive alignment can lack stability\ntowards small input perturbations. Especially when dealing with manually\nexpressed queries, minor variations in the query can cause large differences in\nthe ranking of the best-matching results. In this paper, we present a\nsystematic analysis of the effect of multiple classes of non-semantic query\nperturbations in an multimedia information retrieval scenario. We evaluate a\ndiverse set of lexical, syntactic, and semantic perturbations across multiple\nCLIP variants using the TRECVID Ad-Hoc Video Search queries and the V3C1 video\ncollection. Across models, we find that syntactic and semantic perturbations\ndrive the largest instabilities, while brittleness is concentrated in trivial\nsurface edits such as punctuation and case. Our results highlight robustness as\na critical dimension for evaluating vision-language models beyond benchmark\naccuracy.",
        "entry_id": "http://arxiv.org/abs/2511.04247v2",
        "pub_date": "2025-11-06",
        "translated_summary": "近年来，多模态协同嵌入模型（特别是CLIP）通过将图像与文本对齐至共享表征空间，在零样本分类和多媒体信息检索领域实现了重大突破。然而，基于对比对齐训练的此类模型对输入微小扰动缺乏稳定性。尤其在处理人工表述的查询时，查询语句的细微变化可能导致最佳匹配结果的排序产生显著差异。本文系统分析了多媒体信息检索场景中多类非语义查询扰动的影响，基于TRECVID Ad-Hoc视频搜索查询和V3C1视频数据集，对多种CLIP变体进行了词汇、句法和语义层面的扰动测试。研究发现：所有模型均对句法与语义扰动最为敏感，而鲁棒性薄弱环节集中在标点符号、大小写等表层文本编辑。这一结果表明，在基准准确率之外，鲁棒性应成为评估视觉语言模型的关键维度。"
    },
    {
        "title": "Collaborative residual learners for automatic icd10 prediction using prescribed medications",
        "summary": "Clinical coding is an administrative process that involves the translation of diagnostic data from episodes of care into a standard code format such as ICD10. It has many critical applications such as billing and aetiology research. The automation of clinical coding is very challenging due to data sparsity, low interoperability of digital health systems, complexity of real-life diagnosis coupled with the huge size of ICD10 code space. Related work suffer from low applicability due to reliance on many data sources, inefficient modelling and less generalizable solutions. We propose a novel collaborative residual learning based model to automatically predict ICD10 codes employing only prescriptions data. Extensive experiments were performed on two real-world clinical datasets (outpatient & inpatient) from Maharaj Nakorn Chiang Mai Hospital with real case-mix distributions. We obtain multi-label classification accuracy of 0.71 and 0.57 of average precision, 0.57 and 0.38 of F1-score and 0.73 and 0.44 of accuracy in predicting principal diagnosis for inpatient and outpatient datasets respectively.",
        "entry_id": "http://arxiv.org/abs/2012.11327v1",
        "pub_date": "2020-12-16",
        "translated_summary": "临床编码是将诊疗过程中的诊断数据转换为ICD10等标准编码格式的行政流程，在医疗计费和病因学研究等领域具有重要应用。由于数据稀疏性、数字健康系统互操作性低、真实诊断复杂性及ICD10编码体系庞大，临床编码自动化面临巨大挑战。现有研究因依赖多数据源、建模效率低及解决方案普适性差，存在适用性不足的问题。本文提出一种基于协同残差学习的新型模型，仅通过处方数据即可实现ICD10编码的自动预测。我们在清迈大学马哈拉吉医院包含真实病例组合的门诊与住院数据集上开展了大量实验，结果显示：针对住院和门诊数据集，多标签分类的平均精确度分别达到0.71和0.57，F1分数分别为0.57和0.38，主要诊断预测准确率分别达到0.73和0.44。"
    },
    {
        "title": "Ensemble model for pre-discharge icd10 coding prediction",
        "summary": "The translation of medical diagnosis to clinical coding has wide range of applications in billing, aetiology analysis, and auditing. Currently, coding is a manual effort while the automation of such task is not straight forward. Among the challenges are the messy and noisy clinical records, case complexities, along with the huge ICD10 code space. Previous work mainly relied on discharge notes for prediction and was applied to a very limited data scale. We propose an ensemble model incorporating multiple clinical data sources for accurate code predictions. We further propose an assessment mechanism to provide confidence rates in predicted outcomes. Extensive experiments were performed on two new real-world clinical datasets (inpatient & outpatient) with unaltered case-mix distributions from Maharaj Nakorn Chiang Mai Hospital. We obtain multi-label classification accuracies of 0.73 and 0.58 for average precision, 0.56 and 0.35 for F1-scores and 0.71 and 0.4 accuracy in predicting principal diagnosis for inpatient and outpatient datasets respectively.",
        "entry_id": "http://arxiv.org/abs/2012.11333v1",
        "pub_date": "2020-12-16",
        "translated_summary": "将医疗诊断转化为临床编码在医疗账单管理、病因分析和审计等领域具有广泛应用。当前编码工作主要依赖人工完成，而实现该任务的自动化面临诸多挑战：临床记录杂乱且存在噪声、病例复杂度高、ICD10编码体系庞大。既往研究主要依赖出院小结进行预测，且仅在极有限的数据规模上实施。我们提出一种融合多源临床数据的集成模型，以实现精准的编码预测，并建立评估机制为预测结果提供置信度评级。基于玛哈叻清迈医院未经筛选的真实临床数据集（住院与门诊），我们开展了大规模实验验证。实验结果显示：在住院与门诊数据集上，多标签分类的平均精确度分别达到0.73和0.58，F1分数分别为0.56和0.35，主要诊断预测准确率分别达到0.71和0.4。"
    },
    {
        "title": "Should I visit this place? Inclusion and Exclusion Phrase Mining from Reviews",
        "summary": "Although several automatic itinerary generation services have made travel planning easy, often times travellers find themselves in unique situations where they cannot make the best out of their trip. Visitors differ in terms of many factors such as suffering from a disability, being of a particular dietary preference, travelling with a toddler, etc. While most tourist spots are universal, others may not be inclusive for all. In this paper, we focus on the problem of mining inclusion and exclusion phrases associated with 11 such factors, from reviews related to a tourist spot. While existing work on tourism data mining mainly focuses on structured extraction of trip related information, personalized sentiment analysis, and automatic itinerary generation, to the best of our knowledge this is the first work on inclusion/exclusion phrase mining from tourism reviews. Using a dataset of 2000 reviews related to 1000 tourist spots, our broad level classifier provides a binary overlap F1 of $\\sim$80 and $\\sim$82 to classify a phrase as inclusion or exclusion respectively. Further, our inclusion/exclusion classifier provides an F1 of $\\sim$98 and $\\sim$97 for 11-class inclusion and exclusion classification respectively. We believe that our work can significantly improve the quality of an automatic itinerary generation service.",
        "entry_id": "http://arxiv.org/abs/2012.10226v1",
        "pub_date": "2020-12-18",
        "translated_summary": "尽管多项自动化行程生成服务已使旅行规划变得便捷，但游客在特殊情境下仍难以充分享受旅程。游客个体差异显著——或身患残疾、或有特殊饮食偏好、或需携带幼童同行等。虽然多数旅游景点具有普适性，但部分场所却无法满足所有人群需求。本文重点研究从旅游景点相关评论中挖掘涉及11类特殊因素的包容性与排斥性短语。现有旅游数据挖掘研究主要集中于行程信息的结构化提取、个性化情感分析及自动化行程生成，而本研究首次针对旅游评论中的包容/排斥短语进行挖掘。基于涵盖1000个旅游景点的2000条评论数据集，我们的广义分类器在判断短语属于包容类或排斥类时，分别获得约80和约82的二元重叠F1值。进一步地，针对11类细分场景的包容与排斥分类，我们的专用分类器分别取得了约98和约97的F1值。我们相信这项研究将显著提升自动化行程生成服务的质量。"
    },
    {
        "title": "Intelligent Vector-based Customer Segmentation in the Banking Industry",
        "summary": "Customer Segmentation is the process of dividing customers into groups based on common characteristics. An intelligent Customer Segmentation will not only enable an organization to effectively allocate marketing resources (e.g., Recommender Systems in the Banking sector) but also it will enable identifying the customer cohorts that are most likely to benefit from a specific policy (e.g., to discover diverse patient groups in the Health sector). While there has been a significant improvement in approaches to Customer Segmentation, the main challenge remains to be the understanding of the reasons behind the segmentation need. This task is challenging as it is subjective and depends on the goal of segmentation as well as the analyst's perspective. To address this challenge, in this paper, we present an intelligent vector-based customer segmentation approach. The proposed approach will leverage feature engineering to enable analysts to identify important features (from a pool of features such as demographics, geography, psychographics, behavioral, and more) and feed them into a neural embedding framework named Customer2Vec. The Customer2Vec combines the neural network classification and clustering methods as supervised and unsupervised learning techniques to embed the customer vector. We adopt a typical scenario in the Banking Sector to highlight how Customer2Vec significantly improves the quality of the segmentation and detecting customer similarities.",
        "entry_id": "http://arxiv.org/abs/2012.11876v1",
        "pub_date": "2020-12-22",
        "translated_summary": "客户细分是根据共同特征将客户划分为不同群体的过程。智能化的客户细分不仅能够帮助机构有效配置营销资源（例如银行业的推荐系统），还能识别最可能从特定政策中受益的客户群体（例如医疗领域中发现不同类型的患者群体）。尽管客户细分方法已取得显著进展，但核心挑战仍在于理解细分需求背后的动因。由于该任务具有主观性，且取决于细分目标和分析师视角，因此极具挑战性。为解决这一难题，本文提出了一种基于向量的智能客户细分方法。该方法通过特征工程，使分析师能够从人口统计、地理、心理特征、行为特征等特征池中识别重要特征，并将其输入名为Customer2Vec的神经嵌入框架。该框架结合神经网络分类（监督学习）与聚类（无监督学习）技术，构建客户向量嵌入模型。我们通过银行业典型场景验证了Customer2Vec能显著提升细分质量与客户相似度检测效果。"
    },
    {
        "title": "Dynamic-K Recommendation with Personalized Decision Boundary",
        "summary": "In this paper, we investigate the recommendation task in the most common scenario with implicit feedback (e.g., clicks, purchases). State-of-the-art methods in this direction usually cast the problem as to learn a personalized ranking on a set of items (e.g., webpages, products). The top-N results are then provided to users as recommendations, where the N is usually a fixed number pre-defined by the system according to some heuristic criteria (e.g., page size, screen size). There is one major assumption underlying this fixed-number recommendation scheme, i.e., there are always sufficient relevant items to users' preferences. Unfortunately, this assumption may not always hold in real-world scenarios. In some applications, there might be very limited candidate items to recommend, and some users may have very high relevance requirement in recommendation. In this way, even the top-1 ranked item may not be relevant to a user's preference. Therefore, we argue that it is critical to provide a dynamic-K recommendation, where the K should be different with respect to the candidate item set and the target user. We formulate this dynamic-K recommendation task as a joint learning problem with both ranking and classification objectives. The ranking objective is the same as existing methods, i.e., to create a ranking list of items according to users' interests. The classification objective is unique in this work, which aims to learn a personalized decision boundary to differentiate the relevant items from irrelevant items. Based on these ideas, we extend two state-of-the-art ranking-based recommendation methods, i.e., BPRMF and HRM, to the corresponding dynamic-K versions, namely DK-BPRMF and DK-HRM. Our experimental results on two datasets show that the dynamic-K models are more effective than the original fixed-N recommendation methods.",
        "entry_id": "http://arxiv.org/abs/2012.13569v1",
        "pub_date": "2020-12-25",
        "translated_summary": "本文研究基于隐式反馈（如点击、购买行为）的推荐任务。该领域的先进方法通常将问题转化为对项目集合（如网页、商品）进行个性化排序学习，并将前N个结果作为推荐内容提供给用户。其中N值通常是根据启发式标准（如页面尺寸、屏幕大小）预设的固定数值。这种固定数量推荐方案存在一个关键前提假设：系统总能找到足够多的符合用户偏好的相关项目。然而在实际场景中，该假设未必始终成立。某些应用场景中可推荐候选项目非常有限，部分用户对推荐内容的相关性要求极高，此时即使排名首位的项目也可能与用户偏好不匹配。因此我们提出动态K值推荐机制，其核心在于根据候选项目集和目标用户特性动态调整K值。我们将该任务形式化为包含排序与分类目标的联合学习问题：排序目标与现有方法一致，即根据用户兴趣生成项目排序列表；分类目标则是本研究的创新点，旨在通过学习个性化决策边界来区分相关与无关项目。基于此思路，我们拓展了两种先进排序推荐方法（BPRMF与HRM），提出对应的动态K版本DK-BPRMF和DK-HRM。在两个数据集上的实验结果表明，动态K模型较原始固定N值推荐方法具有显著优势。"
    },
    {
        "title": "Recommending Courses in MOOCs for Jobs: An Auto Weak Supervision Approach",
        "summary": "The proliferation of massive open online courses (MOOCs) demands an effective way of course recommendation for jobs posted in recruitment websites, especially for the people who take MOOCs to find new jobs. Despite the advances of supervised ranking models, the lack of enough supervised signals prevents us from directly learning a supervised ranking model. This paper proposes a general automated weak supervision framework AutoWeakS via reinforcement learning to solve the problem. On the one hand, the framework enables training multiple supervised ranking models upon the pseudo labels produced by multiple unsupervised ranking models. On the other hand, the framework enables automatically searching the optimal combination of these supervised and unsupervised models. Systematically, we evaluate the proposed model on several datasets of jobs from different recruitment websites and courses from a MOOCs platform. Experiments show that our model significantly outperforms the classical unsupervised, supervised and weak supervision baselines.",
        "entry_id": "http://arxiv.org/abs/2012.14234v1",
        "pub_date": "2020-12-28",
        "translated_summary": "大规模开放在线课程(MOOC)的激增，要求招聘网站能为发布的职位提供有效的课程推荐服务，尤其对希望通过慕课求职的人群具有重要意义。尽管现有排序模型已取得长足发展，但监督信号的严重缺失制约了有监督排序模型的直接应用。为此，本文提出基于强化学习的通用自动化弱监督框架AutoWeakS：一方面通过无监督排序模型生成伪标签，进而训练多个有监督排序模型；另一方面通过强化学习自动搜索最优模型组合。我们系统化地在多个招聘网站职位数据集和慕课平台课程数据集上进行评估，实验表明该模型显著优于经典的无监督、有监督及弱监督基线方法。"
    },
    {
        "title": "Measuring University Impact: Wikipedia approach",
        "summary": "The impact of Universities on the social, economic and political landscape is one of the key directions in contemporary educational evaluation. In this paper, we discuss the new methodological technique that evaluates the impact of university based on popularity (number of page-views) of their alumni's pages on Wikipedia. It allows revealing the alumni popularity dynamics and tracking its state. Preliminary analysis shows that the number of page-views is higher for the contemporary persons that prove the perspectives of this approach. Then, universities were ranked based on the methodology and compared to the famous international university rankings ARWU and QS based only on alumni scales: for the top 10 universities, there is an intersection of two universities (Columbia University, Stanford University). The correlation coefficients between different university rankings are provided in the paper. Finally, the ranking based on the alumni popularity was compared with the ranking of universities based on the popularity of their webpages on Wikipedia: there is a strong connection between these indicators.",
        "entry_id": "http://arxiv.org/abs/2012.13980v1",
        "pub_date": "2020-12-27",
        "translated_summary": "高校对社会、经济及政治格局的影响是当代教育评估的核心方向之一。本文探讨了一种基于维基百科校友页面浏览量数据的高校影响力评估新方法。该方法能揭示校友知名度动态变化并追踪其状态。初步分析表明，当代人物的页面浏览量更高，这印证了该方法的应用前景。我们根据该方法对高校进行排名，并与仅基于校友规模的国际知名大学排名（ARWU和QS）进行比较：在前十名高校中，有两个大学重合（哥伦比亚大学、斯坦福大学）。文中提供了不同大学排名间的相关系数。最后，将基于校友知名度的排名与基于高校维基百科页面浏览量的排名进行对比，发现这两项指标之间存在显著关联。"
    },
    {
        "title": "Neural document expansion for ad-hoc information retrieval",
        "summary": "Recently, Nogueira et al. [2019] proposed a new approach to document expansion based on a neural Seq2Seq model, showing significant improvement on short text retrieval task. However, this approach needs a large amount of in-domain training data. In this paper, we show that this neural document expansion approach can be effectively adapted to standard IR tasks, where labels are scarce and many long documents are present.",
        "entry_id": "http://arxiv.org/abs/2012.14005v1",
        "pub_date": "2020-12-27",
        "translated_summary": "最近，Nogueira等人[2019]提出了一种基于神经序列到序列模型的新文档扩展方法，在短文本检索任务上展现出显著提升。然而，该方法需要大量领域内训练数据。本文证明，这种神经文档扩展方法能有效适配标准信息检索任务——这类任务通常面临标注稀缺且存在大量长文档的挑战。"
    },
    {
        "title": "Query Expansion for Cross-Language Question Re-Ranking",
        "summary": "Community question-answering (CQA) platforms have become very popular forums for asking and answering questions daily. While these forums are rich repositories of community knowledge, they present challenges for finding relevant answers and similar questions, due to the open-ended nature of informal discussions. Further, if the platform allows questions and answers in multiple languages, we are faced with the additional challenge of matching cross-lingual information. In this work, we focus on the cross-language question re-ranking shared task, which aims to find existing questions that may be written in different languages. Our contribution is an exploration of query expansion techniques for this problem. We investigate expansions based on Word Embeddings, DBpedia concepts linking, and Hypernym, and show that they outperform existing state-of-the-art methods.",
        "entry_id": "http://arxiv.org/abs/1904.07982v1",
        "pub_date": "2019-04-16",
        "translated_summary": "社区问答平台已成为日常提问与回答的热门论坛。尽管这些论坛是社区知识的丰富宝库，但由于开放式非正式讨论的特性，在寻找相关答案和类似问题时仍面临挑战。此外，若平台允许多语言提问与回答，我们还需应对跨语言信息匹配这一额外难题。本研究聚焦于跨语言问题重排序共享任务，旨在发现可能以不同语言表述的现存问题。我们的贡献在于针对该问题探索查询扩展技术，研究了基于词嵌入、DBpedia概念链接和上位词关系的扩展方法，并证明这些方法优于现有前沿技术。"
    },
    {
        "title": "How to define co-occurrence in different domains of study?",
        "summary": "This position paper presents a comparative study of co-occurrences. Some similarities and differences in the definition exist depending on the research domain (e.g. linguistics, NLP, computer science). This paper discusses these points, and deals with the methodological aspects in order to identify co-occurrences in a multidisciplinary paradigm.",
        "entry_id": "http://arxiv.org/abs/1904.08010v1",
        "pub_date": "2019-04-16",
        "translated_summary": "本立场文件对共现关系展开了一项比较研究。根据研究领域（如语言学、自然语言处理、计算机科学）的不同，其定义存在若干异同之处。本文通过多学科范式探讨这些要点，并论述识别共现关系的方法论层面。"
    },
    {
        "title": "Neural Message Passing for Multi-Label Classification",
        "summary": "Multi-label classification (MLC) is the task of assigning a set of target labels for a given sample. Modeling the combinatorial label interactions in MLC has been a long-haul challenge. We propose Label Message Passing (LaMP) Neural Networks to efficiently model the joint prediction of multiple labels. LaMP treats labels as nodes on a label-interaction graph and computes the hidden representation of each label node conditioned on the input using attention-based neural message passing. Attention enables LaMP to assign different importance to neighbor nodes per label, learning how labels interact (implicitly). The proposed models are simple, accurate, interpretable, structure-agnostic, and applicable for predicting dense labels since LaMP is incredibly parallelizable. We validate the benefits of LaMP on seven real-world MLC datasets, covering a broad spectrum of input/output types and outperforming the state-of-the-art results. Notably, LaMP enables intuitive interpretation of how classifying each label depends on the elements of a sample and at the same time rely on its interaction with other labels. We provide our code and datasets at https://github.com/QData/LaMP",
        "entry_id": "http://arxiv.org/abs/1904.08049v1",
        "pub_date": "2019-04-17",
        "translated_summary": "多标签分类任务旨在为给定样本分配一组目标标签，而如何建模标签间的组合交互关系一直是该领域的长期挑战。我们提出标签消息传递神经网络，通过基于注意力机制的神经消息传递技术，将标签视为标签交互图中的节点，并基于输入计算每个标签节点的隐表示。注意力机制使模型能够为每个标签的相邻节点分配不同权重，从而隐式学习标签间的交互规律。该模型结构简洁、预测精准、可解释性强，且不依赖特定图结构——由于具备高度并行化特性，尤其适用于密集标签预测场景。我们在七个真实多标签数据集上验证了LaMP的优越性，这些数据集覆盖多种输入/输出类型，实验结果表明其性能超越现有最优方法。值得注意的是，LaMP能直观展示每个标签的分类决策如何依赖于样本特征元素，同时揭示其与其他标签的交互依赖关系。代码与数据集已开源：https://github.com/QData/LaMP"
    },
    {
        "title": "Emotional Contribution Analysis of Online Reviews",
        "summary": "In response to the constant increase in population and tourism worldwide, there is a need for the development of cross-language market research tools that are more cost and time effective than surveys or interviews. Focusing on the Chinese tourism boom and the hotel industry in Japan, we extracted the most influential keywords in emotional judgement from Chinese online reviews of Japanese hotels in the portal site Ctrip. Using an entropy based mathematical model and a machine learning algorithm, we determined the words that most closely represent the demands and emotions of this customer base.",
        "entry_id": "http://arxiv.org/abs/1905.00185v1",
        "pub_date": "2019-05-01",
        "translated_summary": "针对全球人口与旅游业的持续增长，亟需开发比传统问卷和访谈更具成本与时间效益的跨语言市场调研工具。本研究聚焦中国游客赴日旅游热潮及日本酒店业，通过携程网中文评论数据，运用基于信息熵的数学模型与机器学习算法，从中国游客对日本酒店的在线评价中提取情感判断最具影响力的关键词，精准识别该客群的核心需求与情感倾向。"
    },
    {
        "title": "FAQ Retrieval using Query-Question Similarity and BERT-Based Query-Answer Relevance",
        "summary": "Frequently Asked Question (FAQ) retrieval is an important task where the objective is to retrieve an appropriate Question-Answer (QA) pair from a database based on a user's query. We propose a FAQ retrieval system that considers the similarity between a user's query and a question as well as the relevance between the query and an answer. Although a common approach to FAQ retrieval is to construct labeled data for training, it takes annotation costs. Therefore, we use a traditional unsupervised information retrieval system to calculate the similarity between the query and question. On the other hand, the relevance between the query and answer can be learned by using QA pairs in a FAQ database. The recently-proposed BERT model is used for the relevance calculation. Since the number of QA pairs in FAQ page is not enough to train a model, we cope with this issue by leveraging FAQ sets that are similar to the one in question. We evaluate our approach on two datasets. The first one is localgovFAQ, a dataset we construct in a Japanese administrative municipality domain. The second is StackExchange dataset, which is the public dataset in English. We demonstrate that our proposed method outperforms baseline methods on these datasets.",
        "entry_id": "http://arxiv.org/abs/1905.02851v2",
        "pub_date": "2019-05-08",
        "translated_summary": "常见问题解答检索是一项重要任务，其目标是根据用户查询从数据库中检索出相应的问题-答案对。我们提出了一种FAQ检索系统，该系统同时考虑用户查询与问题的相似度，以及查询与答案的相关性。尽管构建标注数据进行训练是FAQ检索的常用方法，但标注成本较高。因此，我们采用传统无监督信息检索系统来计算查询与问题的相似度。另一方面，查询与答案的相关性可以通过使用FAQ数据库中的问答对进行学习。我们采用最新提出的BERT模型进行相关性计算。由于FAQ页面中的问答对数量不足以训练模型，我们通过利用与目标FAQ集相似的FAQ集合来解决这一问题。我们在两个数据集上评估了该方法：第一个是本地政务FAQ数据集，这是我们在日本行政市政领域构建的数据集；第二个是StackExchange公共英文数据集。实验证明，我们提出的方法在这两个数据集上均优于基线方法。"
    },
    {
        "title": "Who wrote this book? A challenge for e-commerce",
        "summary": "Modern e-commerce catalogs contain millions of references, associated with textual and visual information that is of paramount importance for the products to be found via search or browsing. Of particular significance is the book category, where the author name(s) field poses a significant challenge. Indeed, books written by a given author (such as F. Scott Fitzgerald) might be listed with different authors' names in a catalog due to abbreviations and spelling variants and mistakes, among others. To solve this problem at scale, we design a composite system involving open data sources for books as well as machine learning components leveraging deep learning-based techniques for natural language processing. In particular, we use Siamese neural networks for an approximate match with known author names, and direct correction of the provided author's name using sequence-to-sequence learning with neural networks. We evaluate this approach on product data from the e-commerce website Rakuten France, and find that the top proposal of the system is the normalized author name with 72% accuracy.",
        "entry_id": "http://arxiv.org/abs/1905.01973v1",
        "pub_date": "2019-04-19",
        "translated_summary": "现代电子商务目录包含数百万种商品，其关联的文本与视觉信息对于用户通过搜索或浏览找到产品至关重要。其中图书类目的作者名字段尤为特殊——同一作者（如F·斯科特·菲茨杰拉德）的著作可能因缩写、拼写变体或错误等原因在目录中呈现不同作者名称。为大规模解决该问题，我们设计了一套复合系统：既整合图书开放数据源，又采用基于深度学习的自然语言处理技术。具体通过孪生神经网络实现与已知作者名的近似匹配，并利用神经网络序列到序列学习直接校正现有作者名。基于法国乐天电商平台产品数据的测试显示，该系统首选建议的标准化作者名准确率达72%。"
    },
    {
        "title": "A Content-Based Approach to Email Triage Action Prediction: Exploration and Evaluation",
        "summary": "Email has remained a principal form of communication among people, both in enterprise and social settings. With a deluge of emails crowding our mailboxes daily, there is a dire need of smart email systems that can recover important emails and make personalized recommendations. In this work, we study the problem of predicting user triage actions to incoming emails where we take the reply prediction as a working example. Different from existing methods, we formulate the triage action prediction as a recommendation problem and focus on the content-based approach, where the users are represented using the content of current and past emails. We also introduce additional similarity features to further explore the affinities between users and emails. Experiments on the publicly available Avocado email collection demonstrate the advantages of our proposed recommendation framework and our method is able to achieve better performance compared to the state-of-the-art deep recommendation methods. More importantly, we provide valuable insight into the effectiveness of different textual and user representations and show that traditional bag-of-words approaches, with the help from the similarity features, compete favorably with the more advanced neural embedding methods.",
        "entry_id": "http://arxiv.org/abs/1905.01991v1",
        "pub_date": "2019-04-30",
        "translated_summary": "电子邮件始终是企业和社交场景中人们沟通的主要方式。面对每日涌入收件箱的海量邮件，智能邮件系统亟需实现重要邮件恢复与个性化推荐功能。本文以回复预测为例，研究用户对接收邮件的分类行为预测问题。与现有方法不同，我们将分类行为预测构建为推荐问题，聚焦于基于内容的研究方法——通过当前及历史邮件内容构建用户画像。通过引入额外相似性特征，进一步挖掘用户与邮件之间的关联性。在公开的Avocado邮件数据集上的实验表明，我们提出的推荐框架具有显著优势，相较当前最先进的深度推荐方法能获得更优性能。更重要的是，我们揭示了不同文本表征和用户表征方法的有效性，并证明传统词袋模型在相似性特征辅助下，可与更先进的神经嵌入方法相媲美。"
    },
    {
        "title": "Deep Landscape Forecasting for Real-time Bidding Advertising",
        "summary": "The emergence of real-time auction in online advertising has drawn huge attention of modeling the market competition, i.e., bid landscape forecasting. The problem is formulated as to forecast the probability distribution of market price for each ad auction. With the consideration of the censorship issue which is caused by the second-price auction mechanism, many researchers have devoted their efforts on bid landscape forecasting by incorporating survival analysis from medical research field. However, most existing solutions mainly focus on either counting-based statistics of the segmented sample clusters, or learning a parameterized model based on some heuristic assumptions of distribution forms. Moreover, they neither consider the sequential patterns of the feature over the price space. In order to capture more sophisticated yet flexible patterns at fine-grained level of the data, we propose a Deep Landscape Forecasting (DLF) model which combines deep learning for probability distribution forecasting and survival analysis for censorship handling. Specifically, we utilize a recurrent neural network to flexibly model the conditional winning probability w.r.t. each bid price. Then we conduct the bid landscape forecasting through probability chain rule with strict mathematical derivations. And, in an end-to-end manner, we optimize the model by minimizing two negative likelihood losses with comprehensive motivations. Without any specific assumption for the distribution form of bid landscape, our model shows great advantages over previous works on fitting various sophisticated market price distributions. In the experiments over two large-scale real-world datasets, our model significantly outperforms the state-of-the-art solutions under various metrics.",
        "entry_id": "http://arxiv.org/abs/1905.03028v2",
        "pub_date": "2019-05-07",
        "translated_summary": "在线广告实时竞价的出现，使得市场竞争建模（即竞价环境预测）受到广泛关注。该问题可表述为预测每次广告竞价市场价格的概率分布。针对第二价格拍卖机制导致的数据截断问题，众多研究者借鉴医学领域的生存分析方法开展竞价环境预测研究。然而现有解决方案大多聚焦于分段样本群的计数统计，或基于分布形式的启发式假设学习参数化模型，且均未考虑特征在价格空间上的序列模式。为在细粒度数据层面捕捉更复杂灵活的模式，我们提出深度融合竞价环境预测模型，将深度学习与生存分析相结合进行概率分布预测与截断数据处理。具体而言，我们利用循环神经网络灵活建模各出价价格对应的条件获胜概率，继而通过概率链式法则进行严格数学推导来实现竞价环境预测。以端到端方式，我们通过最小化两个具有综合动机的负似然损失函数来优化模型。该模型无需对竞价环境分布形式做特定假设，在拟合各类复杂市场价格分布方面较已有工作展现出显著优势。基于两个大规模真实数据集的实验表明，我们的模型在多项指标上均显著优于现有最优解决方案。"
    },
    {
        "title": "A Novel Fuzzy Search Approach over Encrypted Data with Improved Accuracy and Efficiency",
        "summary": "As cloud computing becomes prevalent in recent years, more and more enterprises and individuals outsource their data to cloud servers. To avoid privacy leaks, outsourced data usually is encrypted before being sent to cloud servers, which disables traditional search schemes for plain text. To meet both end of security and searchability, search-supported encryption is proposed. However, many previous schemes suffer severe vulnerability when typos and semantic diversity exist in query requests. To overcome such flaw, higher error-tolerance is always expected for search-supported encryption design, sometimes defined as 'fuzzy search'. In this paper, we propose a new scheme of multi-keyword fuzzy search over encrypted and outsourced data. Our approach introduces a new mechanism to map a natural language expression into a word-vector space. Compared with previous approaches, our design shows higher robustness when multiple kinds of typos are involved. Besides, our approach is enhanced with novel data structures to improve search efficiency. These two innovations can work well for both accuracy and efficiency. Moreover, these designs will not hurt the fundamental security. Experiments on a real-world dataset demonstrate the effectiveness of our proposed approach, which outperforms currently popular approaches focusing on similar tasks.",
        "entry_id": "http://arxiv.org/abs/1904.12111v2",
        "pub_date": "2019-04-27",
        "translated_summary": "近年来，随着云计算的普及，越来越多的企业和个人将数据外包至云服务器。为防止隐私泄露，外包数据通常会在上传至云端前进行加密处理，但这使得传统明文搜索方案无法适用。为实现安全性与可搜索性的统一，可搜索加密技术应运而生。然而，现有方案在查询请求存在拼写错误或语义多样性时存在明显缺陷。为克服这一不足，可搜索加密设计需要具备更高的容错能力，即实现\"模糊搜索\"。本文提出一种支持多关键词模糊搜索的加密外包数据查询方案。该方案创新性地通过词向量空间映射自然语言表达，相较于现有方案，在应对多种拼写错误时展现出更强的鲁棒性。同时，我们采用新型数据结构提升搜索效率，这两项创新在保证准确率的同时显著提升性能，且不会损害基础安全性。在真实数据集上的实验表明，本方案在同等任务中的表现优于当前主流方案。"
    },
    {
        "title": "Topic Classification Method for Analyzing Effect of eWOM on Consumer Game Sales",
        "summary": "Electronic word-of-mouth (eWOM) has become an important resource for the analysis of marketing research. In this study, in order to analyze user needs for consumer game software, we focus on tweet data. And we proposed topic extraction method using entropy-based feature selection based feature expansion. We also applied it to the classification of the data extracted from tweet data by using SVM. As a result, we achieved a 0.63 F-measure.",
        "entry_id": "http://arxiv.org/abs/1904.13213v1",
        "pub_date": "2019-04-23",
        "translated_summary": "电子口碑已成为营销调研分析的重要资源。为探究消费者对游戏软件的需求特性，本研究以推文数据为分析对象，提出基于熵特征选择与特征扩展的主题挖掘方法，并采用支持向量机对推文数据进行分类处理。实验结果显示，该方法的F值评估指标达到0.63。"
    },
    {
        "title": "Advanced Customer Activity Prediction based on Deep Hierarchic Encoder-Decoders",
        "summary": "Product recommender systems and customer profiling techniques have always been a priority in online retail. Recent machine learning research advances and also wide availability of massive parallel numerical computing has enabled various approaches and directions of recommender systems advancement. Worth to mention is the fact that in past years multiple traditional \"offline\" retail business are gearing more and more towards employing inferential and even predictive analytics both to stock-related problems such as predictive replenishment but also to enrich customer interaction experience. One of the most important areas of recommender systems research and development is that of Deep Learning based models which employ representational learning to model consumer behavioral patterns. Current state of the art in Deep Learning based recommender systems uses multiple approaches ranging from already classical methods such as the ones based on learning product representation vector, to recurrent analysis of customer transactional time-series and up to generative models based on adversarial training. Each of these methods has multiple advantages and inherent weaknesses such as inability of understanding the actual user-journey, ability to propose only single product recommendation or top-k product recommendations without prediction of actual next-best-offer. In our work we will present a new and innovative architectural approach of applying state-of-the-art hierarchical multi-module encoder-decoder architecture in order to solve several of current state-of-the-art recommender systems issues. Our approach will also produce by-products such as product need-based segmentation and customer behavioral segmentation - all in an end-to-end trainable approach. Finally, we will present a couple methods that solve known retail & distribution pain-points based on the proposed architecture.",
        "entry_id": "http://arxiv.org/abs/1904.07687v4",
        "pub_date": "2019-04-11",
        "translated_summary": "商品推荐系统与用户画像技术始终是在线零售领域的关注焦点。随着机器学习研究的最新进展以及大规模并行数值计算的广泛普及，推荐系统的发展呈现出多元化趋势。值得注意的是，近年来众多传统线下零售企业正越来越多地运用推断性甚至预测性分析技术，不仅将其应用于库存管理（如预测性补货），更致力于提升客户交互体验。基于深度学习的推荐模型通过表征学习来构建消费者行为模式，已成为该领域的重要研究方向。当前最先进的深度学习推荐系统融合了多种技术路径：既包含基于商品表征向量学习的经典方法，也涵盖客户交易时间序列的循环分析，更延伸至基于对抗训练的生成模型。这些方法虽各具优势，却也存在固有缺陷——例如无法真正理解用户行为路径、仅能推荐单一商品或Top-K商品列表而无法预测真正意义上的\"下一个最佳优惠\"。本研究提出了一种创新的层次化多模块编码器-解码器架构，旨在解决现有推荐系统的若干痛点。该端到端可训练架构不仅能实现核心推荐功能，还将自然衍生出基于需求的产品细分和客户行为细分等副产品。最后，我们将基于该架构提出若干解决零售分销领域典型痛点的方法论。"
    },
    {
        "title": "Short Text Topic Modeling Techniques, Applications, and Performance: A Survey",
        "summary": "Analyzing short texts infers discriminative and coherent latent topics that is a critical and fundamental task since many real-world applications require semantic understanding of short texts. Traditional long text topic modeling algorithms (e.g., PLSA and LDA) based on word co-occurrences cannot solve this problem very well since only very limited word co-occurrence information is available in short texts. Therefore, short text topic modeling has already attracted much attention from the machine learning research community in recent years, which aims at overcoming the problem of sparseness in short texts. In this survey, we conduct a comprehensive review of various short text topic modeling techniques proposed in the literature. We present three categories of methods based on Dirichlet multinomial mixture, global word co-occurrences, and self-aggregation, with example of representative approaches in each category and analysis of their performance on various tasks. We develop the first comprehensive open-source library, called STTM, for use in Java that integrates all surveyed algorithms within a unified interface, benchmark datasets, to facilitate the expansion of new methods in this research field. Finally, we evaluate these state-of-the-art methods on many real-world datasets and compare their performance against one another and versus long text topic modeling algorithm.",
        "entry_id": "http://arxiv.org/abs/1904.07695v1",
        "pub_date": "2019-04-13",
        "translated_summary": "短文本分析旨在推断出具有判别力且连贯的潜在主题，这是一项关键的基础性任务，因为众多实际应用都需要对短文本进行语义理解。基于词语共现的传统长文本主题建模算法（如PLSA和LDA）难以有效解决该问题，因为短文本中可用的词语共现信息极其有限。因此，旨在克服短文本稀疏性问题的主题建模技术近年来备受机器学习研究界关注。本文系统综述了文献中提出的各类短文本主题建模方法，将其划分为基于狄利克雷多项混合、全局词语共现和自聚合三大类方法，通过典型算法示例分析其在各任务中的性能表现。我们开发了首个综合性开源工具包STTM（基于Java语言），该工具集成了所有综述算法与基准数据集，采用统一接口以促进该研究领域新方法的拓展。最后，我们在多个真实数据集上评估了这些前沿方法，通过纵向对比与长文本主题建模算法的横向比较，全面验证其性能表现。"
    },
    {
        "title": "Don't Waste It: Guiding Generative Recommenders with Structured Human Priors via Multi-head Decoding",
        "summary": "Optimizing recommender systems for objectives beyond accuracy, such as diversity, novelty, and personalization, is crucial for long-term user satisfaction. To this end, industrial practitioners have accumulated vast amounts of structured domain knowledge, which we term human priors (e.g., item taxonomies, temporal patterns). This knowledge is typically applied through post-hoc adjustments during ranking or post-ranking. However, this approach remains decoupled from the core model learning, which is particularly undesirable as the industry shifts to end-to-end generative recommendation foundation models. On the other hand, many methods targeting these beyond-accuracy objectives often require architecture-specific modifications and discard these valuable human priors by learning user intent in a fully unsupervised manner.\n  Instead of discarding the human priors accumulated over years of practice, we introduce a backbone-agnostic framework that seamlessly integrates these human priors directly into the end-to-end training of generative recommenders. With lightweight, prior-conditioned adapter heads inspired by efficient LLM decoding strategies, our approach guides the model to disentangle user intent along human-understandable axes (e.g., interaction types, long- vs. short-term interests). We also introduce a hierarchical composition strategy for modeling complex interactions across different prior types. Extensive experiments on three large-scale datasets demonstrate that our method significantly enhances both accuracy and beyond-accuracy objectives. We also show that human priors allow the backbone model to more effectively leverage longer context lengths and larger model sizes.",
        "entry_id": "http://arxiv.org/abs/2511.10492v1",
        "pub_date": "2025-11-13",
        "translated_summary": "在推荐系统中，除了准确性之外，针对多样性、新颖性和个性化等目标的优化对长期用户满意度至关重要。工业实践者已积累了大量结构化领域知识，我们将其称为\"人类先验\"（如物品分类体系、时序模式）。这类知识通常通过排名阶段或后排名阶段的后期调整来应用，但这种方法始终与核心模型学习相分离——随着行业向端到端生成式推荐基础模型转型，这种分离尤为不利。另一方面，许多针对超准确性目标的方法往往需要针对特定架构进行修改，并以完全无监督的方式学习用户意图，从而丢弃了这些宝贵的人类先验。\n\n我们提出了一种与主干模型无关的框架，将多年实践积累的人类先验直接整合到生成式推荐器的端到端训练中，而非抛弃这些知识。受高效大语言模型解码策略启发，我们通过轻量级的先验条件适配头，引导模型沿着人类可理解的维度（如交互类型、长短期兴趣）解耦用户意图。同时引入了分层组合策略来建模不同先验类型间的复杂交互。在三个大规模数据集上的实验表明，我们的方法显著提升了准确性及超准确性目标。研究还证实，人类先验能使主干模型更有效地利用更长上下文和更大模型规模。"
    },
    {
        "title": "Fixed-Persona SLMs with Modular Memory: Scalable NPC Dialogue on Consumer Hardware",
        "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in generating human-like text, yet their applicability to dialogue systems in computer games remains limited. This limitation arises from their substantial hardware requirements, latency constraints, and the necessity to maintain clearly defined knowledge boundaries within a game setting. In this paper, we propose a modular NPC dialogue system that leverages Small Language Models (SLMs), fine-tuned to encode specific NPC personas and integrated with runtime-swappable memory modules. These memory modules preserve character-specific conversational context and world knowledge, enabling expressive interactions and long-term memory without retraining or model reloading during gameplay. We comprehensively evaluate our system using three open-source SLMs: DistilGPT-2, TinyLlama-1.1B-Chat, and Mistral-7B-Instruct, trained on synthetic persona-aligned data and benchmarked on consumer-grade hardware. While our approach is motivated by applications in gaming, its modular design and persona-driven memory architecture hold significant potential for broader adoption in domains requiring expressive, scalable, and memory-rich conversational agents, such as virtual assistants, customer support bots, or interactive educational systems.",
        "entry_id": "http://arxiv.org/abs/2511.10277v1",
        "pub_date": "2025-11-13",
        "translated_summary": "大型语言模型在生成类人文本方面展现出卓越能力，但在计算机游戏对话系统中的应用仍存在局限。这主要源于其较高的硬件需求、延迟限制，以及游戏场景中需保持明确知识边界的必要性。本文提出一种模块化非玩家角色对话系统，通过微调小型语言模型来编码特定角色特征，并与可实时切换的记忆模块相结合。这些记忆模块能够保存角色专属的对话上下文和世界知识，无需在游戏过程中重新训练或加载模型，即可实现富有表现力的交互和长期记忆功能。我们使用三种开源小型语言模型进行系统评估：DistilGPT-2、TinyLlama-1.1B-Chat和Mistral-7B-Instruct，这些模型基于合成的角色对齐数据训练，并在消费级硬件上进行基准测试。虽然该研究受游戏应用驱动，但其模块化设计和角色驱动的记忆架构，对于需要表现力丰富、可扩展且具备深度记忆的对话代理场景具有广泛适用潜力，例如虚拟助手、客服机器人或交互式教育系统等领域。"
    },
    {
        "title": "GPR: Towards a Generative Pre-trained One-Model Paradigm for Large-Scale Advertising Recommendation",
        "summary": "As an intelligent infrastructure connecting users with commercial content, advertising recommendation systems play a central role in information flow and value creation within the digital economy. However, existing multi-stage advertising recommendation systems suffer from objective misalignment and error propagation, making it difficult to achieve global optimality, while unified generative recommendation models still struggle to meet the demands of practical industrial applications. To address these issues, we propose GPR (Generative Pre-trained Recommender), the first one-model framework that redefines advertising recommendation as an end-to-end generative task, replacing the traditional cascading paradigm with a unified generative approach. To realize GPR, we introduce three key innovations spanning unified representation, network architecture, and training strategy. First, we design a unified input schema and tokenization method tailored to advertising scenarios, mapping both ads and organic content into a shared multi-level semantic ID space, thereby enhancing semantic alignment and modeling consistency across heterogeneous data. Second, we develop the Heterogeneous Hierarchical Decoder (HHD), a dual-decoder architecture that decouples user intent modeling from ad generation, achieving a balance between training efficiency and inference flexibility while maintaining strong modeling capacity. Finally, we propose a multi-stage joint training strategy that integrates Multi-Token Prediction (MTP), Value-Aware Fine-Tuning and the Hierarchy Enhanced Policy Optimization (HEPO) algorithm, forming a complete generative recommendation pipeline that unifies interest modeling, value alignment, and policy optimization. GPR has been fully deployed in the Tencent Weixin Channels advertising system, delivering significant improvements in key business metrics including GMV and CTCVR.",
        "entry_id": "http://arxiv.org/abs/2511.10138v1",
        "pub_date": "2025-11-13",
        "translated_summary": "作为连接用户与商业内容的智能枢纽，广告推荐系统在数字经济的信息流通与价值创造中占据核心地位。然而现有多阶段广告推荐系统存在目标错位与误差累积问题，难以实现全局最优；而统一生成式推荐模型在实际工业应用中仍面临诸多挑战。为此，我们提出GPR（生成式预训练推荐系统），首次通过单模型框架将广告推荐重新定义为端到端生成任务，以统一生成范式替代传统级联架构。为实现该框架，我们在统一表征、网络架构和训练策略三大维度实现创新突破：首先设计面向广告场景的统一输入范式与令牌化方法，将广告与自然内容映射至共享的多层级语义ID空间，增强异构数据的语义对齐与建模一致性；其次构建异质层级解码器（HHD），通过双流解码架构分离用户意图建模与广告生成路径，在保持强大建模能力的同时实现训练效率与推理灵活性的平衡；最终提出融合多令牌预测（MTP）、价值感知微调与层级增强策略优化（HEPO）算法的多阶段联合训练策略，形成统一兴趣建模、价值对齐与策略优化的完整生成式推荐链路。GPR已在腾讯微信视频号广告系统全面部署，在GMV、CTCVR等关键业务指标上取得显著提升。"
    },
    {
        "title": "Practical RAG Evaluation: A Rarity-Aware Set-Based Metric and Cost-Latency-Quality Trade-offs",
        "summary": "This paper addresses the guessing game in building production RAG. Classical rank-centric IR metrics (nDCG/MAP/MRR) are a poor fit for RAG, where LLMs consume a set of passages rather than a browsed list; position discounts and prevalence-blind aggregation miss what matters: whether the prompt at cutoff K contains the decisive evidence. Second, there is no standardized, reproducible way to build and audit golden sets. Third, leaderboards exist but lack end-to-end, on-corpus benchmarking that reflects production trade-offs. Fourth, how state-of-the-art embedding models handle proper-name identity signals and conversational noise remains opaque. To address these, we contribute: (1) RA-nWG@K, a rarity-aware, per-query-normalized set score, and operational ceilings via the pool-restricted oracle ceiling (PROC) and the percentage of PROC (%PROC) to separate retrieval from ordering headroom within a Cost-Latency-Quality (CLQ) lens; (2) rag-gs (MIT), a lean golden-set pipeline with Plackett-Luce listwise refinement whose iterative updates outperform single-shot LLM ranking; (3) a comprehensive benchmark on a production RAG (scientific-papers corpus) spanning dense retrieval, hybrid dense+BM25, embedding models and dimensions, cross-encoder rerankers, ANN (HNSW), and quantization; and (4) targeted diagnostics that quantify proper-name identity signal and conversational-noise sensitivity via identity-destroying and formatting ablations. Together, these components provide practitioner Pareto guidance and auditable guardrails to support reproducible, budget/SLA-aware decisions.",
        "entry_id": "http://arxiv.org/abs/2511.09545v1",
        "pub_date": "2025-11-12",
        "translated_summary": "本文针对生产环境RAG构建中的评估难题展开研究。传统以排序为核心的信息检索指标（nDCG/MAP/MRR）与RAG场景存在根本性错配——大语言模型处理的是段落集合而非浏览列表，位置衰减和忽略证据分布的聚合方式无法捕捉核心问题：截断点K处的提示是否包含决定性证据。其次，当前缺乏标准化、可复现的黄金集构建与审计方法。再者，现有排行榜缺少反映生产环境权衡的端到端全库基准。最后，前沿嵌入模型如何处理专有名词标识信号与会话噪声仍不透明。为此我们提出：(1) RA-nWG@K——一种稀有度感知的查询归一化集合评分指标，通过池限制理论上限(PROC)及其百分比(%PROC)在成本-延迟-质量(CLQ)框架下区分检索能力与排序潜力；(2) rag-gs(MIT授权)——采用Plackett-Luce列表优化的轻量级黄金集流程，其迭代更新优于单次LLM排序；(3) 基于科学论文库的生产级RAG综合基准，覆盖稠密检索、混合检索、嵌入模型与维度、交叉编码器重排序、近似最近邻(HNSW)及量化技术；(4) 通过身份标识破坏与格式消融实验，量化专有名词标识信号处理能力与会话噪声敏感性。这些组件共同为实践者提供帕累托决策指导与可审计防护，支持符合预算与服务等级协议的可复现决策。"
    },
    {
        "title": "Sim4IA-Bench: A User Simulation Benchmark Suite for Next Query and Utterance Prediction",
        "summary": "Validating user simulation is a difficult task due to the lack of established measures and benchmarks, which makes it challenging to assess whether a simulator accurately reflects real user behavior. As part of the Sim4IA Micro-Shared Task at the Sim4IA Workshop, SIGIR 2025, we present Sim4IA-Bench, a simulation benchmark suit for the prediction of the next queries and utterances, the first of its kind in the IR community. Our dataset as part of the suite comprises 160 real-world search sessions from the CORE search engine. For 70 of these sessions, up to 62 simulator runs are available, divided into Task A and Task B, in which different approaches predicted users next search queries or utterances. Sim4IA-Bench provides a basis for evaluating and comparing user simulation approaches and for developing new measures of simulator validity. Although modest in size, the suite represents the first publicly available benchmark that links real search sessions with simulated next-query predictions. In addition to serving as a testbed for next query prediction, it also enables exploratory studies on query reformulation behavior, intent drift, and interaction-aware retrieval evaluation. We also introduce a new measure for evaluating next-query predictions in this task. By making the suite publicly available, we aim to promote reproducible research and stimulate further work on realistic and explainable user simulation for information access: https://github.com/irgroup/Sim4IA-Bench.",
        "entry_id": "http://arxiv.org/abs/2511.09329v1",
        "pub_date": "2025-11-12",
        "translated_summary": "由于缺乏成熟的衡量标准与基准，用户模拟验证始终是一项困难的任务，这使得评估模拟器是否准确反映真实用户行为充满挑战。作为SIGIR 2025 Sim4IA研讨会微共享任务环节的一部分，我们推出首个信息检索领域针对下一查询与对话预测的仿真基准套件Sim4IA-Bench。该套件中的数据集包含来自CORE搜索引擎的160个真实搜索会话，其中70个会话提供多达62次模拟运行数据，分为任务A与任务B，分别对应不同方法对用户后续搜索查询或对话的预测。Sim4IA-Bench为评估比较用户模拟方法及开发新型模拟器效度指标奠定了基础。尽管规模适中，但这是首个公开连接真实搜索会话与模拟下一查询预测的基准套件。除作为下一查询预测测试平台外，它还可支持查询重构行为、意图漂移及交互感知检索评估的探索性研究。我们还为此任务引入新的下一查询预测评估指标。通过开源此套件，我们旨在推动可复现研究，并促进面向信息访问的逼真可解释用户模拟工作：https://github.com/irgroup/Sim4IA-Bench。"
    },
    {
        "title": "NeuroCLIP: Brain-Inspired Prompt Tuning for EEG-to-Image Multimodal Contrastive Learning",
        "summary": "Recent advances in brain-inspired artificial intelligence have sought to align neural signals with visual semantics using multimodal models such as CLIP. However, existing methods often treat CLIP as a static feature extractor, overlooking its adaptability to neural representations and the inherent physiological-symbolic gap in EEG-image alignment. To address these challenges, we present NeuroCLIP, a prompt tuning framework tailored for EEG-to-image contrastive learning. Our approach introduces three core innovations: (1) We design a dual-stream visual embedding pipeline that combines dynamic filtering and token-level fusion to generate instance-level adaptive prompts, which guide the adjustment of patch embedding tokens based on image content, thereby enabling fine-grained modulation of visual representations under neural constraints; (2) We are the first to introduce visual prompt tokens into EEG-image alignment, acting as global, modality-level prompts that work in conjunction with instance-level adjustments. These visual prompt tokens are inserted into the Transformer architecture to facilitate neural-aware adaptation and parameter optimization at a global level; (3) Inspired by neuroscientific principles of human visual encoding, we propose a refined contrastive loss that better model the semantic ambiguity and cross-modal noise present in EEG signals. On the THINGS-EEG2 dataset, NeuroCLIP achieves a Top-1 accuracy of 63.2% in zero-shot image retrieval, surpassing the previous best method by +12.3%, and demonstrates strong generalization under inter-subject conditions (+4.6% Top-1), highlighting the potential of physiology-aware prompt tuning for bridging brain signals and visual semantics.",
        "entry_id": "http://arxiv.org/abs/2511.09250v1",
        "pub_date": "2025-11-12",
        "translated_summary": "受脑启发人工智能领域的最新进展试图利用CLIP等多模态模型将神经信号与视觉语义对齐。然而现有方法通常将CLIP视为静态特征提取器，忽视了其对神经表征的适应性以及EEG-图像对齐中固有的生理-符号鸿沟。为解决这些挑战，我们提出NeuroCLIP——一个专为EEG-图像对比学习设计的提示调优框架。该框架包含三项核心创新：(1) 设计双流视觉嵌入管道，结合动态过滤与令牌级融合生成实例级自适应提示，通过图像内容指导图像块嵌入令牌的调整，实现神经约束下的视觉表征细粒度调制；(2) 首次将视觉提示令牌引入EEG-图像对齐，作为全局模态级提示与实例级调整协同工作，这些令牌被嵌入Transformer架构以促进神经感知的全局适应与参数优化；(3) 受人类视觉编码神经科学原理启发，提出改进的对比损失函数，更精准建模EEG信号中的语义歧义与跨模态噪声。在THINGS-EEG2数据集上，NeuroCLIP在零样本图像检索任务中达到63.2%的Top-1准确率，较此前最佳方法提升12.3%，并在跨被试条件下展现出强大泛化能力（Top-1提升4.6%），彰显了生理感知提示调优在连接大脑信号与视觉语义方面的巨大潜力。"
    },
    {
        "title": "Thinking Forward and Backward: Multi-Objective Reinforcement Learning for Retrieval-Augmented Reasoning",
        "summary": "Retrieval-augmented generation (RAG) has proven to be effective in mitigating hallucinations in large language models, yet its effectiveness remains limited in complex, multi-step reasoning scenarios. Recent efforts have incorporated search-based interactions into RAG, enabling iterative reasoning with real-time retrieval. Most approaches rely on outcome-based supervision, offering no explicit guidance for intermediate steps. This often leads to reward hacking and degraded response quality. We propose Bi-RAR, a novel retrieval-augmented reasoning framework that evaluates each intermediate step jointly in both forward and backward directions. To assess the information completeness of each step, we introduce a bidirectional information distance grounded in Kolmogorov complexity, approximated via language model generation probabilities. This quantification measures both how far the current reasoning is from the answer and how well it addresses the question. To optimize reasoning under these bidirectional signals, we adopt a multi-objective reinforcement learning framework with a cascading reward structure that emphasizes early trajectory alignment. Empirical results on seven question answering benchmarks demonstrate that Bi-RAR surpasses previous methods and enables efficient interaction and reasoning with the search engine during training and inference.",
        "entry_id": "http://arxiv.org/abs/2511.09109v2",
        "pub_date": "2025-11-12",
        "translated_summary": "检索增强生成技术虽已被证实能有效缓解大语言模型的幻觉问题，但在复杂多步推理场景中的效能仍显不足。近期研究将基于搜索的交互机制融入RAG，实现了实时检索的迭代推理。然而现有方法多依赖结果监督，未能对中间步骤提供明确指导，易导致奖励破解和回答质量下降。我们提出双向检索增强推理框架Bi-RAR，通过前向与后向联合评估每个推理步骤。为衡量各步骤的信息完备性，基于柯氏复杂度构建了双向信息距离指标，并借助语言模型生成概率进行近似计算。该量化方法既能评估当前推理与答案的距离，又可衡量其对问题的解答程度。在此双向信号优化方面，采用具有级联奖励结构的多目标强化学习框架，重点强化早期轨迹对齐。在七个问答基准测试中的实证结果表明，Bi-RAR不仅超越现有方法，还能在训练与推理过程中实现与搜索引擎的高效交互推理。"
    },
    {
        "title": "Efficient Model-Agnostic Continual Learning for Next POI Recommendation",
        "summary": "Next point-of-interest (POI) recommendation improves personalized location-based services by predicting users' next destinations based on their historical check-ins. However, most existing methods rely on static datasets and fixed models, limiting their ability to adapt to changes in user behavior over time. To address this limitation, we explore a novel task termed continual next POI recommendation, where models dynamically adapt to evolving user interests through continual updates. This task is particularly challenging, as it requires capturing shifting user behaviors while retaining previously learned knowledge. Moreover, it is essential to ensure efficiency in update time and memory usage for real-world deployment. To this end, we propose GIRAM (Generative Key-based Interest Retrieval and Adaptive Modeling), an efficient, model-agnostic framework that integrates context-aware sustained interests with recent interests. GIRAM comprises four components: (1) an interest memory to preserve historical preferences; (2) a context-aware key encoding module for unified interest key representation; (3) a generative key-based retrieval module to identify diverse and relevant sustained interests; and (4) an adaptive interest update and fusion module to update the interest memory and balance sustained and recent interests. In particular, GIRAM can be seamlessly integrated with existing next POI recommendation models. Experiments on three real-world datasets demonstrate that GIRAM consistently outperforms state-of-the-art methods while maintaining high efficiency in both update time and memory consumption.",
        "entry_id": "http://arxiv.org/abs/2511.08941v1",
        "pub_date": "2025-11-12",
        "translated_summary": "下一兴趣点推荐通过用户历史签到记录预测其下一个目的地，从而提升个性化基于位置的服务质量。然而现有方法大多依赖静态数据集和固定模型，难以适应用户行为随时间的动态变化。为突破这一局限，我们探索名为\"持续下一兴趣点推荐\"的新任务，使模型能通过持续更新机制动态适应用户兴趣的演变。该任务面临双重挑战：既要捕捉用户行为的动态变化，又需保留已学知识。同时，在实际部署中还需确保更新时效与内存使用效率。为此，我们提出GIRAM框架——基于生成式关键字的兴趣检索与自适应建模，这个高效且模型无关的框架将情境感知的持续兴趣与近期兴趣相融合。GIRAM包含四个核心组件：(1)用于保存历史偏好的兴趣记忆库；(2)实现统一兴趣关键字表征的情境感知编码模块；(3)基于生成式关键字的检索模块，用于识别多样化相关持续兴趣；(4)自适应兴趣更新与融合模块，负责更新兴趣记忆库并平衡持续兴趣与近期兴趣。该框架可与现有下一兴趣点推荐模型无缝集成。在三个真实数据集上的实验表明，GIRAM在保持高效更新时间与内存消耗的同时，持续优于现有最优方法。"
    },
    {
        "title": "Compression then Matching: An Efficient Pre-training Paradigm for Multimodal Embedding",
        "summary": "Vision-language models advance multimodal representation learning by acquiring transferable semantic embeddings, thereby substantially enhancing performance across a range of vision-language tasks, including cross-modal retrieval, clustering, and classification. An effective embedding is expected to comprehensively preserve the semantic content of the input while simultaneously emphasizing features that are discriminative for downstream tasks. Recent approaches demonstrate that VLMs can be adapted into competitive embedding models via large-scale contrastive learning, enabling the simultaneous optimization of two complementary objectives. We argue that the two aforementioned objectives can be decoupled: a comprehensive understanding of the input facilitates the embedding model in achieving superior performance in downstream tasks via contrastive learning. In this paper, we propose CoMa, a compressed pre-training phase, which serves as a warm-up stage for contrastive learning. Experiments demonstrate that with only a small amount of pre-training data, we can transform a VLM into a competitive embedding model. CoMa achieves new state-of-the-art results among VLMs of comparable size on the MMEB, realizing optimization in both efficiency and effectiveness.",
        "entry_id": "http://arxiv.org/abs/2511.08480v1",
        "pub_date": "2025-11-11",
        "translated_summary": "视觉语言模型通过获取可迁移的语义嵌入推动多模态表征学习，从而显著提升跨模态检索、聚类与分类等视觉语言任务的性能。理想的嵌入向量应全面保留输入语义内容，同时突出下游任务所需的判别性特征。最新研究表明，通过大规模对比学习可将VLMs转化为具有竞争力的嵌入模型，实现两个互补目标的同步优化。我们认为上述两个目标可解耦：对输入的全面理解有助于嵌入模型通过对比学习在下游任务中获得更优表现。本文提出压缩式预训练阶段CoMa，作为对比学习的热身阶段。实验表明，仅需少量预训练数据即可将VLM转化为具有竞争力的嵌入模型。CoMa在MMEB基准测试中实现了同体量VLMs的最优性能，在效率与效果上达成双重突破。"
    },
    {
        "title": "Advancing Scientific Knowledge Retrieval and Reuse with a Novel Digital Library for Machine-Readable Knowledge",
        "summary": "Digital libraries for research, such as the ACM Digital Library or Semantic Scholar, do not enable the machine-supported, efficient reuse of scientific knowledge (e.g., in synthesis research). This is because these libraries are based on document-centric models with narrative text knowledge expressions that require manual or semi-automated knowledge extraction, structuring, and organization. We present ORKG reborn, an emerging digital library that supports finding, accessing, and reusing accurate, fine-grained, and reproducible machine-readable expressions of scientific knowledge that relate scientific statements and their supporting evidence in terms of data and code. The rich expressions of scientific knowledge are published as reborn (born-reusable) articles and provide novel possibilities for scientific knowledge retrieval, for instance by statistical methods, software packages, variables, or data matching specific constraints. We describe the proposed system and demonstrate its practical viability and potential for information retrieval in contrast to state-of-the-art digital libraries and document-centric scholarly communication using several published articles in research fields ranging from computer science to soil science. Our work underscores the enormous potential of scientific knowledge databases and a viable approach to their construction.",
        "entry_id": "http://arxiv.org/abs/2511.08476v1",
        "pub_date": "2025-11-11",
        "translated_summary": "诸如ACM数字图书馆或语义学者（Semantic Scholar）等研究型数字图书馆，尚无法实现科学知识的机器支持高效复用（例如在综述研究中）。这是因为这些图书馆基于以文档为中心的模型，其叙述性文本的知识表达方式需要人工或半自动化的知识提取、结构化与组织。我们推出“重生版开放研究知识图谱”（ORKG reborn），这一新兴数字图书馆支持查找、访问并复用精确、细粒度、可重现的机器可读科学知识表达，这些表达通过数据与代码将科学论断及其支撑证据相互关联。这种丰富的科学知识表达以“重生”（即可重复使用）论文的形式发布，为科学知识检索提供了全新可能，例如通过统计方法、软件包、变量或符合特定约束条件的数据进行检索。我们详细描述了该系统的设计，并通过计算机科学到土壤科学等多个研究领域已发表论文的实例，对比现有顶尖数字图书馆和以文档为中心的学术交流模式，论证了该系统在信息检索方面的实际可行性与潜力。我们的工作彰显了科学知识数据库的巨大潜力，并为其构建提供了可行路径。"
    },
    {
        "title": "Bid Farewell to Seesaw: Towards Accurate Long-tail Session-based Recommendation via Dual Constraints of Hybrid Intents",
        "summary": "Session-based recommendation (SBR) aims to predict anonymous users' next interaction based on their interaction sessions. In the practical recommendation scenario, low-exposure items constitute the majority of interactions, creating a long-tail distribution that severely compromises recommendation diversity. Existing approaches attempt to address this issue by promoting tail items but incur accuracy degradation, exhibiting a \"see-saw\" effect between long-tail and accuracy performance. We attribute such conflict to session-irrelevant noise within the tail items, which existing long-tail approaches fail to identify and constrain effectively. To resolve this fundamental conflict, we propose \\textbf{HID} (\\textbf{H}ybrid \\textbf{I}ntent-based \\textbf{D}ual Constraint Framework), a plug-and-play framework that transforms the conventional \"see-saw\" into \"win-win\" through introducing the hybrid intent-based dual constraints for both long-tail and accuracy. Two key innovations are incorporated in this framework: (i) \\textit{Hybrid Intent Learning}, where we reformulate the intent extraction strategies by employing attribute-aware spectral clustering to reconstruct the item-to-intent mapping. Furthermore, discrimination of session-irrelevant noise is achieved through the assignment of the target and noise intents to each session. (ii) \\textit{Intent Constraint Loss}, which incorporates two novel constraint paradigms regarding the \\textit{diversity} and \\textit{accuracy} to regulate the representation learning process of both items and sessions. These two objectives are unified into a single training loss through rigorous theoretical derivation. Extensive experiments across multiple SBR models and datasets demonstrate that HID can enhance both long-tail performance and recommendation accuracy, establishing new state-of-the-art performance in long-tail recommender systems.",
        "entry_id": "http://arxiv.org/abs/2511.08378v1",
        "pub_date": "2025-11-11",
        "translated_summary": "基于会话的推荐旨在根据匿名用户的交互会话预测其下一次交互行为。在实际推荐场景中，低曝光商品构成了交互行为的主体，这种长尾分布严重影响了推荐多样性。现有方法试图通过提升尾部商品曝光来解决该问题，却导致推荐准确率下降，呈现出长尾性能与准确率之间的“跷跷板效应”。我们认为这一矛盾源于尾部商品中存在的会话无关噪声，而现有长尾处理方法未能有效识别和约束此类噪声。为解决这一根本矛盾，我们提出\\textbf{HID}框架——一种即插即用的混合意图双约束框架，通过引入面向长尾性能和准确率的混合意图双约束，将传统的“跷跷板”关系转化为“共赢”关系。该框架包含两大核心创新：(一) \\textit{混合意图学习}，通过采用属性感知谱聚类重构商品-意图映射关系，重新构建意图提取策略。此外，通过为每个会话分配目标意图和噪声意图，实现会话无关噪声的甄别；(二) \\textit{意图约束损失函数}，融合了面向\\textit{多样性}和\\textit{准确率}的两个创新约束范式，用以规范商品和会话的表示学习过程。通过严格的理论推导，这两个目标被统一到单个训练损失函数中。在多个SBR模型和数据集上的大量实验表明，HID能同时提升长尾性能和推荐准确率，在长尾推荐系统中确立了新的性能标杆。"
    },
    {
        "title": "TurkEmbed: Turkish Embedding Model on NLI & STS Tasks",
        "summary": "This paper introduces TurkEmbed, a novel Turkish language embedding model designed to outperform existing models, particularly in Natural Language Inference (NLI) and Semantic Textual Similarity (STS) tasks. Current Turkish embedding models often rely on machine-translated datasets, potentially limiting their accuracy and semantic understanding. TurkEmbed utilizes a combination of diverse datasets and advanced training techniques, including matryoshka representation learning, to achieve more robust and accurate embeddings. This approach enables the model to adapt to various resource-constrained environments, offering faster encoding capabilities. Our evaluation on the Turkish STS-b-TR dataset, using Pearson and Spearman correlation metrics, demonstrates significant improvements in semantic similarity tasks. Furthermore, TurkEmbed surpasses the current state-of-the-art model, Emrecan, on All-NLI-TR and STS-b-TR benchmarks, achieving a 1-4\\% improvement. TurkEmbed promises to enhance the Turkish NLP ecosystem by providing a more nuanced understanding of language and facilitating advancements in downstream applications.",
        "entry_id": "http://arxiv.org/abs/2511.08376v1",
        "pub_date": "2025-11-11",
        "translated_summary": "本文介绍了TurkEmbed——一种新型土耳其语嵌入模型，其设计目标是在自然语言推理（NLI）和语义文本相似度（STS）任务中超越现有模型。当前土耳其语嵌入模型普遍依赖机器翻译数据集，这可能限制其准确性和语义理解能力。TurkEmbed通过融合多样化数据集与先进训练技术（包括套娃表示学习），实现了更鲁棒精准的嵌入表示。该方法使模型能适配各类资源受限环境，并提供更快速的编码能力。我们在土耳其语STS-b-TR数据集上采用皮尔逊与斯皮尔曼相关指标进行评估，结果显示该模型在语义相似度任务中取得显著提升。此外，TurkEmbed在All-NLI-TR和STS-b-TR基准测试中超越当前最优模型Emrecan，实现了1-4%的性能提升。TurkEmbed有望通过提供更精细的语言理解能力并推动下游应用发展，从而增强土耳其语自然语言处理生态系统。"
    },
    {
        "title": "AgentPRM: Process Reward Models for LLM Agents via Step-Wise Promise and Progress",
        "summary": "Despite rapid development, large language models (LLMs) still encounter challenges in multi-turn decision-making tasks (i.e., agent tasks) like web shopping and browser navigation, which require making a sequence of intelligent decisions based on environmental feedback. Previous work for LLM agents typically relies on elaborate prompt engineering or fine-tuning with expert trajectories to improve performance. In this work, we take a different perspective: we explore constructing process reward models (PRMs) to evaluate each decision and guide the agent's decision-making process. Unlike LLM reasoning, where each step is scored based on correctness, actions in agent tasks do not have a clear-cut correctness. Instead, they should be evaluated based on their proximity to the goal and the progress they have made. Building on this insight, we propose a re-defined PRM for agent tasks, named AgentPRM, to capture both the interdependence between sequential decisions and their contribution to the final goal. This enables better progress tracking and exploration-exploitation balance. To scalably obtain labeled data for training AgentPRM, we employ a Temporal Difference-based (TD-based) estimation method combined with Generalized Advantage Estimation (GAE), which proves more sample-efficient than prior methods. Extensive experiments across different agentic tasks show that AgentPRM is over $8\\times$ more compute-efficient than baselines, and it demonstrates robust improvement when scaling up test-time compute. Moreover, we perform detailed analyses to show how our method works and offer more insights, e.g., applying AgentPRM to the reinforcement learning of LLM agents.",
        "entry_id": "http://arxiv.org/abs/2511.08325v1",
        "pub_date": "2025-11-11",
        "translated_summary": "尽管大型语言模型（LLM）发展迅速，但在网络购物、浏览器导航等多轮决策任务（即智能体任务）中仍面临挑战。这类任务要求根据环境反馈进行一系列智能决策。以往针对LLM智能体的研究通常依赖精心设计的提示工程或通过专家轨迹进行微调来提升性能。本研究另辟蹊径：探索构建过程奖励模型（PRM）来评估每个决策步骤并指导智能体的决策过程。与LLM推理中每一步都基于正确性评分不同，智能体任务中的行为没有绝对的正确性标准，而应通过其与目标的接近程度及已取得的进展来评估。基于这一洞见，我们提出了面向智能体任务的重新定义的过程奖励模型AgentPRM，该模型能同时捕捉序列决策间的相互关联及其对最终目标的贡献，从而实现更优的进度跟踪与探索-利用平衡。为高效获取训练AgentPRM所需的标注数据，我们采用基于时序差分（TD）的估计方法结合广义优势估计（GAE），该方法被证明比现有方法更具样本效率。跨多个智能体任务的广泛实验表明，AgentPRM的计算效率较基线方法提升超过8倍，且在扩展测试时计算资源时展现出稳健的性能提升。此外，我们通过详细分析揭示了该方法的作用机制，并提供了更多洞见，例如将AgentPRM应用于LLM智能体的强化学习。"
    },
    {
        "title": "MARC: Multimodal and Multi-Task Agentic Retrieval-Augmented Generation for Cold-Start Recommender System",
        "summary": "Recommender systems (RS) are currently being studied to mitigate limitations during cold-start conditions by leveraging modality information or introducing Agent concepts based on the exceptional reasoning capabilities of Large Language Models (LLMs). Meanwhile, food and beverage recommender systems have traditionally used knowledge graph and ontology concepts due to the domain's unique data attributes and relationship characteristics. On this background, we propose MARC, a multimodal and multi-task cocktail recommender system based on Agentic Retrieval-Augmented Generation (RAG) utilizing graph database under cold-start conditions. The proposed system generates high-quality, contextually appropriate answers through two core processes: a task recognition router and a reflection process. The graph database was constructed by processing cocktail data from Kaggle, and its effectiveness was evaluated using 200 manually crafted questions. The evaluation used both LLM-as-a-judge and human evaluation to demonstrate that answers generated via the graph database outperformed those from a simple vector database in terms of quality. The code is available at https://github.com/diddbwls/cocktail_rec_agentrag",
        "entry_id": "http://arxiv.org/abs/2511.08181v1",
        "pub_date": "2025-11-11",
        "translated_summary": "当前，推荐系统领域正致力于通过利用模态信息或引入基于大语言模型卓越推理能力的智能体概念，来缓解冷启动场景下的局限性。与此同时，由于餐饮领域独特的数据属性与关系特征，传统餐饮推荐系统多采用知识图谱与本体论概念。在此背景下，我们提出MARC——一个基于智能体检索增强生成的多模态多任务鸡尾酒推荐系统，该系统在冷启动条件下利用图数据库实现推荐。该体系通过任务识别路由器和反思机制两大核心流程，生成高质量且符合情境的推荐结果。我们通过处理Kaggle平台的鸡尾酒数据构建图数据库，并采用200道人工编制的问题进行效果评估。评估过程综合运用大语言模型即评判与人工评估两种方式，结果表明基于图数据库生成的答案质量显著优于简单向量数据库方案。代码已开源：https://github.com/diddbwls/cocktail_rec_agentrag"
    },
    {
        "title": "DiffuGR: Generative Document Retrieval with Diffusion Language Models",
        "summary": "Generative retrieval (GR) re-frames document retrieval as a sequence-based document identifier (DocID) generation task, memorizing documents with model parameters and enabling end-to-end retrieval without explicit indexing. Existing GR methods are based on auto-regressive generative models, i.e., the token generation is performed from left to right. However, such auto-regressive methods suffer from: (1) mismatch between DocID generation and natural language generation, e.g., an incorrect DocID token generated in early left steps would lead to totally erroneous retrieval; and (2) failure to balance the trade-off between retrieval efficiency and accuracy dynamically, which is crucial for practical applications. To address these limitations, we propose generative document retrieval with diffusion language models, dubbed DiffuGR. It models DocID generation as a discrete diffusion process: during training, DocIDs are corrupted through a stochastic masking process, and a diffusion language model is learned to recover them under a retrieval-aware objective. For inference, DiffuGR attempts to generate DocID tokens in parallel and refines them through a controllable number of denoising steps. In contrast to conventional left-to-right auto-regressive decoding, DiffuGR provides a novel mechanism to first generate more confident DocID tokens and refine the generation through diffusion-based denoising. Moreover, DiffuGR also offers explicit runtime control over the qualitylatency tradeoff. Extensive experiments on benchmark retrieval datasets show that DiffuGR is competitive with strong auto-regressive generative retrievers, while offering flexible speed and accuracy tradeoffs through variable denoising budgets. Overall, our results indicate that non-autoregressive diffusion models are a practical and effective alternative for generative document retrieval.",
        "entry_id": "http://arxiv.org/abs/2511.08150v1",
        "pub_date": "2025-11-11",
        "translated_summary": "生成式检索将文档检索重新定义为基于序列的文档标识符生成任务，通过模型参数记忆文档，实现无需显式索引的端到端检索。现有生成式检索方法均基于自回归生成模型，即从左到右顺序生成标识符。然而这类方法存在两大局限：（1）文档标识符生成与自然语言生成存在本质差异，早期生成的错误标识符会导致完全错误的检索结果；（2）无法动态平衡检索效率与准确率之间的权衡关系，而这在实际应用中至关重要。为克服这些局限，我们提出基于扩散语言模型的生成式检索方法DiffuGR。该方法将文档标识符生成建模为离散扩散过程：训练阶段通过随机掩码破坏文档标识符，并学习扩散语言模型在检索感知目标下恢复被破坏的标识符；推理阶段则尝试并行生成标识符，并通过可控的去噪步骤进行优化。相较于传统的自回归解码机制，DiffuGR首创了先生成高置信度标识符、再通过扩散去噪优化的新范式。此外，DiffuGR还能显式控制质量与延迟的权衡关系。在标准检索数据集上的大量实验表明，DiffuGR在保持与强基线自回归方法竞争力的同时，可通过调整去噪次数实现灵活的精度-速度权衡。我们的研究结果证明，非自回归扩散模型是生成式文档检索领域具有实用价值的有效替代方案。"
    },
    {
        "title": "BiCA: Effective Biomedical Dense Retrieval with Citation-Aware Hard Negatives",
        "summary": "Hard negatives are essential for training effective retrieval models. Hard-negative mining typically relies on ranking documents using cross-encoders or static embedding models based on similarity metrics such as cosine distance. Hard negative mining becomes challenging for biomedical and scientific domains due to the difficulty in distinguishing between source and hard negative documents. However, referenced documents naturally share contextual relevance with the source document but are not duplicates, making them well-suited as hard negatives. In this work, we propose BiCA: Biomedical Dense Retrieval with Citation-Aware Hard Negatives, an approach for hard-negative mining by utilizing citation links in 20,000 PubMed articles for improving a domain-specific small dense retriever. We fine-tune the GTE_small and GTE_Base models using these citation-informed negatives and observe consistent improvements in zero-shot dense retrieval using nDCG@10 for both in-domain and out-of-domain tasks on BEIR and outperform baselines on long-tailed topics in LoTTE using Success@5. Our findings highlight the potential of leveraging document link structure to generate highly informative negatives, enabling state-of-the-art performance with minimal fine-tuning and demonstrating a path towards highly data-efficient domain adaptation.",
        "entry_id": "http://arxiv.org/abs/2511.08029v1",
        "pub_date": "2025-11-11",
        "translated_summary": "硬负样本对于训练高效检索模型至关重要。硬负样本挖掘通常依赖于使用交叉编码器或基于余弦距离等相似性度量的静态嵌入模型对文档进行排序。在生物医学和科学领域，由于难以区分源文档与硬负样本文档，硬负样本挖掘变得颇具挑战。然而，被引文献天然与源文档具有上下文关联性但并非重复内容，这使其成为理想的硬负样本。本研究提出BiCA：基于引文感知硬负样本的生物医学稠密检索方法，通过利用20,000篇PubMed文献中的引文链接进行硬负样本挖掘，以改进领域专用的小型稠密检索器。我们使用这些引文指导的负样本对GTE_small和GTE_Base模型进行微调，在BEIR数据集的内域和外域任务中通过nDCG@10指标观察到零样本稠密检索的持续提升，并在LoTTE数据集的长尾主题上使用Success@5指标超越基线。我们的研究结果揭示了利用文档链接结构生成高信息量负样本的潜力，通过最小化微调即可实现最先进性能，为高数据效率的领域自适应开辟了新路径。"
    },
    {
        "title": "From IDs to Semantics: A Generative Framework for Cross-Domain Recommendation with Adaptive Semantic Tokenization",
        "summary": "Cross-domain recommendation (CDR) is crucial for improving recommendation accuracy and generalization, yet traditional methods are often hindered by the reliance on shared user/item IDs, which are unavailable in most real-world scenarios. Consequently, many efforts have focused on learning disentangled representations through multi-domain joint training to bridge the domain gaps. Recent Large Language Model (LLM)-based approaches show promise, they still face critical challenges, including: (1) the \\textbf{item ID tokenization dilemma}, which leads to vocabulary explosion and fails to capture high-order collaborative knowledge; and (2) \\textbf{insufficient domain-specific modeling} for the complex evolution of user interests and item semantics. To address these limitations, we propose \\textbf{GenCDR}, a novel \\textbf{Gen}erative \\textbf{C}ross-\\textbf{D}omain \\textbf{R}ecommendation framework. GenCDR first employs a \\textbf{Domain-adaptive Tokenization} module, which generates disentangled semantic IDs for items by dynamically routing between a universal encoder and domain-specific adapters. Symmetrically, a \\textbf{Cross-domain Autoregressive Recommendation} module models user preferences by fusing universal and domain-specific interests. Finally, a \\textbf{Domain-aware Prefix-tree} enables efficient and accurate generation. Extensive experiments on multiple real-world datasets demonstrate that GenCDR significantly outperforms state-of-the-art baselines. Our code is available in the supplementary materials.",
        "entry_id": "http://arxiv.org/abs/2511.08006v1",
        "pub_date": "2025-11-11",
        "translated_summary": "跨领域推荐对提升推荐准确性与泛化能力至关重要，但传统方法常受限于对共享用户/物品ID的依赖，而这类ID在现实场景中往往不可用。为此，研究者们多聚焦于通过多领域联合训练学习解耦表征以弥合领域差异。尽管基于大语言模型的新方法展现出潜力，仍面临两大核心挑战：（1）**物品ID标记化困境**，导致词表爆炸且无法捕获高阶协同知识；（2）对用户兴趣与物品语义复杂演化的**领域特异性建模不足**。针对这些局限，我们提出**GenCDR**——一个创新的**生成式跨领域推荐框架**。该框架首先通过**领域自适应标记化模块**，借助通用编码器与领域适配器间的动态路由生成解耦的物品语义ID；对称地，**跨领域自回归推荐模块**通过融合通用兴趣与领域特异性兴趣建模用户偏好；最后通过**领域感知前缀树**实现高效精准的生成。在多组真实数据集上的大量实验表明，GenCDR显著优于当前最先进的基线模型。代码已附于补充材料中。"
    },
    {
        "title": "TurkEmbed4Retrieval: Turkish Embedding Model for Retrieval Task",
        "summary": "In this work, we introduce TurkEmbed4Retrieval, a retrieval specialized variant of the TurkEmbed model originally designed for Natural Language Inference (NLI) and Semantic Textual Similarity (STS) tasks. By fine-tuning the base model on the MS MARCO TR dataset using advanced training techniques, including Matryoshka representation learning and a tailored multiple negatives ranking loss, we achieve SOTA performance for Turkish retrieval tasks. Extensive experiments demonstrate that our model outperforms Turkish colBERT by 19,26% on key retrieval metrics for the Scifact TR dataset, thereby establishing a new benchmark for Turkish information retrieval.",
        "entry_id": "http://arxiv.org/abs/2511.07595v1",
        "pub_date": "2025-11-10",
        "translated_summary": "本研究推出了TurkEmbed4Retrieval——这是专为检索任务优化的TurkEmbed模型变体，原模型设计用于自然语言推理（NLI）与语义文本相似度（STS）任务。通过在MS MARCO TR数据集上采用先进训练技术对基础模型进行微调，包括套娃表示学习与定制化的多重负样本排序损失函数，我们实现了土耳其语检索任务的性能突破。大量实验表明，在Scifact TR数据集的关键检索指标上，本模型以19.26%的优势超越土耳其语colBERT模型，由此为土耳其语信息检索树立了全新基准。"
    },
    {
        "title": "Think Before You Retrieve: Learning Test-Time Adaptive Search with Small Language Models",
        "summary": "Effective information retrieval requires reasoning over partial evidence and refining strategies as information emerges. Yet current approaches fall short: neural retrievers lack reasoning capabilities, large language models (LLMs) provide semantic depth but at prohibitive cost, and query rewriting or decomposition limits improvement to static transformations. As a result, existing methods fail to capture the iterative dynamics of exploration, feedback, and revision that complex user queries demand. We introduce Orion, a training framework that enables compact models (350M-1.2B parameters) to perform iterative retrieval through learned search strategies. Orion combines: (1) synthetic trajectory generation and supervised fine-tuning to encourage diverse exploration patterns in models, (2) reinforcement learning (RL) that rewards effective query refinement and backtracking behaviors, and (3) inference-time beam search algorithms that exploit the self-reflection capabilities learned during RL. Despite using only 3% of the training data available, our 1.2B model achieves 77.6% success on SciFact (vs. 72.6% for prior retrievers), 25.2% on BRIGHT (vs. 22.1%), 63.2% on NFCorpus (vs. 57.8%), and remains competitive on FEVER, HotpotQA, and MSMarco. It outperforms retrievers up to 200-400x larger on five of six benchmarks. These findings suggest that retrieval performance can emerge from learned strategies, not just model scale, when models are trained to search, reflect, and revise.",
        "entry_id": "http://arxiv.org/abs/2511.07581v1",
        "pub_date": "2025-11-10",
        "translated_summary": "高效的信息检索要求能够基于局部证据进行推理，并在信息出现时不断优化策略。然而现有方法存在明显局限：神经检索模型缺乏推理能力，大语言模型虽能提供语义深度但计算成本过高，而查询重写或分解方法仅能实现静态转换。这些方法均无法满足复杂用户查询所需的探索、反馈与修正的迭代动态过程。我们提出Orion训练框架，使轻量化模型（3.5-12亿参数）通过学习搜索策略实现迭代检索。该框架包含三大核心组件：（1）通过合成轨迹生成与监督微调激发模型多样化探索模式；（2）采用强化学习奖励有效的查询优化与回溯行为；（3）基于束搜索的推理算法，利用强化学习阶段习得的自反思能力。尽管仅使用3%的训练数据，我们的12亿参数模型在SciFact上达成77.6%成功率（优于原有72.6%），BRIGHT达到25.2%（原22.1%），NFCorpus提升至63.2%（原57.8%），并在FEVER、HotpotQA和MSMarco保持竞争力。在六项基准测试中有五项超越参数量200-400倍的检索模型。这表明当模型被训练具备搜索、反思与修正能力时，检索性能的提升可源于学习策略本身，而不仅依赖模型规模。"
    },
    {
        "title": "A Decentralized Retrieval Augmented Generation System with Source Reliabilities Secured on Blockchain",
        "summary": "Existing retrieval-augmented generation (RAG) systems typically use a centralized architecture, causing a high cost of data collection, integration, and management, as well as privacy concerns. There is a great need for a decentralized RAG system that enables foundation models to utilize information directly from data owners who maintain full control over their sources. However, decentralization brings a challenge: the numerous independent data sources vary significantly in reliability, which can diminish retrieval accuracy and response quality. To address this, our decentralized RAG system has a novel reliability scoring mechanism that dynamically evaluates each source based on the quality of responses it contributes to generate and prioritizes high-quality sources during retrieval. To ensure transparency and trust, the scoring process is securely managed through blockchain-based smart contracts, creating verifiable and tamper-proof reliability records without relying on a central authority. We evaluate our decentralized system with two Llama models (3B and 8B) in two simulated environments where six data sources have different levels of reliability. Our system achieves a +10.7\\% performance improvement over its centralized counterpart in the real world-like unreliable data environments. Notably, it approaches the upper-bound performance of centralized systems under ideally reliable data environments. The decentralized infrastructure enables secure and trustworthy scoring management, achieving approximately 56\\% marginal cost savings through batched update operations. Our code and system are open-sourced at github.com/yining610/Reliable-dRAG.",
        "entry_id": "http://arxiv.org/abs/2511.07577v1",
        "pub_date": "2025-11-10",
        "translated_summary": "现有的检索增强生成系统通常采用集中式架构，这导致数据收集、整合与管理成本高昂，并引发隐私担忧。业界亟需一种去中心化的RAG系统，使基础模型能够直接利用数据所有者控制的信息源，同时确保数据所有者保持对数据的完全掌控。然而，去中心化架构面临关键挑战：大量独立数据源的可靠性差异显著，可能降低检索精度与响应质量。为此，我们提出的去中心化RAG系统创新性地引入了可靠性评分机制，该机制根据各数据源在生成响应过程中的贡献质量进行动态评估，并在检索时优先调用高质量数据源。为确保透明度与可信度，评分过程通过基于区块链的智能合约进行安全管理，建立可验证且防篡改的可靠性记录，无需依赖中心化机构。我们使用两个Llama模型（3B和8B参数）在模拟环境中对系统进行评估，该环境包含六个具有不同可靠性等级的数据源。在模拟真实世界不可靠数据环境时，本系统相较集中式系统实现了10.7%的性能提升。值得注意的是，在理想可靠数据环境下，其性能已逼近集中式系统的理论上限。该去中心化基础设施通过批量更新操作实现了约56%的边际成本节约，同时保障了评分管理的安全可信。我们的代码与系统已在github.com/yining610/Reliable-dRAG开源。"
    },
    {
        "title": "GRIN Transfer: A production-ready tool for libraries to retrieve digital copies from Google Books",
        "summary": "Publicly launched in 2004, the Google Books project has scanned tens of millions of items in partnership with libraries around the world. As part of this project, Google created the Google Return Interface (GRIN). Through this platform, libraries can access their scanned collections, the associated metadata, and the ongoing OCR and metadata improvements that become available as Google reprocesses these collections using new technologies. When downloading the Harvard Library Google Books collection from GRIN to develop the Institutional Books dataset, we encountered several challenges related to rate-limiting and atomized metadata within the GRIN platform. To overcome these challenges and help other libraries make more robust use of their Google Books collections, this technical report introduces the initial release of GRIN Transfer. This open-source and production-ready Python pipeline allows partner libraries to efficiently retrieve their Google Books collections from GRIN. This report also introduces an updated version of our Institutional Books 1.0 pipeline, initially used to analyze, augment, and assemble the Institutional Books 1.0 dataset. We have revised this pipeline for compatibility with the output format of GRIN Transfer. A library could pair these two tools to create an end-to-end processing pipeline for their Google Books collection to retrieve, structure, and enhance data available from GRIN. This report gives an overview of how GRIN Transfer was designed to optimize for reliability and usability in different environments, as well as guidance on configuration for various use cases.",
        "entry_id": "http://arxiv.org/abs/2511.11447v1",
        "pub_date": "2025-11-14",
        "translated_summary": "谷歌图书项目于2004年正式启动，已与全球多家图书馆合作扫描数千万册文献。作为该项目的重要组成部分，谷歌开发了谷歌回传接口（GRIN）。通过该平台，合作图书馆可获取其馆藏扫描文献、相关元数据，以及谷歌运用新技术重新处理文献时持续优化的OCR文本与元数据。当哈佛图书馆通过GRIN平台下载谷歌图书资源以构建机构图书数据集时，我们遇到了接口速率限制与元数据原子化等技术挑战。为突破这些限制并助力其他图书馆更高效地利用谷歌图书资源，本技术报告正式发布GRIN Transfer工具。这套开源即用的Python流水线系统，可帮助合作图书馆从GRIN平台快速获取图书资源。报告同时推出了机构图书1.0流水线的升级版本——该原始流水线最初用于分析、增强和整合机构图书1.0数据集。我们已对其进行了重构，使其兼容GRIN Transfer的输出格式。图书馆可组合使用这两套工具，构建端到端的谷歌图书资源处理流程，实现从GRIN平台的数据获取、结构化处理到质量增强的全链条操作。本报告详细阐述了GRIN Transfer如何针对不同环境优化可靠性及易用性的设计思路，并为多种应用场景提供了配置指南。"
    },
    {
        "title": "Unlocking Advanced Graph Machine Learning Insights through Knowledge Completion on Neo4j Graph Database",
        "summary": "Graph Machine Learning (GML) with Graph Databases (GDBs) has gained significant relevance in recent years, due to its ability to handle complex interconnected data and apply ML techniques using Graph Data Science (GDS). However, a critical gap exists in the current way GDB-GML applications analyze data, especially in terms of Knowledge Completion (KC) in Knowledge Graphs (KGs). In particular, current architectures ignore KC, working on datasets that appear incomplete or fragmented, despite they actually contain valuable hidden knowledge. This limitation may cause wrong interpretations when these data are used as input for GML models.\n  This paper proposes an innovative architecture that integrates a KC phase into GDB-GML applications, demonstrating how revealing hidden knowledge can heavily impact datasets' behavior and metrics. For this purpose, we introduce scalable transitive relationships, which are links that propagate information over the network and modelled by a decay function, allowing a deterministic knowledge flows across multiple nodes.\n  Experimental results demonstrate that our intuition radically reshapes both topology and overall dataset dynamics, underscoring the need for this new GDB-GML architecture to produce better models and unlock the full potential of graph-based data analysis.",
        "entry_id": "http://arxiv.org/abs/2511.11399v1",
        "pub_date": "2025-11-14",
        "translated_summary": "近年来，结合图数据库的图机器学习技术因其处理复杂互联数据的能力，以及运用图数据科学实施机器学习的特点而日益重要。然而，当前图数据库-图机器学习应用在数据分析方式上存在显著缺陷，尤其在知识图谱的知识补全环节表现得尤为突出。现有架构往往忽略知识补全环节，直接处理表面不完整或碎片化的数据集，尽管这些数据实则蕴含宝贵的隐藏知识。这种局限性可能导致在使用这些数据作为图机器学习模型输入时产生错误解读。\n\n本文提出了一种创新架构，将知识补全阶段整合至图数据库-图机器学习应用中，通过实证揭示了显性化隐藏知识如何深刻影响数据集表现与评估指标。为此，我们引入了可扩展的传递关系——这种通过衰减函数建模的关系链能在网络中传播信息，实现跨节点的确定性知识流动。\n\n实验结果表明，我们的创新构想能从根本上重塑数据集的拓扑结构与整体动态特征，这印证了采用新型图数据库-图机器学习架构的必要性：既能构建更优质的模型，又能充分释放图数据分析的全部潜力。"
    },
    {
        "title": "SRLF: An Agent-Driven Set-Wise Reflective Learning Framework for Sequential Recommendation",
        "summary": "LLM-based agents are emerging as a promising paradigm for simulating user behavior to enhance recommender systems. However, their effectiveness is often limited by existing studies that focus on modeling user ratings for individual items. This point-wise approach leads to prevalent issues such as inaccurate user preference comprehension and rigid item-semantic representations.\n  To address these limitations, we propose the novel Set-wise Reflective Learning Framework (SRLF). Our framework operationalizes a closed-loop \"assess-validate-reflect\" cycle that harnesses the powerful in-context learning capabilities of LLMs. SRLF departs from conventional point-wise assessment by formulating a holistic judgment on an entire set of items. It accomplishes this by comprehensively analyzing both the intricate interrelationships among items within the set and their collective alignment with the user's preference profile. This method of set-level contextual understanding allows our model to capture complex relational patterns essential to user behavior, making it significantly more adept for sequential recommendation. Extensive experiments validate our approach, confirming that this set-wise perspective is crucial for achieving state-of-the-art performance in sequential recommendation tasks.",
        "entry_id": "http://arxiv.org/abs/2511.11370v1",
        "pub_date": "2025-11-14",
        "translated_summary": "基于大语言模型的智能体正成为一种新兴范式，通过模拟用户行为来增强推荐系统性能。然而现有研究多聚焦于对单一物品评分的建模，这种点对点范式导致模型存在用户偏好理解失准和物品语义表征僵化等普遍问题。为突破这些局限，我们提出创新性的集合式反思学习框架。该框架通过构建\"评估-验证-反思\"的闭环流程，充分发挥大语言模型的上下文学习优势。与传统点对点评估不同，我们的框架对整组物品进行整体判断，通过综合分析物品间错综复杂的内部关联及其与用户偏好画像的集体契合度，实现集合层面的情境理解。这种方法使模型能捕捉用户行为中至关重要的复杂关系模式，从而显著提升序列推荐效能。大量实验验证了本方法的优越性，证实集合式视角对实现序列推荐任务最先进性能具有关键作用。"
    },
    {
        "title": "MOON Embedding: Multimodal Representation Learning for E-commerce Search Advertising",
        "summary": "We introduce MOON, our comprehensive set of sustainable iterative practices for multimodal representation learning for e-commerce applications. MOON has already been fully deployed across all stages of Taobao search advertising system, including retrieval, relevance, ranking, and so on. The performance gains are particularly significant on click-through rate (CTR) prediction task, which achieves an overall +20.00% online CTR improvement. Over the past three years, this project has delivered the largest improvement on CTR prediction task and undergone five full-scale iterations. Throughout the exploration and iteration of our MOON, we have accumulated valuable insights and practical experience that we believe will benefit the research community. MOON contains a three-stage training paradigm of \"Pretraining, Post-training, and Application\", allowing effective integration of multimodal representations with downstream tasks. Notably, to bridge the misalignment between the objectives of multimodal representation learning and downstream training, we define the exchange rate to quantify how effectively improvements in an intermediate metric can translate into downstream gains. Through this analysis, we identify the image-based search recall as a critical intermediate metric guiding the optimization of multimodal models. Over three years and five iterations, MOON has evolved along four critical dimensions: data processing, training strategy, model architecture, and downstream application. The lessons and insights gained through the iterative improvements will also be shared. As part of our exploration into scaling effects in the e-commerce field, we further conduct a systematic study of the scaling laws governing multimodal representation learning, examining multiple factors such as the number of training tokens, negative samples, and the length of user behavior sequences.",
        "entry_id": "http://arxiv.org/abs/2511.11305v1",
        "pub_date": "2025-11-14",
        "translated_summary": "我们正式推出MOON——一套面向电商应用的多模态表征学习可持续迭代实践体系。该体系已全面部署于淘宝搜索广告系统的检索、相关性、排序等全链路环节，在点击率预测任务上取得显著效果，实现总点击率20.00%的大幅提升。这一历时三年的项目已完成五轮全链路迭代，成为点击率预测任务改进幅度最大的实践。在MOON体系的探索迭代过程中，我们积累了宝贵洞见与实践经验，现将其凝练为包含“预训练-后训练-应用”的三阶段训练范式，有效打通多模态表征与下游任务的衔接通道。值得注意的是，为弥合多模态表征学习目标与下游训练目标之间的错位，我们创新性地定义了“兑换率”指标，用以量化中间指标提升对下游收益的转化效能。通过该分析框架，我们成功锁定基于图像的搜索召回率作为指导多模态模型优化的关键中间指标。历经三年五轮迭代，MOON体系在数据处理、训练策略、模型架构与下游应用四大维度持续演进，相关经验教训与深度洞察将在本文分享。作为对电商领域规模化效应的探索延伸，我们进一步系统研究了多模态表征学习的规模法则，深入解析训练词元数量、负样本规模、用户行为序列长度等多重因素的协同影响规律。"
    },
    {
        "title": "SQuaD: The Software Quality Dataset",
        "summary": "Software quality research increasingly relies on large-scale datasets that measure both the product and process aspects of software systems. However, existing resources often focus on limited dimensions, such as code smells, technical debt, or refactoring activity, thereby restricting comprehensive analyses across time and quality dimensions. To address this gap, we present the Software Quality Dataset (SQuaD), a multi-dimensional, time-aware collection of software quality metrics extracted from 450 mature open-source projects across diverse ecosystems, including Apache, Mozilla, FFmpeg, and the Linux kernel. By integrating nine state-of-the-art static analysis tools, i.e., SonarQube, CodeScene, PMD, Understand, CK, JaSoMe, RefactoringMiner, RefactoringMiner++, and PyRef, our dataset unifies over 700 unique metrics at method, class, file, and project levels. Covering a total of 63,586 analyzed project releases, SQuaD also provides version control and issue-tracking histories, software vulnerability data (CVE/CWE), and process metrics proven to enhance Just-In-Time (JIT) defect prediction. The SQuaD enables empirical research on maintainability, technical debt, software evolution, and quality assessment at unprecedented scale. We also outline emerging research directions, including automated dataset updates and cross-project quality modeling to support the continuous evolution of software analytics. The dataset is publicly available on ZENODO (DOI: 10.5281/zenodo.17566690).",
        "entry_id": "http://arxiv.org/abs/2511.11265v1",
        "pub_date": "2025-11-14",
        "translated_summary": "软件质量研究日益依赖于能够同时衡量软件系统产品维度与过程维度的大规模数据集。然而现有资源往往聚焦于有限维度（如代码异味、技术债或重构活动），从而制约了跨时间维度和质量维度的综合分析。为弥补这一空白，我们推出软件质量数据集SQuaD——这是一个从450个成熟开源项目（涵盖Apache、Mozilla、FFmpeg和Linux内核等多元生态系统）中提取的多维度、时间感知型软件质量指标集合。通过集成九种前沿静态分析工具（SonarQube、CodeScene、PMD、Understand、CK、JaSoMe、RefactoringMiner、RefactoringMiner++和PyRef），本数据集在方法、类、文件和项目层级统一了700余项独特指标。SQuaD覆盖总计63,586个经过分析的项目版本，同时提供版本控制与问题追踪历史、软件漏洞数据（CVE/CWE），以及被证实能增强即时缺陷预测的过程指标。该数据集支持在可维护性、技术债、软件演进和质量评估方面开展前所未有的实证研究。我们还规划了新兴研究方向，包括自动化数据集更新与跨项目质量建模，以支撑软件分析技术的持续演进。本数据集已在ZENODO平台公开发布（DOI: 10.5281/zenodo.17566690）。"
    },
    {
        "title": "Align$^3$GR: Unified Multi-Level Alignment for LLM-based Generative Recommendation",
        "summary": "Large Language Models (LLMs) demonstrate significant advantages in leveraging structured world knowledge and multi-step reasoning capabilities. However, fundamental challenges arise when transforming LLMs into real-world recommender systems due to semantic and behavioral misalignment. To bridge this gap, we propose Align$^3$GR, a novel framework that unifies token-level, behavior modeling-level, and preference-level alignment. Our approach introduces: Dual tokenization fusing user-item semantic and collaborative signals. Enhanced behavior modeling with bidirectional semantic alignment. Progressive DPO strategy combining self-play (SP-DPO) and real-world feedback (RF-DPO) for dynamic preference adaptation. Experiments show Align$^3$GR outperforms the SOTA baseline by +17.8% in Recall@10 and +20.2% in NDCG@10 on the public dataset, with significant gains in online A/B tests and full-scale deployment on an industrial large-scale recommendation platform.",
        "entry_id": "http://arxiv.org/abs/2511.11255v1",
        "pub_date": "2025-11-14",
        "translated_summary": "大语言模型在利用结构化世界知识与多步推理能力方面展现出显著优势，但由于语义和行为层面的错位，将其转化为现实推荐系统仍存在根本性挑战。为弥合这一差距，我们提出Align³GR创新框架，通过三层次对齐实现统一：融合用户-项目语义信号与协同信号的双重标记化机制；基于双向语义对齐的增强行为建模；结合自我博弈优化与真实反馈的渐进式直接偏好优化策略。实验表明，在公开数据集上Align³GR的Recall@10和NDCG@10指标分别超越现有最优基线17.8%和20.2%，在工业级推荐平台的在线A/B测试与全量部署中均取得显著效果提升。"
    },
    {
        "title": "Enhancing Group Recommendation using Soft Impute Singular Value Decomposition",
        "summary": "The growing popularity of group activities increased the need to develop methods for providing recommendations to a group of users based on the collective preferences of the group members. Several group recommender systems have been proposed, but these methods often struggle due to sparsity and high-dimensionality of the available data, common in many real-world applications. In this paper, we propose a group recommender system called Group Soft-Impute SVD, which leverages soft-impute singular value decomposition to enhance group recommendations. This approach addresses the challenge of sparse high-dimensional data using low-rank matrix completion. We compared the performance of Group Soft-Impute SVD with Group MF based approaches and found that our method outperforms the baselines in recall for small user groups while achieving comparable results across all group sizes when tasked on Goodbooks, Movielens, and Synthetic datasets. Furthermore, our method recovers lower matrix ranks than the baselines, demonstrating its effectiveness in handling high-dimensional data.",
        "entry_id": "http://arxiv.org/abs/2511.11172v1",
        "pub_date": "2025-11-14",
        "translated_summary": "随着团体活动的日益普及，如何基于群体成员的集体偏好为整个用户群提供推荐的需求不断增长。尽管已有多种团体推荐系统被提出，但这些方法常因实际应用中普遍存在的数据稀疏性和高维度问题而效果受限。本文提出了一种名为Group Soft-Impute SVD的团体推荐系统，通过软填充奇异值分解技术来增强团体推荐效果。该方法利用低秩矩阵补全技术应对稀疏高维数据的挑战。在Goodbooks、Movielens和合成数据集上的实验表明，与基于群体矩阵分解的方法相比，本方法在小规模用户群体的召回率指标上表现更优，同时在所有群体规模下均能取得相当的结果。此外，本方法能恢复比基线模型更低的矩阵秩，证明了其在处理高维数据方面的有效性。"
    },
    {
        "title": "GovScape: A Public Multimodal Search System for 70 Million Pages of Government PDFs",
        "summary": "Efforts over the past three decades have produced web archives containing billions of webpage snapshots and petabytes of data. The End of Term Web Archive alone contains, among other file types, millions of PDFs produced by the federal government. While preservation with web archives has been successful, significant challenges for access and discoverability remain. For example, current affordances for browsing the End of Term PDFs are limited to downloading and browsing individual PDFs, as well as performing basic keyword search across them. In this paper, we introduce GovScape, a public search system that supports multimodal searches across 10,015,993 federal government PDFs from the 2020 End of Term crawl (70,958,487 total PDF pages) - to our knowledge, all renderable PDFs in the 2020 crawl that are 50 pages or under. GovScape supports four primary forms of search over these 10 million PDFs: in addition to providing (1) filter conditions over metadata facets including domain and crawl date and (2) exact text search against the PDF text, we provide (3) semantic text search and (4) visual search against the PDFs across individual pages, enabling users to structure queries such as \"redacted documents\" or \"pie charts.\" We detail the constituent components of GovScape, including the search affordances, embedding pipeline, system architecture, and open source codebase. Significantly, the total estimated compute cost for GovScape's pre-processing pipeline for 10 million PDFs was approximately $1,500, equivalent to 47,000 PDF pages per dollar spent on compute, demonstrating the potential for immediate scalability. Accordingly, we outline steps that we have already begun pursuing toward multimodal search at the 100+ million PDF scale. GovScape can be found at https://www.govscape.net.",
        "entry_id": "http://arxiv.org/abs/2511.11010v1",
        "pub_date": "2025-11-14",
        "translated_summary": "过去三十年的努力已建成包含数十亿网页快照和PB级数据的网络档案馆。仅\"任期结束网络档案馆\"就收录了联邦政府制作的数百万份PDF文件及其他类型文件。尽管网络存档在保存方面成果显著，但在访问和可发现性方面仍存在重大挑战。例如，当前对\"任期结束PDF\"的浏览功能仅限于下载和浏览单个PDF文件，以及执行基本关键词检索。本文推出GovScape公共检索系统，该系统支持对2020年\"任期结束\"网络抓取中10,015,993份联邦政府PDF文件（总计70,958,487页）进行多模态检索——据我们所知，这涵盖了2020年抓取中所有可渲染且不超过50页的PDF文件。GovScape为这千万量级PDF提供四种主要检索方式：除支持(1)基于域名和抓取日期等元数据面的筛选条件及(2)精确文本检索外，还提供(3)语义文本检索与(4)跨页视觉检索，使用户能构建\"经修订文件\"或\"饼状图\"等结构化查询。我们详细阐述了GovScape的构成组件，包括检索功能、嵌入流程、系统架构和开源代码库。值得注意的是，该系统预处理千万份PDF的总计算成本约为1,500美元，相当于每美元计算成本可处理47,000页PDF，展现出即时扩展的潜力。基于此，我们已着手推进亿级PDF规模的多模态检索研究。GovScape可通过https://www.govscape.net 访问。"
    },
    {
        "title": "LEMUR: Large scale End-to-end MUltimodal Recommendation",
        "summary": "Traditional ID-based recommender systems often struggle with cold-start and generalization challenges. Multimodal recommendation systems, which leverage textual and visual data, offer a promising solution to mitigate these issues. However, existing industrial approaches typically adopt a two-stage training paradigm: first pretraining a multimodal model, then applying its frozen representations to train the recommendation model. This decoupled framework suffers from misalignment between multimodal learning and recommendation objectives, as well as an inability to adapt dynamically to new data. To address these limitations, we propose LEMUR, the first large-scale multimodal recommender system trained end-to-end from raw data. By jointly optimizing both the multimodal and recommendation components, LEMUR ensures tighter alignment with downstream objectives while enabling real-time parameter updates. Constructing multimodal sequential representations from user history often entails prohibitively high computational costs. To alleviate this bottleneck, we propose a novel memory bank mechanism that incrementally accumulates historical multimodal representations throughout the training process. After one month of deployment in Douyin Search, LEMUR has led to a 0.843% reduction in query change rate decay and a 0.81% improvement in QAUC. Additionally, LEMUR has shown significant gains across key offline metrics for Douyin Advertisement. Our results validate the superiority of end-to-end multimodal recommendation in real-world industrial scenarios.",
        "entry_id": "http://arxiv.org/abs/2511.10962v1",
        "pub_date": "2025-11-14",
        "translated_summary": "传统基于ID的推荐系统常面临冷启动和泛化性挑战。融合文本与视觉特征的多模态推荐系统为缓解这些问题提供了新思路。然而现有工业级方案通常采用两阶段训练范式：先预训练多模态模型，再将其冻结的特征表示应用于推荐模型训练。这种解耦框架存在多模态学习与推荐目标失配、无法动态适配新数据等缺陷。为解决这些问题，我们提出首个基于原始数据端到端训练的大规模多模态推荐系统LEMUR。通过联合优化多模态模块与推荐模块，该系统在实现实时参数更新的同时，能更紧密地对齐下游任务目标。从用户历史行为构建多模态序列表示往往伴随高昂计算成本，为此我们设计了一种新型记忆库机制，可在训练过程中渐进式累积历史多模态表示。在抖音搜索场景部署一个月后，LEMUR使查询变更率衰减降低0.843%，QAUC指标提升0.81%，同时在抖音广告核心离线指标上均取得显著收益。实验结果验证了端到端多模态推荐在真实工业场景中的优越性。"
    },
    {
        "title": "Compact Multimodal Language Models as Robust OCR Alternatives for Noisy Textual Clinical Reports",
        "summary": "Digitization of medical records often relies on smartphone photographs of printed reports, producing images degraded by blur, shadows, and other noise. Conventional OCR systems, optimized for clean scans, perform poorly under such real-world conditions. This study evaluates compact multimodal language models as privacy-preserving alternatives for transcribing noisy clinical documents. Using obstetric ultrasound reports written in regionally inflected medical English common to Indian healthcare settings, we compare eight systems in terms of transcription accuracy, noise sensitivity, numeric accuracy, and computational efficiency. Compact multimodal models consistently outperform both classical and neural OCR pipelines. Despite higher computational costs, their robustness and linguistic adaptability position them as viable candidates for on-premises healthcare digitization.",
        "entry_id": "http://arxiv.org/abs/2511.13523v1",
        "pub_date": "2025-11-17",
        "translated_summary": "医疗记录数字化常依赖智能手机拍摄的印刷报告，但生成的图像常因模糊、阴影及其他噪点而质量受损。传统OCR系统虽针对洁净扫描文件优化，在此类现实场景中表现不佳。本研究评估了紧凑型多模态语言模型作为隐私保护方案，在转录含噪临床文档中的应用。通过采用印度医疗环境中常见的、带有地域特色医疗英语撰写的产科超声报告，我们从转录准确率、噪声敏感度、数字精确度及计算效率四个维度比较了八类系统。实验表明，紧凑型多模态模型持续优于传统与神经OCR流程。尽管其计算成本较高，但卓越的鲁棒性与语言适应性使其成为医疗本地化数字化可行的技术选择。"
    },
    {
        "title": "PolicyBot - Reliable Question Answering over Policy Documents",
        "summary": "All citizens of a country are affected by the laws and policies introduced by their government. These laws and policies serve essential functions for citizens. Such as granting them certain rights or imposing specific obligations. However, these documents are often lengthy, complex, and difficult to navigate, making it challenging for citizens to locate and understand relevant information. This work presents PolicyBot, a retrieval-augmented generation (RAG) system designed to answer user queries over policy documents with a focus on transparency and reproducibility. The system combines domain-specific semantic chunking, multilingual dense embeddings, multi-stage retrieval with reranking, and source-aware generation to provide responses grounded in the original documents. We implemented citation tracing to reduce hallucinations and improve user trust, and evaluated alternative retrieval and generation configurations to identify effective design choices. The end-to-end pipeline is built entirely with open-source tools, enabling easy adaptation to other domains requiring document-grounded question answering. This work highlights design considerations, practical challenges, and lessons learned in deploying trustworthy RAG systems for governance-related contexts.",
        "entry_id": "http://arxiv.org/abs/2511.13489v1",
        "pub_date": "2025-11-17",
        "translated_summary": "一国公民皆受政府制定的法律政策影响。这些法律政策承担着为公民赋予特定权利、规定相应义务等重要职能。然而此类文件往往篇幅冗长、内容复杂且难以检索，致使公民难以快速定位并理解相关信息。本文推出PolicyBot系统——一个注重透明度与可复现性的检索增强生成框架，专门用于基于政策文档的智能问答。该系统融合领域语义分块、多语言稠密嵌入、多阶段检索重排序及溯源感知生成技术，确保应答内容忠实于原始文献。我们通过实施引文溯源来减少幻觉生成并增强用户信任，同时评估了多种检索与生成方案以确定最优架构。该端到端系统完全基于开源工具构建，可轻松适配其他需基于文档的问答场景。本研究重点阐述了在政务相关场景中部署可信赖检索增强生成系统时的设计考量、实践挑战与经验总结。"
    },
    {
        "title": "Exploring Multi-Table Retrieval Through Iterative Search",
        "summary": "Open-domain question answering over datalakes requires retrieving and composing information from multiple tables, a challenging subtask that demands semantic relevance and structural coherence (e.g., joinability). While exact optimization methods like Mixed-Integer Programming (MIP) can ensure coherence, their computational complexity is often prohibitive. Conversely, simpler greedy heuristics that optimize for query coverage alone often fail to find these coherent, joinable sets. This paper frames multi-table retrieval as an iterative search process, arguing this approach offers advantages in scalability, interpretability, and flexibility. We propose a general framework and a concrete instantiation: a fast, effective Greedy Join-Aware Retrieval algorithm that holistically balances relevance, coverage, and joinability. Experiments across 5 NL2SQL benchmarks demonstrate that our iterative method achieves competitive retrieval performance compared to the MIP-based approach while being 4-400x faster depending on the benchmark and search space settings. This work highlights the potential of iterative heuristics for practical, scalable, and composition-aware retrieval.",
        "entry_id": "http://arxiv.org/abs/2511.13418v1",
        "pub_date": "2025-11-17",
        "translated_summary": "面向数据湖的开放域问答需从多表中检索并整合信息，这一具有挑战性的子任务既要求语义相关性又需保持结构连贯性（如可连接性）。虽然混合整数规划等精确优化方法能确保结构连贯，但其计算复杂度往往令人望而却步。相反，仅针对查询覆盖度进行优化的简单贪心启发式方法又难以找到这些具备连贯性的可连接表集合。本文将多表检索构建为迭代搜索过程，论证该方法在可扩展性、可解释性与灵活性方面的优势。我们提出通用框架及具体实现方案——一种快速高效的贪心连接感知检索算法，能够整体平衡相关性、覆盖度与可连接性。在5个NL2SQL基准测试中的实验表明，相较于基于混合整数规划的方法，我们的迭代检索方法在保持竞争力的同时，根据基准测试与搜索空间设置的不同，速度提升达4-400倍。这项研究揭示了迭代启发式方法在实现实用化、可扩展且具备组合感知能力的检索方面的潜力。"
    },
    {
        "title": "Attention Grounded Enhancement for Visual Document Retrieval",
        "summary": "Visual document retrieval requires understanding heterogeneous and multi-modal content to satisfy information needs. Recent advances use screenshot-based document encoding with fine-grained late interaction, significantly improving retrieval performance. However, retrievers are still trained with coarse global relevance labels, without revealing which regions support the match. As a result, retrievers tend to rely on surface-level cues and struggle to capture implicit semantic connections, hindering their ability to handle non-extractive queries. To alleviate this problem, we propose a \\textbf{A}ttention-\\textbf{G}rounded \\textbf{RE}triever \\textbf{E}nhancement (AGREE) framework. AGREE leverages cross-modal attention from multimodal large language models as proxy local supervision to guide the identification of relevant document regions. During training, AGREE combines local signals with the global signals to jointly optimize the retriever, enabling it to learn not only whether documents match, but also which content drives relevance. Experiments on the challenging ViDoRe V2 benchmark show that AGREE significantly outperforms the global-supervision-only baseline. Quantitative and qualitative analyses further demonstrate that AGREE promotes deeper alignment between query terms and document regions, moving beyond surface-level matching toward more accurate and interpretable retrieval. Our code is available at: https://anonymous.4open.science/r/AGREE-2025.",
        "entry_id": "http://arxiv.org/abs/2511.13415v1",
        "pub_date": "2025-11-17",
        "translated_summary": "视觉文档检索需理解异构多模态内容以满足信息需求。近期研究采用基于截图的文档编码与细粒度延迟交互机制，显著提升了检索性能。然而，检索模型仍使用粗粒度的全局相关性标签进行训练，未能揭示支持匹配的具体区域。这导致模型倾向于依赖表层线索，难以捕捉隐式语义关联，制约了处理非抽取式查询的能力。为缓解该问题，我们提出一种基于注意力定位的检索增强框架AGREE。该框架利用多模态大语言模型的跨模态注意力作为代理局部监督信号，引导模型识别相关文档区域。在训练过程中，AGREE将局部信号与全局信号结合以联合优化检索器，使其不仅能判断文档是否匹配，更能学习驱动相关性的具体内容。在具有挑战性的ViDoRe V2基准测试中，AGREE显著优于仅使用全局监督的基线模型。定量与定性分析进一步表明，AGREE促进了查询词与文档区域的深度对齐，实现了超越表层匹配的更精准、可解释的检索。代码已开源：https://anonymous.4open.science/r/AGREE-2025。"
    },
    {
        "title": "Uncovering Causal Drivers of Energy Efficiency for Industrial Process in Foundry via Time-Series Causal Inference",
        "summary": "Improving energy efficiency in industrial foundry processes is a critical challenge, as these operations are highly energy-intensive and marked by complex interdependencies among process variables. Correlation-based analyses often fail to distinguish true causal drivers from spurious associations, limiting their usefulness for decision-making. This paper applies a time-series causal inference framework to identify the operational factors that directly affect energy efficiency in induction furnace melting. Using production data from a Danish foundry, the study integrates time-series clustering to segment melting cycles into distinct operational modes with the PCMCI+ algorithm, a state-of-the-art causal discovery method, to uncover cause-effect relationships within each mode. Across clusters, robust causal relations among energy consumption, furnace temperature, and material weight define the core drivers of efficiency, while voltage consistently influences cooling water temperature with a delayed response. Cluster-specific differences further distinguish operational regimes: efficient clusters are characterized by stable causal structures, whereas inefficient ones exhibit reinforcing feedback loops and atypical dependencies. The contributions of this study are twofold. First, it introduces an integrated clustering-causal inference pipeline as a methodological innovation for analyzing energy-intensive processes. Second, it provides actionable insights that enable foundry operators to optimize performance, reduce energy consumption, and lower emissions.",
        "entry_id": "http://arxiv.org/abs/2511.13389v1",
        "pub_date": "2025-11-17",
        "translated_summary": "提升工业铸造过程的能源效率是一项关键挑战，因为这类工序属于高能耗作业，且工艺变量间存在复杂的相互依存关系。基于相关性的分析方法往往难以区分真正的因果驱动因素与伪相关性，限制了其在决策中的应用。本文运用时间序列因果推断框架，识别感应炉熔炼过程中直接影响能源效率的操作因素。通过整合丹麦某铸造厂的生产数据，研究采用时间序列聚类将熔炼周期划分为不同操作模式，并运用前沿因果发现算法PCMCI+揭示各模式内的因果关系。跨集群分析表明：能耗、炉温与物料重量间的强因果关系构成了能效的核心驱动因素，而电压对冷却水温的影响则始终存在延迟响应。集群间差异进一步区分了操作机制——高效集群以稳定的因果结构为特征，低效集群则表现出强化反馈回路与非典型依赖关系。本研究的贡献具有双重意义：方法论层面提出了融合聚类与因果推断的分析流程，为能源密集型工艺研究提供了创新工具；实践层面则为铸造企业优化生产性能、降低能耗与排放提供了可操作的见解。"
    },
    {
        "title": "FLOWER: Flow-Oriented Entity-Relationship Tool",
        "summary": "Exploring relationships across data sources is a crucial optimization for entities recognition. Since databases can store big amount of information with synthetic and organic data, serving all quantity of objects correctly is an important task to deal with. However, the decision of how to construct entity relationship model is associated with human factor. In this paper, we present flow-oriented entity-relationship tool. This is first and unique end-to-end solution that eliminates routine and resource-intensive problems of processing, creating and visualizing both of explicit and implicit dependencies for prominent SQL dialects on-the-fly. Once launched, FLOWER automatically detects built-in constraints and starting to create own correct and necessary one using dynamic sampling and robust data analysis techniques. This approach applies to improve entity-relationship model and data storytelling to better understand the foundation of data and get unseen insights from DB sources using SQL or natural language. Evaluated on state-of-the-art STATS benchmark, experiments show that FLOWER is superior to reservoir sampling by 2.4x for distribution representation and 2.6x for constraint learning with 2.15x acceleration. For data storytelling, our tool archives 1.19x for accuracy enhance with 1.86x context decrease compare to LLM. Presented tool is also support 23 languages and compatible with both of CPU and GPU. Those results show that FLOWER can manage with real-world data a way better to ensure with quality, scalability and applicability for different use-cases.",
        "entry_id": "http://arxiv.org/abs/2511.13357v1",
        "pub_date": "2025-11-17",
        "translated_summary": "跨数据源的关系探索是实体识别优化的关键环节。由于数据库能够存储包含合成数据与自然数据的大体量信息，正确处理全部对象成为重要任务。然而实体关系模型的构建方式往往受到人为因素影响。本文提出面向流程的实体关系工具FLOWER，这是首个端到端解决方案，能够实时消除主流SQL方言在处理、创建及可视化显性与隐性依赖时的重复性资源消耗问题。启动后，FLOWER自动检测内置约束，通过动态采样与鲁棒数据分析技术构建正确且必要的约束体系。该方法可优化实体关系模型与数据叙事功能，帮助用户深入理解数据基础，通过SQL或自然语言从数据库源获取潜在洞察。在STATS前沿基准测试中，FLOWER在分布表征方面较水库采样提升2.4倍，约束学习效率提高2.6倍，并实现2.15倍加速。在数据叙事方面，相比大语言模型准确度提升1.19倍，上下文依赖减少1.86倍。该工具支持23种语言，兼容CPU与GPU架构。实验结果表明FLOWER能更高效处理现实数据，在不同应用场景中确保质量、可扩展性与适用性。"
    },
    {
        "title": "Examining the Usage of Generative AI Models in Student Learning Activities for Software Programming",
        "summary": "The rise of Generative AI (GenAI) tools like ChatGPT has created new opportunities and challenges for computing education. Existing research has primarily focused on GenAI's ability to complete educational tasks and its impact on student performance, often overlooking its effects on knowledge gains. In this study, we investigate how GenAI assistance compares to conventional online resources in supporting knowledge gains across different proficiency levels. We conducted a controlled user experiment with 24 undergraduate students of two different levels of programming experience (beginner, intermediate) to examine how students interact with ChatGPT while solving programming tasks. We analyzed task performance, conceptual understanding, and interaction behaviors. Our findings reveal that generating complete solutions with GenAI significantly improves task performance, especially for beginners, but does not consistently result in knowledge gains. Importantly, usage strategies differ by experience: beginners tend to rely heavily on GenAI toward task completion often without knowledge gain in the process, while intermediates adopt more selective approaches. We find that both over-reliance and minimal use result in weaker knowledge gains overall. Based on our results, we call on students and educators to adopt GenAI as a learning rather than a problem solving tool. Our study highlights the urgent need for guidance when integrating GenAI into programming education to foster deeper understanding.",
        "entry_id": "http://arxiv.org/abs/2511.13271v1",
        "pub_date": "2025-11-17",
        "translated_summary": "以ChatGPT为代表的生成式人工智能工具兴起，为计算机教育带来新机遇与挑战。现有研究多聚焦于其完成任务的能力及对学习成绩的影响，却常忽视其对知识获取的作用。本研究通过对照实验，比较了不同编程基础的学习者在使用生成式AI与传统网络资源时知识获取的差异。我们招募24名具有初级与中级编程经验的本科生，观察其在完成编程任务时与ChatGPT的互动过程，从任务表现、概念理解及交互行为三个维度进行分析。研究发现：借助生成式AI生成完整解决方案能显著提升任务完成度（尤其对初学者），但未必转化为知识增长；更重要的是，使用策略因经验水平而异——初学者往往过度依赖AI完成作业却未获得知识提升，中级学习者则更善于选择性利用。研究表明，无论过度依赖还是极少使用都会削弱知识获取效果。基于此，我们呼吁师生将生成式AI定位为学习工具而非解题手段，并强调在编程教育中亟需建立引导机制，以促进深度理解。"
    },
    {
        "title": "Cog-RAG: Cognitive-Inspired Dual-Hypergraph with Theme Alignment Retrieval-Augmented Generation",
        "summary": "Retrieval-Augmented Generation (RAG) enhances the response quality and domain-specific performance of large language models (LLMs) by incorporating external knowledge to combat hallucinations. In recent research, graph structures have been integrated into RAG to enhance the capture of semantic relations between entities. However, it primarily focuses on low-order pairwise entity relations, limiting the high-order associations among multiple entities. Hypergraph-enhanced approaches address this limitation by modeling multi-entity interactions via hyperedges, but they are typically constrained to inter-chunk entity-level representations, overlooking the global thematic organization and alignment across chunks. Drawing inspiration from the top-down cognitive process of human reasoning, we propose a theme-aligned dual-hypergraph RAG framework (Cog-RAG) that uses a theme hypergraph to capture inter-chunk thematic structure and an entity hypergraph to model high-order semantic relations. Furthermore, we design a cognitive-inspired two-stage retrieval strategy that first activates query-relevant thematic content from the theme hypergraph, and then guides fine-grained recall and diffusion in the entity hypergraph, achieving semantic alignment and consistent generation from global themes to local details. Our extensive experiments demonstrate that Cog-RAG significantly outperforms existing state-of-the-art baseline approaches.",
        "entry_id": "http://arxiv.org/abs/2511.13201v1",
        "pub_date": "2025-11-17",
        "translated_summary": "检索增强生成（RAG）通过引入外部知识来抑制大语言模型的幻觉现象，有效提升其响应质量与领域适应性。近期研究将图结构引入RAG以增强实体间语义关系捕获，但主要聚焦于低阶成对实体关系，难以建模多实体间的高阶关联。超图增强方法通过超边建模多实体交互突破此局限，但通常局限于语块内部的实体级表征，未能兼顾跨语块的全局主题组织与对齐机制。受人类思维自上而下认知过程的启发，我们提出主题对齐的双超图RAG框架（Cog-RAG），通过主题超图捕捉语块间主题结构，利用实体超图建模高阶语义关系。进一步设计认知启发的两阶段检索策略：先从主题超图激活查询相关主题内容，再引导实体超图进行细粒度召回与扩散，实现从全局主题到局部细节的语义对齐与连贯生成。大量实验表明，Cog-RAG显著优于现有主流基线方法。"
    },
    {
        "title": "Large Language Models Meet Extreme Multi-label Classification: Scaling and Multi-modal Framework",
        "summary": "Foundation models have revolutionized artificial intelligence across numerous domains, yet their transformative potential remains largely untapped in Extreme Multi-label Classification (XMC). Queries in XMC are associated with relevant labels from extremely large label spaces, where it is critical to strike a balance between efficiency and performance. Therefore, many recent approaches efficiently pose XMC as a maximum inner product search between embeddings learned from small encoder-only transformer architectures. In this paper, we address two important aspects in XMC: how to effectively harness larger decoder-only models, and how to exploit visual information while maintaining computational efficiency. We demonstrate that both play a critical role in XMC separately and can be combined for improved performance. We show that a few billion-size decoder can deliver substantial improvements while keeping computational overhead manageable. Furthermore, our Vision-enhanced eXtreme Multi-label Learning framework (ViXML) efficiently integrates foundation vision models by pooling a single embedding per image. This limits computational growth while unlocking multi-modal capabilities. Remarkably, ViXML with small encoders outperforms text-only decoder in most cases, showing that an image is worth billions of parameters. Finally, we present an extension of existing text-only datasets to exploit visual metadata and make them available for future benchmarking. Comprehensive experiments across four public text-only datasets and their corresponding image enhanced versions validate our proposals' effectiveness, surpassing previous state-of-the-art by up to +8.21\\% in P@1 on the largest dataset. ViXML's code is available at https://github.com/DiegoOrtego/vixml.",
        "entry_id": "http://arxiv.org/abs/2511.13189v1",
        "pub_date": "2025-11-17",
        "translated_summary": "基础模型已在众多领域引发人工智能革命，然而其在极端多标签分类（XMC）领域的变革潜力仍待开发。XMC任务需从极大规模标签空间中为查询匹配相关标签，其核心挑战在于效率与性能的平衡。为此，近期研究多采用仅含编码器的小型Transformer架构学习嵌入向量，将XMC高效转化为最大内积搜索问题。本文聚焦XMC两大关键方向：如何有效利用仅含解码器的大型模型，以及如何在保持计算效率的同时整合视觉信息。我们证明这两个方向各自具有重要价值，且能协同提升性能。实验表明，数十亿参数的解码器可在可控计算开销下实现显著性能提升。进一步提出的视觉增强极端多标签学习框架（ViXML）通过单图像嵌入池化技术，在限制计算增长的同时成功融合基础视觉模型，解锁多模态能力。值得注意的是，采用小型编码器的ViXML在多数场景下优于纯文本解码器，印证“一图胜千言”的效能。此外，我们还将现有纯文本数据集扩展为包含视觉元数据的版本，为后续研究提供基准平台。在四个公开纯文本数据集及其图像增强版本上的综合实验验证了方案有效性，在最大数据集上P@1指标较之前最优成果提升达8.21%。ViXML代码已开源：https://github.com/DiegoOrtego/vixml。"
    },
    {
        "title": "Local Collaborative Filtering: A Collaborative Filtering Method that Utilizes Local Similarities among Users",
        "summary": "To leverage user behavior data from the Internet more effectively in recommender systems, this paper proposes a novel collaborative filtering (CF) method called Local Collaborative Filtering (LCF). LCF utilizes local similarities among users and integrates their data using the law of large numbers (LLN), thereby improving the utilization of user behavior data. Experiments are conducted on the Steam game dataset, and the results of LCF align with real-world needs.",
        "entry_id": "http://arxiv.org/abs/2511.13166v1",
        "pub_date": "2025-11-17",
        "translated_summary": "为更有效地利用互联网用户行为数据，本文提出一种新颖的协同过滤方法——局部协同过滤(LCF)。该方法通过挖掘用户间的局部相似性，运用大数定律整合用户数据，从而提升用户行为数据的利用率。在Steam游戏数据集上的实验表明，LCF方法的推荐效果符合现实需求。"
    },
    {
        "title": "Region-Point Joint Representation for Effective Trajectory Similarity Learning",
        "summary": "Recent learning-based methods have reduced the computational complexity of traditional trajectory similarity computation, but state-of-the-art (SOTA) methods still fail to leverage the comprehensive spectrum of trajectory information for similarity modeling. To tackle this problem, we propose \\textbf{RePo}, a novel method that jointly encodes \\textbf{Re}gion-wise and \\textbf{Po}int-wise features to capture both spatial context and fine-grained moving patterns. For region-wise representation, the GPS trajectories are first mapped to grid sequences, and spatial context are captured by structural features and semantic context enriched by visual features. For point-wise representation, three lightweight expert networks extract local, correlation, and continuous movement patterns from dense GPS sequences. Then, a router network adaptively fuses the learned point-wise features, which are subsequently combined with region-wise features using cross-attention to produce the final trajectory embedding. To train RePo, we adopt a contrastive loss with hard negative samples to provide similarity ranking supervision. Experiment results show that RePo achieves an average accuracy improvement of 22.2\\% over SOTA baselines across all evaluation metrics.",
        "entry_id": "http://arxiv.org/abs/2511.13125v1",
        "pub_date": "2025-11-17",
        "translated_summary": "近年来基于学习的方法虽然降低了传统轨迹相似性计算的时间复杂度，但现有最优方法仍未能充分利用轨迹信息的完整频谱进行相似性建模。为解决这一问题，我们提出\\textbf{RePo}方法，通过联合编码\\textbf{区域级}与\\textbf{点级}特征来同时捕捉空间上下文和细粒度移动模式。在区域级表征方面，首先将GPS轨迹映射为网格序列，通过结构特征捕捉空间上下文，并借助视觉特征增强语义上下文；在点级表征方面，三个轻量级专家网络分别从密集GPS序列中提取局部特征、关联特征和连续移动模式。随后通过路由网络自适应融合点级特征，再与区域级特征进行交叉注意力融合生成最终轨迹嵌入。我们采用包含困难负样本的对比损失函数进行模型训练，以提供相似度排序监督。实验结果表明，在所有评估指标上，RePo相较现有最优基线模型平均准确率提升22.2\\%。"
    },
    {
        "title": "FGNet: Leveraging Feature-Guided Attention to Refine SAM2 for 3D EM Neuron Segmentation",
        "summary": "Accurate segmentation of neural structures in Electron Microscopy (EM) images is paramount for neuroscience. However, this task is challenged by intricate morphologies, low signal-to-noise ratios, and scarce annotations, limiting the accuracy and generalization of existing methods. To address these challenges, we seek to leverage the priors learned by visual foundation models on a vast amount of natural images to better tackle this task. Specifically, we propose a novel framework that can effectively transfer knowledge from Segment Anything 2 (SAM2), which is pre-trained on natural images, to the EM domain. We first use SAM2 to extract powerful, general-purpose features. To bridge the domain gap, we introduce a Feature-Guided Attention module that leverages semantic cues from SAM2 to guide a lightweight encoder, the Fine-Grained Encoder (FGE), in focusing on these challenging regions. Finally, a dual-affinity decoder generates both coarse and refined affinity maps. Experimental results demonstrate that our method achieves performance comparable to state-of-the-art (SOTA) approaches with the SAM2 weights frozen. Upon further fine-tuning on EM data, our method significantly outperforms existing SOTA methods. This study validates that transferring representations pre-trained on natural images, when combined with targeted domain-adaptive guidance, can effectively address the specific challenges in neuron segmentation.",
        "entry_id": "http://arxiv.org/abs/2511.13063v1",
        "pub_date": "2025-11-17",
        "translated_summary": "电子显微镜图像中神经结构的精确分割对神经科学研究至关重要。然而，该任务面临形态结构复杂、信噪比低及标注稀缺等挑战，限制了现有方法的准确性与泛化能力。为解决这些问题，我们尝试利用视觉基础模型在自然图像上学习到的先验知识来改进分割性能。具体而言，我们提出了一种创新框架，能够将基于自然图像预训练的SAM2模型的知识有效迁移至电子显微镜领域。该框架首先通过SAM2提取强泛化性的通用特征；为弥合领域差异，我们设计了特征引导注意力模块，利用SAM2的语义线索引导轻量级精细编码器聚焦于困难区域；最后通过双亲和度解码器同步生成粗粒度与精细化亲和力图。实验结果表明，在冻结SAM2权重的情况下，我们的方法已达到与现有最优方法相当的精度；当在电子显微镜数据上进行微调后，其性能显著超越当前最优方法。本研究证实：结合针对性领域自适应引导，迁移自然图像预训练表征能有效解决神经元分割中的特定挑战。"
    },
    {
        "title": "Dimension vs. Precision: A Comparative Analysis of Autoencoders and Quantization for Efficient Vector Retrieval on BEIR SciFact",
        "summary": "Dense retrieval models have become a standard for state-of-the-art information retrieval. However, their high-dimensional, high-precision (float32) vector embeddings create significant storage and memory challenges for real-world deployment. To address this, we conduct a rigorous empirical study on the BEIR SciFact benchmark, evaluating the trade-offs between two primary compression strategies: (1) Dimensionality Reduction via deep Autoencoders (AE), reducing original 384-dim vectors to latent spaces from 384 down to 12, and (2) Precision Reduction via Quantization (float16, int8, and binary). We systematically compare each method by measuring the \"performance loss\" (or gain) relative to a float32 baseline across a full suite of retrieval metrics (NDCG, MAP, MRR, Recall, Precision) at various k cutoffs. Our results show that int8 scalar quantization provides the most effective \"sweet spot,\" achieving a 4x compression with a negligible [~1-2%] drop in nDCG@10. In contrast, Autoencoders show a graceful degradation but suffer a more significant performance loss at equivalent 4x compression ratios (AE-96). binary quantization was found to be unsuitable for this task due to catastrophic performance drops. This work provides a practical guide for deploying efficient, high-performance retrieval systems.",
        "entry_id": "http://arxiv.org/abs/2511.13057v1",
        "pub_date": "2025-11-17",
        "translated_summary": "稠密检索模型已成为信息检索领域的最先进标准。然而其高维度、高精度（float32）的向量嵌入在实际部署中带来了显著的存储与内存挑战。为应对此问题，我们在BEIR SciFact基准上开展严格实证研究，评估两种主要压缩策略的平衡关系：（1）通过深度自编码器实现维度压缩，将原始384维向量降至12维潜在空间；（2）通过量化实现精度压缩（float16、int8与二值化）。我们通过全套检索指标（NDCG、MAP、MRR、召回率、精确度）在不同k值截断点上相对float32基线的“性能损失（或增益）”，对每种方法进行系统比较。实验结果表明：int8标量量化能提供最佳平衡点，在实现4倍压缩的同时，nDCG@10指标仅出现可忽略的[约1-2%]下降；而自编码器虽呈现平缓的性能衰减，但在同等4倍压缩比（AE-96）下会出现更显著的性能损失；二值化量化由于会导致性能急剧下降，被证明不适用于此任务。本研究为部署高效能检索系统提供了实用指南。"
    },
    {
        "title": "Mitigating Recommendation Biases via Group-Alignment and Global-Uniformity in Representation Learning",
        "summary": "Collaborative Filtering~(CF) plays a crucial role in modern recommender systems, leveraging historical user-item interactions to provide personalized suggestions. However, CF-based methods often encounter biases due to imbalances in training data. This phenomenon makes CF-based methods tend to prioritize recommending popular items and performing unsatisfactorily on inactive users. Existing works address this issue by rebalancing training samples, reranking recommendation results, or making the modeling process robust to the bias. Despite their effectiveness, these approaches can compromise accuracy or be sensitive to weighting strategies, making them challenging to train. In this paper, we deeply analyze the causes and effects of the biases and propose a framework to alleviate biases in recommendation from the perspective of representation distribution, namely Group-Alignment and Global-Uniformity Enhanced Representation Learning for Debiasing Recommendation (AURL). Specifically, we identify two significant problems in the representation distribution of users and items, namely group-discrepancy and global-collapse. These two problems directly lead to biases in the recommendation results. To this end, we propose two simple but effective regularizers in the representation space, respectively named group-alignment and global-uniformity. The goal of group-alignment is to bring the representation distribution of long-tail entities closer to that of popular entities, while global-uniformity aims to preserve the information of entities as much as possible by evenly distributing representations. Our method directly optimizes both the group-alignment and global-uniformity regularization terms to mitigate recommendation biases. Extensive experiments on three real datasets and various recommendation backbones verify the superiority of our proposed framework.",
        "entry_id": "http://arxiv.org/abs/2511.13041v1",
        "pub_date": "2025-11-17",
        "translated_summary": "协同过滤技术在现代推荐系统中发挥着关键作用，它通过分析用户与项目的交互历史来实现个性化推荐。然而基于协同过滤的方法常因训练数据不平衡而产生偏差，这种倾向会导致系统优先推荐热门项目，而对非活跃用户的推荐效果欠佳。现有研究通过重平衡训练样本、重排推荐结果或建立对偏差具有鲁棒性的模型来解决这一问题。这些方法虽有效，但可能影响推荐准确性，或对权重策略过于敏感，导致模型训练困难。本文深入分析了推荐偏差的成因与影响，从表示分布视角提出去偏框架AURL，通过增强表征学习中的群组对齐与全局一致性来实现推荐去偏。具体而言，我们发现了用户与项目表示分布中存在的两个核心问题：群组差异与全局坍缩，这两者直接导致推荐结果产生偏差。为此，我们在表示空间中设计了两个简洁有效的正则化器：群组对齐器致力于拉近长尾实体与热门实体的表示分布，全局一致性器则通过均匀分布表示来最大限度保留实体信息。我们的方法通过同步优化群组对齐与全局一致性正则项来缓解推荐偏差。在三个真实数据集和多种推荐骨干网络上进行的广泛实验，验证了所提框架的优越性。"
    },
    {
        "title": "Personalized Federated Recommendation With Knowledge Guidance",
        "summary": "Federated Recommendation (FedRec) has emerged as a key paradigm for building privacy-preserving recommender systems. However, existing FedRec models face a critical dilemma: memory-efficient single-knowledge models suffer from a suboptimal knowledge replacement practice that discards valuable personalization, while high-performance dual-knowledge models are often too memory-intensive for practical on-device deployment. We propose Federated Recommendation with Knowledge Guidance (FedRKG), a model-agnostic framework that resolves this dilemma. The core principle, Knowledge Guidance, avoids full replacement and instead fuses global knowledge into preserved local embeddings, attaining the personalization benefits of dual-knowledge within a single-knowledge memory footprint. Furthermore, we introduce Adaptive Guidance, a fine-grained mechanism that dynamically modulates the intensity of this guidance for each user-item interaction, overcoming the limitations of static fusion methods. Extensive experiments on benchmark datasets demonstrate that FedRKG significantly outperforms state-of-the-art methods, validating the effectiveness of our approach. The code is available at https://github.com/Jaehyung-Lim/fedrkg.",
        "entry_id": "http://arxiv.org/abs/2511.12959v1",
        "pub_date": "2025-11-17",
        "translated_summary": "联邦推荐系统已成为构建隐私保护推荐系统的关键范式。然而现有联邦推荐模型面临核心困境：内存高效的单一知识模型受限于次优的知识替换机制，导致有价值的个性化信息被丢弃；而高性能的双知识模型因内存占用过高难以在实际设备上部署。我们提出知识引导的联邦推荐框架FedRKG，这一模型无关的解决方案通过\"知识引导\"核心原则，避免完全替换而将全局知识融合到保留的本地嵌入中，在单一知识内存占用量下实现双知识模型的个性化优势。进一步提出自适应引导机制，通过细粒度动态调节每个用户-项目交互的引导强度，克服静态融合方法的局限性。在基准数据集上的大量实验表明，FedRKG显著优于现有最优方法，验证了本方法的有效性。代码已开源：https://github.com/Jaehyung-Lim/fedrkg。"
    },
    {
        "title": "Can We Predict the Next Question? A Collaborative Filtering Approach to Modeling User Behavior",
        "summary": "In recent years, large language models (LLMs) have excelled in language understanding and generation, powering advanced dialogue and recommendation systems. However, a significant limitation persists: these systems often model user preferences statically, failing to capture the dynamic and sequential nature of interactive behaviors. The sequence of a user's historical questions provides a rich, implicit signal of evolving interests and cognitive patterns, yet leveraging this temporal data for predictive tasks remains challenging due to the inherent disconnect between language modeling and behavioral sequence modeling.\n  To bridge this gap, we propose a Collaborative Filtering-enhanced Question Prediction (CFQP) framework. CFQP dynamically models evolving user-question interactions by integrating personalized memory modules with graph-based preference propagation. This dual mechanism allows the system to adaptively learn from user-specific histories while refining predictions through collaborative signals from similar users. Experimental results demonstrate that our approach effectively generates agents that mimic real-user questioning patterns, highlighting its potential for building proactive and adaptive dialogue systems.",
        "entry_id": "http://arxiv.org/abs/2511.12949v1",
        "pub_date": "2025-11-17",
        "translated_summary": "近年来，大语言模型在语言理解与生成任务中表现出色，推动了智能对话和推荐系统的发展。然而这些系统仍存在显著局限：往往以静态方式建模用户偏好，难以捕捉交互行为中动态连续的潜在规律。用户历史提问序列隐含着兴趣演变与认知模式的丰富信号，但由于语言建模与行为序列建模之间存在固有割裂，如何利用这类时序数据进行预测仍具挑战。\n\n为突破这一局限，我们提出协同过滤增强的提问预测框架。该框架通过融合个性化记忆模块与基于图的偏好传播机制，动态建模用户-问题交互的演变过程。这种双重机制使系统既能自适应学习用户特定历史，又能借助相似用户的协同信号优化预测。实验结果表明，我们的方法可有效生成模拟真实用户提问模式的智能体，展现了构建前瞻自适应对话系统的潜力。"
    },
    {
        "title": "A Plug-and-Play Spatially-Constrained Representation Enhancement Framework for Local-Life Recommendation",
        "summary": "Local-life recommendation have witnessed rapid growth, providing users with convenient access to daily essentials. However, this domain faces two key challenges: (1) spatial constraints, driven by the requirements of the local-life scenario, where items are usually shown only to users within a limited geographic area, indirectly reducing their exposure probability; and (2) long-tail sparsity, where few popular items dominate user interactions, while many high-quality long-tail items are largely overlooked due to imbalanced interaction opportunities. Existing methods typically adopt a user-centric perspective, such as modeling spatial user preferences or enhancing long-tail representations with collaborative filtering signals. However, we argue that an item-centric perspective is more suitable for this domain, focusing on enhancing long-tail items representation that align with the spatially-constrained characteristics of local lifestyle services. To tackle this issue, we propose ReST, a Plug-And-Play Spatially-Constrained Representation Enhancement Framework for Long-Tail Local-Life Recommendation. Specifically, we first introduce a Meta ID Warm-up Network, which initializes fundamental ID representations by injecting their basic attribute-level semantic information. Subsequently, we propose a novel Spatially-Constrained ID Representation Enhancement Network (SIDENet) based on contrastive learning, which incorporates two efficient strategies: a spatially-constrained hard sampling strategy and a dynamic representation alignment strategy. This design adaptively identifies weak ID representations based on their attribute-level information during training. It additionally enhances them by capturing latent item relationships within the spatially-constrained characteristics of local lifestyle services, while preserving compatibility with popular items.",
        "entry_id": "http://arxiv.org/abs/2511.12947v1",
        "pub_date": "2025-11-17",
        "translated_summary": "本地生活推荐服务近年来快速发展，为用户获取日常所需提供了便捷途径。然而该领域面临两大核心挑战：（1）空间约束性——受本地生活场景特性影响，商品通常仅向有限地理范围内的用户展示，间接降低了商品曝光概率；（2）长尾稀疏性——少数热门商品占据大部分用户交互记录，而大量优质长尾商品因交互机会失衡被严重忽视。现有方法多采用用户中心视角，例如建模空间用户偏好或利用协同过滤信号增强长尾表征。但我们认为，基于商品中心的视角更能契合该领域特性，应聚焦于增强符合本地生活服务空间约束特征的长尾商品表征。为此，我们提出ReST框架——一种即插即用的空间约束表征增强框架。具体而言，我们首先设计元ID预热网络，通过注入基础属性层级语义信息来初始化ID表征；随后提出基于对比学习的空间约束ID表征增强网络（SIDENet），该网络融合两项高效策略：空间约束硬采样策略与动态表征对齐策略。该设计能在训练过程中基于属性信息自适应识别弱表征ID，通过捕捉本地生活服务空间约束特性下的潜在商品关联来增强其表征，同时保持与热门商品的兼容性。"
    },
    {
        "title": "AIF: Asynchronous Inference Framework for Cost-Effective Pre-Ranking",
        "summary": "In industrial recommendation systems, pre-ranking models based on deep neural networks (DNNs) commonly adopt a sequential execution framework: feature fetching and model forward computation are triggered only after receiving candidates from the upstream retrieval stage. This design introduces inherent bottlenecks, including redundant computations of identical users/items and increased latency due to strictly sequential operations, which jointly constrain the model's capacity and system efficiency. To address these limitations, we propose the Asynchronous Inference Framework (AIF), a cost-effective computational architecture that decouples interaction-independent components, those operating within a single user or item, from real-time prediction. AIF reorganizes the model inference process by performing user-side computations in parallel with the retrieval stage and conducting item-side computations in a nearline manner. This means that interaction-independent components are calculated just once and completed before the real-time prediction phase of the pre-ranking stage. As a result, AIF enhances computational efficiency and reduces latency, freeing up resources to significantly improve the feature set and model architecture of interaction-independent components. Moreover, we delve into model design within the AIF framework, employing approximated methods for interaction-dependent components in online real-time predictions. By co-designing both the framework and the model, our solution achieves notable performance gains without significantly increasing computational and latency costs. This has enabled the successful deployment of AIF in the Taobao display advertising system.",
        "entry_id": "http://arxiv.org/abs/2511.12934v1",
        "pub_date": "2025-11-17",
        "translated_summary": "在工业推荐系统中，基于深度神经网络（DNN）的粗排模型通常采用顺序执行框架：只有在接收到上游召回阶段的候选集后，才会触发特征获取和模型前向计算。这种设计存在固有瓶颈，包括对相同用户/项目的重复计算，以及严格顺序操作带来的延迟增加，这些因素共同制约了模型容量与系统效率。为突破这些限制，我们提出异步推理框架（AIF），这是一种高效经济的计算架构，其核心在于将交互无关组件（即仅涉及单一用户或项目内部运算的模块）从实时预测中解耦。AIF通过以下方式重构模型推理流程：用户侧计算与召回阶段并行执行，项目侧计算则采用近线处理模式。这意味着交互无关组件的计算仅需执行一次，并在粗排阶段实时预测开始前完成。该架构显著提升了计算效率并降低延迟，释放的资源使得交互无关组件的特征集与模型架构得以显著优化。此外，我们深入探索了AIF框架内的模型设计，对线上实时预测中的交互相关组件采用近似计算方法。通过框架与模型的协同设计，我们的解决方案在不显著增加计算与延迟成本的前提下实现了显著性能提升，目前已在淘宝展示广告系统成功部署。"
    },
    {
        "title": "Tokenize Once, Recommend Anywhere: Unified Item Tokenization for Multi-domain LLM-based Recommendation",
        "summary": "Large language model (LLM)-based recommender systems have achieved high-quality performance by bridging the discrepancy between the item space and the language space through item tokenization. However, existing item tokenization methods typically require training separate models for each item domain, limiting generalization. Moreover, the diverse distributions and semantics across item domains make it difficult to construct a unified tokenization that preserves domain-specific information. To address these challenges, we propose UniTok, a Unified item Tokenization framework that integrates our own mixture-of-experts (MoE) architecture with a series of codebooks to convert items into discrete tokens, enabling scalable tokenization while preserving semantic information across multiple item domains. Specifically, items from different domains are first projected into a unified latent space through a shared encoder. They are then routed to domain-specific experts to capture the unique semantics, while a shared expert, which is always active, encodes common knowledge transferable across domains. Additionally, to mitigate semantic imbalance across domains, we present a mutual information calibration mechanism, which guides the model towards retaining similar levels of semantic information for each domain. Comprehensive experiments on wide-ranging real-world datasets demonstrate that the proposed UniTok framework is (a) highly effective: achieving up to 51.89% improvements over strong benchmarks, (b) theoretically sound: showing the analytical validity of our architectural design and optimization; and (c) highly generalizable: demonstrating robust performance across diverse domains without requiring per-domain retraining, a capability not supported by existing baselines.",
        "entry_id": "http://arxiv.org/abs/2511.12922v1",
        "pub_date": "2025-11-17",
        "translated_summary": "基于大语言模型的推荐系统通过项目标记化技术弥合项目空间与语言空间之间的差异，实现了高质量的推荐性能。然而，现有的项目标记化方法通常需要为每个项目领域单独训练模型，限制了泛化能力。同时，不同项目领域间分布与语义的差异性使得构建能保留领域特异性信息的统一标记化面临挑战。为此，我们提出UniTok——一个统一的项目标记化框架，通过将混合专家架构与系列码本相结合，将项目转化为离散标记，在实现可扩展标记化的同时保留跨领域语义信息。具体而言，不同领域的项目首先通过共享编码器投射到统一潜在空间，随后被路由至领域特定专家以捕获独特语义，而始终保持激活状态的共享专家则负责编码可跨领域迁移的通用知识。此外，为缓解领域间语义不均衡问题，我们提出互信息校准机制，引导模型为各领域保留相近层级的语义信息。基于多领域真实数据集的综合实验表明，UniTok框架具有以下优势：（a）高效性：在强基准测试中实现最高51.89%的性能提升；（b）理论严谨性：架构设计与优化的分析有效性得到验证；（c）强泛化性：无需针对每个领域重新训练即可在多样化领域保持稳健性能，这是现有基线方法所不具备的能力。"
    },
    {
        "title": "Auditing Google's AI Overviews and Featured Snippets: A Case Study on Baby Care and Pregnancy",
        "summary": "Google Search increasingly surfaces AI-generated content through features like AI Overviews (AIO) and Featured Snippets (FS), which users frequently rely on despite having no control over their presentation. Through a systematic algorithm audit of 1,508 real baby care and pregnancy-related queries, we evaluate the quality and consistency of these information displays. Our robust evaluation framework assesses multiple quality dimensions, including answer consistency, relevance, presence of medical safeguards, source categories, and sentiment alignment. Our results reveal concerning gaps in information consistency, with information in AIO and FS displayed on the same search result page being inconsistent with each other in 33% of cases. Despite high relevance scores, both features critically lack medical safeguards (present in just 11% of AIO and 7% of FS responses). While health and wellness websites dominate source categories for both, AIO and FS, FS also often link to commercial sources. These findings have important implications for public health information access and demonstrate the need for stronger quality controls in AI-mediated health information. Our methodology provides a transferable framework for auditing AI systems across high-stakes domains where information quality directly impacts user well-being.",
        "entry_id": "http://arxiv.org/abs/2511.12920v1",
        "pub_date": "2025-11-17",
        "translated_summary": "谷歌搜索正通过\"AI概览\"和\"精选摘要\"等功能呈现越来越多AI生成内容，用户虽无法控制其呈现形式却日益依赖。本研究通过对1,508个真实育儿及孕期相关查询进行系统算法审计，评估了这些信息展示的质量与一致性。我们构建的稳健评估框架涵盖多维度质量指标：答案一致性、相关性、医疗安全措施、信息来源类型及情感倾向。研究结果显示，同一搜索结果页面上AI概览与精选摘要的信息不一致率高达33%。尽管相关性评分普遍较高，但两者均严重缺乏医疗安全提示（AI概览仅11%含警示，精选摘要仅7%）。在信息来源方面，健康类网站虽占主导，但精选摘要还频繁链接商业来源。这些发现对公共卫生信息获取具有重要意义，表明AI赋能的健康信息亟需更严格的质量管控。本研究方法论为审计高风险领域AI系统提供了可迁移框架，这些领域的信息质量直接关系用户福祉。"
    },
    {
        "title": "NeuCLIRBench: A Modern Evaluation Collection for Monolingual, Cross-Language, and Multilingual Information Retrieval",
        "summary": "To measure advances in retrieval, test collections with relevance judgments that can faithfully distinguish systems are required. This paper presents NeuCLIRBench, an evaluation collection for cross-language and multilingual retrieval. The collection consists of documents written natively in Chinese, Persian, and Russian, as well as those same documents machine translated into English. The collection supports several retrieval scenarios including: monolingual retrieval in English, Chinese, Persian, or Russian; cross-language retrieval with English as the query language and one of the other three languages as the document language; and multilingual retrieval, again with English as the query language and relevant documents in all three languages. NeuCLIRBench combines the TREC NeuCLIR track topics of 2022, 2023, and 2024. The 250,128 judgments across approximately 150 queries for the monolingual and cross-language tasks and 100 queries for multilingual retrieval provide strong statistical discriminatory power to distinguish retrieval approaches. A fusion baseline of strong neural retrieval systems is included with the collection so that developers of reranking algorithms are no longer reliant on BM25 as their first-stage retriever. NeuCLIRBench is publicly available.",
        "entry_id": "http://arxiv.org/abs/2511.14758v1",
        "pub_date": "2025-11-18",
        "translated_summary": "为有效衡量检索技术的进展，需要具备能够准确区分系统性能的相关性评估测试集。本文推出NeuCLIRBench——一个面向跨语言与多语言检索的评估数据集。该数据集包含中文、波斯语和俄语的原始文档，以及这些文档经机器翻译后的英文版本，支持多种检索场景：英语、中文、波斯语或俄语的单语检索；以英语为查询语言、其他三种语言之一为文档语言的跨语言检索；以及以英语为查询语言、三种语言文档均需检索的多语言检索。该数据集整合了TREC NeuCLIR赛道2022至2024年的全部主题，包含单语及跨语言任务约150个查询的250,128条评估结果，以及多语言检索100个查询的评估数据，具备强大的统计区分能力以甄别不同检索方法。数据集还提供了强神经检索系统的融合基线，使重排序算法开发者无需再依赖BM25作为首阶段检索器。NeuCLIRBench已面向公众开放。"
    },
    {
        "title": "LiveRAG: A diverse Q&A dataset with varying difficulty level for RAG evaluation",
        "summary": "With Retrieval Augmented Generation (RAG) becoming more and more prominent in generative AI solutions, there is an emerging need for systematically evaluating their effectiveness. We introduce the LiveRAG benchmark, a publicly available dataset of 895 synthetic questions and answers designed to support systematic evaluation of RAG-based Q&A systems. This synthetic benchmark is derived from the one used during the SIGIR'2025 LiveRAG Challenge, where competitors were evaluated under strict time constraints. It is augmented with information that was not made available to competitors during the Challenge, such as the ground-truth answers, together with their associated supporting claims which were used for evaluating competitors' answers. In addition, each question is associated with estimated difficulty and discriminability scores, derived from applying an Item Response Theory model to competitors' responses. Our analysis highlights the benchmark's questions diversity, the wide range of their difficulty levels, and their usefulness in differentiating between system capabilities. The LiveRAG benchmark will hopefully help the community advance RAG research, conduct systematic evaluation, and develop more robust Q&A systems.",
        "entry_id": "http://arxiv.org/abs/2511.14531v1",
        "pub_date": "2025-11-18",
        "translated_summary": "随着检索增强生成(RAG)技术在生成式AI解决方案中的地位日益凸显，系统化评估其效能的需求也愈发迫切。我们推出LiveRAG基准测试——一个包含895组合成问答对的公开数据集，专为支持基于RAG的问答系统进行系统性评估而设计。该合成基准源自SIGIR'2025 LiveRAG挑战赛的竞赛题库，所有参赛者曾在严格时间限制下接受该题库的测试。当前版本新增了挑战赛期间未公开的关键信息，包括用于评估参赛答案的基准答案及其支撑依据。此外，通过将项目反应理论模型应用于参赛者答题数据，我们为每个问题标注了预估难度系数与区分度指数。分析表明，该基准测试兼具问题多样性、难度广谱性以及系统能力区分度三大特性。期待LiveRAG基准能助力学界推进RAG研究、实施系统化评估，并开发出更稳健的问答系统。"
    },
    {
        "title": "Effective Diversification of Multi-Carousel Book Recommendation",
        "summary": "Using multiple carousels, lists that wrap around and can be scrolled, is the basis for offering content in most contemporary movie streaming platforms. Carousels allow for highlighting different aspects of users' taste, that fall in categories such as genres and authors. However, while carousels offer structure and greater ease of navigation, they alone do not increase diversity in recommendations, while this is essential to keep users engaged. In this work we propose several approaches to effectively increase item diversity within the domain of book recommendations, on top of a collaborative filtering algorithm. These approaches are intended to improve book recommendations in the web catalogs of public libraries. Furthermore, we introduce metrics to evaluate the resulting strategies, and show that the proposed system finds a suitable balance between accuracy and beyond-accuracy aspects.",
        "entry_id": "http://arxiv.org/abs/2511.14461v1",
        "pub_date": "2025-11-18",
        "translated_summary": "在当代大多数电影流媒体平台中，采用可循环滚动的多轮播列表已成为内容呈现的基本模式。这种设计通过类型、作者等分类维度，有效凸显用户兴趣的不同面向。尽管轮播界面能优化信息结构与导航效率，但单纯依靠这种形式并不能提升推荐内容的多样性——而多样性恰恰是维持用户参与度的关键要素。本研究基于协同过滤算法，提出多种有效提升图书推荐多样性的解决方案，旨在优化公共图书馆线上目录的荐书体系。我们同时建立了评估指标体系，通过实验证明该推荐系统能够在准确性与超准确性指标之间实现良好平衡。"
    },
    {
        "title": "Jasper-Token-Compression-600M Technical Report",
        "summary": "This technical report presents the training methodology and evaluation results of the open-source Jasper-Token-Compression-600M model, released in November 2025. Building on previous distillation-based recipes from the English Stella and Jasper models, we successfully extend this approach to a bilingual (English and Chinese) domain, further enhancing model performance through the incorporation of contrastive learning. A key innovation of our model is the introduction of a one-dimensional convolution-based token compression module. We dynamically adjust the compression rate during training, enabling the model to learn more robust and efficient compressed text representations. By combining knowledge distillation with token compression techniques, we achieve significant improvements in both embedding quality and inference efficiency. Our model performs with higher efficiency than a traditional 0.6B model while achieving performance comparable to that of an 8B model. For more information on the model release, visit: https://huggingface.co/infgrad/Jasper-Token-Compression-600M.",
        "entry_id": "http://arxiv.org/abs/2511.14405v1",
        "pub_date": "2025-11-18",
        "translated_summary": "本技术报告介绍了2025年11月发布的开源Jasper-Token-Compression-600M模型的训练方法与评估结果。基于先前英文Stella和Jasper模型的蒸馏方案，我们成功将该方法扩展至中英双语领域，并通过引入对比学习进一步提升了模型性能。本模型的核心创新在于引入基于一维卷积的令牌压缩模块，通过动态调整训练过程中的压缩率，使模型能够学习更鲁棒、更高效的压缩文本表示。通过将知识蒸馏与令牌压缩技术相结合，我们在嵌入质量和推理效率两方面均实现了显著提升。该模型在达到与80亿参数模型相当性能的同时，运行效率显著优于传统的6亿参数模型。更多模型发布信息请访问：https://huggingface.co/infgrad/Jasper-Token-Compression-600M。"
    },
    {
        "title": "Infer As You Train: A Symmetric Paradigm of Masked Generative for Click-Through Rate Prediction",
        "summary": "Generative models are increasingly being explored in click-through rate (CTR) prediction field to overcome the limitations of the conventional discriminative paradigm, which rely on a simple binary classification objective. However, existing generative models typically confine the generative paradigm to the training phase, primarily for representation learning. During online inference, they revert to a standard discriminative paradigm, failing to leverage their powerful generative capabilities to further improve prediction accuracy. This fundamental asymmetry between the training and inference phases prevents the generative paradigm from realizing its full potential. To address this limitation, we propose the Symmetric Masked Generative Paradigm for CTR prediction (SGCTR), a novel framework that establishes symmetry between the training and inference phases. Specifically, after acquiring generative capabilities by learning feature dependencies during training, SGCTR applies the generative capabilities during online inference to iteratively redefine the features of input samples, which mitigates the impact of noisy features and enhances prediction accuracy. Extensive experiments validate the superiority of SGCTR, demonstrating that applying the generative paradigm symmetrically across both training and inference significantly unlocks its power in CTR prediction.",
        "entry_id": "http://arxiv.org/abs/2511.14403v1",
        "pub_date": "2025-11-18",
        "translated_summary": "生成式模型在点击率预估领域日益受到关注，旨在突破传统判别式范式仅依赖简单二元分类目标的局限。然而现有生成模型通常将生成范式局限于训练阶段，主要用于表征学习。在线推理时它们仍回归标准判别式范式，未能利用强大的生成能力进一步提升预测精度。这种训练与推理阶段的根本性不对称阻碍了生成范式发挥全部潜力。为解决这一局限，我们提出对称掩码生成式点击率预估框架，构建训练与推理阶段的对称性。具体而言，在训练阶段通过学习特征依赖获得生成能力后，该框架在在线推理阶段运用这种生成能力迭代重构输入样本特征，从而有效缓解噪声特征影响并提升预测准确性。大量实验验证了该框架的优越性，证明在训练和推理阶段对称应用生成范式能显著释放其在点击率预估中的潜力。"
    },
    {
        "title": "PathMind: A Retrieve-Prioritize-Reason Framework for Knowledge Graph Reasoning with Large Language Models",
        "summary": "Knowledge graph reasoning (KGR) is the task of inferring new knowledge by performing logical deductions on knowledge graphs. Recently, large language models (LLMs) have demonstrated remarkable performance in complex reasoning tasks. Despite promising success, current LLM-based KGR methods still face two critical limitations. First, existing methods often extract reasoning paths indiscriminately, without assessing their different importance, which may introduce irrelevant noise that misleads LLMs. Second, while many methods leverage LLMs to dynamically explore potential reasoning paths, they require high retrieval demands and frequent LLM calls. To address these limitations, we propose PathMind, a novel framework designed to enhance faithful and interpretable reasoning by selectively guiding LLMs with important reasoning paths. Specifically, PathMind follows a \"Retrieve-Prioritize-Reason\" paradigm. First, it retrieves a query subgraph from KG through the retrieval module. Next, it introduces a path prioritization mechanism that identifies important reasoning paths using a semantic-aware path priority function, which simultaneously considers the accumulative cost and the estimated future cost for reaching the target. Finally, PathMind generates accurate and logically consistent responses via a dual-phase training strategy, including task-specific instruction tuning and path-wise preference alignment. Extensive experiments on benchmark datasets demonstrate that PathMind consistently outperforms competitive baselines, particularly on complex reasoning tasks with fewer input tokens, by identifying essential reasoning paths.",
        "entry_id": "http://arxiv.org/abs/2511.14256v1",
        "pub_date": "2025-11-18",
        "translated_summary": "知识图谱推理（KGR）是通过对知识图谱进行逻辑推演以推断新知识的任务。近年来，大语言模型（LLM）在复杂推理任务中展现出卓越性能。尽管取得显著进展，当前基于LLM的KGR方法仍面临两个关键局限：其一，现有方法往往不加区分地提取推理路径，未能评估路径的重要性差异，可能引入无关噪声误导LLM；其二，多数方法依赖LLM动态探索潜在推理路径，但需要高频次检索和大量LLM调用。为应对这些挑战，我们提出PathMind框架，通过选择性引导LLM关注重要推理路径，提升推理的可靠性与可解释性。该框架采用“检索-优先级排序-推理”范式：首先通过检索模块从知识图谱中获取查询子图；随后引入路径优先级机制，通过语义感知的路径优先级函数识别重要推理路径，该函数同步考量路径累积代价与抵达目标的预估未来代价；最后通过双阶段训练策略（包括任务特定指令微调与路径偏好对齐）生成精准且逻辑一致的答案。在基准数据集上的大量实验表明，PathMind通过识别关键推理路径，在输入标记更少的复杂推理任务中持续优于现有基线模型。"
    },
    {
        "title": "LLM-Aligned Geographic Item Tokenization for Local-Life Recommendation",
        "summary": "Recent advances in Large Language Models (LLMs) have enhanced text-based recommendation by enriching traditional ID-based methods with semantic generalization capabilities. Text-based methods typically encode item textual information via prompt design and generate discrete semantic IDs through item tokenization. However, in domain-specific tasks such as local-life services, simply injecting location information into prompts fails to capture fine-grained spatial characteristics and real-world distance awareness among items. To address this, we propose LGSID, an LLM-Aligned Geographic Item Tokenization Framework for Local-life Recommendation. This framework consists of two key components: (1) RL-based Geographic LLM Alignment, and (2) Hierarchical Geographic Item Tokenization. In the RL-based alignment module, we initially train a list-wise reward model to capture real-world spatial relationships among items. We then introduce a novel G-DPO algorithm that uses pre-trained reward model to inject generalized spatial knowledge and collaborative signals into LLMs while preserving their semantic understanding. Furthermore, we propose a hierarchical geographic item tokenization strategy, where primary tokens are derived from discrete spatial and content attributes, and residual tokens are refined using the aligned LLM's geographic representation vectors. Extensive experiments on real-world Kuaishou industry datasets show that LGSID consistently outperforms state-of-the-art discriminative and generative recommendation models. Ablation studies, visualizations, and case studies further validate its effectiveness.",
        "entry_id": "http://arxiv.org/abs/2511.14221v1",
        "pub_date": "2025-11-18",
        "translated_summary": "大型语言模型的最新进展通过增强语义泛化能力，改进了基于文本的推荐系统，突破了传统基于ID方法的局限。现有文本方法通常通过提示设计编码物品文本信息，并借助物品标记化生成离散语义ID。然而在本地生活服务等垂直领域任务中，仅将位置信息注入提示模板难以捕捉细粒度空间特征及物品间真实距离感知。为此，我们提出LGSID——面向本地生活推荐的LLM对齐地理标记化框架，该框架包含两大核心组件：（1）基于强化学习的地理LLM对齐；（2）分层级地理物品标记化。在强化学习对齐模块中，我们首先训练列表式奖励模型以捕捉物品间真实空间关系，继而提出创新性G-DPO算法，利用预训练奖励模型向LLM注入泛化空间知识与协同信号，同时保持其语义理解能力。进一步提出分层级地理物品标记化策略：主标记源自离散化空间与内容属性，残差标记则通过对齐后LLM的地理表征向量进行精细化生成。在快手真实工业数据集上的大量实验表明，LGSID在各项指标上持续优于当前最先进的判别式与生成式推荐模型。消融实验、可视化分析与案例研究进一步验证了该框架的有效性。"
    },
    {
        "title": "WebRec: Enhancing LLM-based Recommendations with Attention-guided RAG from Web",
        "summary": "Recommender systems play a vital role in alleviating information overload and enriching users' online experience. In the era of large language models (LLMs), LLM-based recommender systems have emerged as a prevalent paradigm for advancing personalized recommendations. Recently, retrieval-augmented generation (RAG) has drawn growing interest to facilitate the recommendation capability of LLMs, incorporating useful information retrieved from external knowledge bases. However, as a rich source of up-to-date information, the web remains under-explored by existing RAG-based recommendations. In particular, unique challenges are posed from two perspectives: one is to generate effective queries for web retrieval, considering the inherent knowledge gap between web search and recommendations; another challenge lies in harnessing online websites that contain substantial noisy content. To tackle these limitations, we propose WebRec, a novel web-based RAG framework, which takes advantage of the reasoning capability of LLMs to interpret recommendation tasks into queries of user preferences that cater to web retrieval. Moreover, given noisy web-retrieved information, where relevant pieces of evidence are scattered far apart, an insightful MP-Head is designed to enhance LLM attentions between distant tokens of relevant information via message passing. Extensive experiments have been conducted to demonstrate the effectiveness of our proposed web-based RAG methods in recommendation scenarios.",
        "entry_id": "http://arxiv.org/abs/2511.14182v1",
        "pub_date": "2025-11-18",
        "translated_summary": "推荐系统在缓解信息过载、丰富用户在线体验方面发挥着关键作用。在大语言模型时代，基于大语言模型的推荐系统已成为推进个性化推荐的主流范式。近年来，检索增强生成技术通过整合外部知识库中的有效信息，日益受到学界关注，以增强大语言模型的推荐能力。然而，作为实时信息的丰富来源，网络资源在当前基于检索增强生成的推荐系统中尚未得到充分探索。具体而言存在两大挑战：一是考虑到网络搜索与推荐任务之间固有的知识鸿沟，如何生成适用于网络检索的有效查询；二是如何有效利用包含大量噪声内容的在线网站资源。为突破这些局限，我们提出WebRec——一个创新的基于网络的检索增强生成框架，该框架利用大语言模型的推理能力，将推荐任务解析为符合网络检索需求的用户偏好查询。此外，针对网络检索信息中相关证据分散存在的噪声问题，我们设计了具有洞察力的MP-Head模块，通过消息传递机制增强大语言模型对分散相关信息的注意力聚焦。大量实验证明，我们提出的基于网络的检索增强生成方法在推荐场景中具有显著有效性。"
    },
    {
        "title": "Applying Relation Extraction and Graph Matching to Answering Multiple Choice Questions",
        "summary": "In this research, we combine Transformer-based relation extraction with matching of knowledge graphs (KGs) and apply them to answering multiple-choice questions (MCQs) while maintaining the traceability of the output process. KGs are structured representations of factual knowledge consisting of entities and relations. Due to the high construction cost, they had been regarded as static databases with validated links. However, the recent development of Transformer-based relation extraction (RE) methods has enabled us to generate KGs dynamically by giving them natural language texts, and thereby opened the possibility for representing the meaning of the input sentences with the created KGs. Using this effect, we propose a method that answers MCQs in the \"fill-in-the-blank\" format, taking care of the point that RE methods generate KGs that represent false information if provided with factually incorrect texts. We measure the truthfulness of each question sentence by (i) converting the sentence into a relational graph using an RE method and (ii) verifying it against factually correct KGs under the closed-world assumption. The experimental results demonstrate that our method correctly answers up to around 70% of the questions, while providing traceability of the procedure. We also highlight that the question category has a vast influence on the accuracy.",
        "entry_id": "http://arxiv.org/abs/2511.14144v1",
        "pub_date": "2025-11-18",
        "translated_summary": "本研究将基于Transformer的关系抽取与知识图谱匹配相结合，应用于填空题形式的多项选择题解答，同时保持输出过程的可追溯性。知识图谱是由实体和关系构成的结构化事实知识表示。由于构建成本高昂，传统上被视为具有已验证链接的静态数据库。但近年来基于Transformer的关系抽取技术发展使我们能够通过输入自然文本来动态生成知识图谱，从而开创了用生成图谱表征输入语句语义的新可能。基于此，我们提出一种针对填空题的解答方法，重点关注当输入事实错误的文本时，关系抽取方法会生成包含虚假信息知识图谱的特性。我们通过以下方式评估问题陈述的真实性：(i)使用关系抽取方法将语句转换为关系图谱，(ii)在封闭世界假设下对照事实正确的知识图谱进行验证。实验结果表明，本方法在保持过程可追溯性的同时，能对约70%的问题给出正确答案。我们还发现问题类别对准确率存在显著影响。"
    },
    {
        "title": "PRISM: Prompt-Refined In-Context System Modelling for Financial Retrieval",
        "summary": "With the rapid progress of large language models (LLMs), financial information retrieval has become a critical industrial application. Extracting task-relevant information from lengthy financial filings is essential for both operational and analytical decision-making. The FinAgentBench dataset formalizes this problem through two tasks: document ranking and chunk ranking. We present PRISM, a training-free framework that integrates refined system prompting, in-context learning (ICL), and a lightweight multi-agent system. Each component is examined extensively to reveal their synergies: prompt engineering provides precise task instructions, ICL supplies semantically relevant few-shot examples, and the multi-agent system models coordinated scoring behaviour. Our best configuration achieves an NDCG@5 of 0.71818 on the restricted validation split. We further demonstrate that PRISM is feasible and robust for production-scale financial retrieval. Its modular, inference-only design makes it practical for real-world use cases. The source code is released at https://bit.ly/prism-ailens.",
        "entry_id": "http://arxiv.org/abs/2511.14130v1",
        "pub_date": "2025-11-18",
        "translated_summary": "随着大语言模型的快速发展，金融信息检索已成为关键的工业应用场景。从冗长的财务报告中提取任务相关信息对运营决策与分析决策都至关重要。FinAgentBench数据集通过文档排序和文本块排序两项任务将这一问题规范化。我们提出PRISM这一免训练框架，融合了精细化系统提示、上下文学习与轻量级多代理系统。通过深入剖析各组件间的协同机制：提示工程提供精准任务指令，上下文学习注入语义相关的少样本示例，多代理系统则模拟协同评分行为。我们的最优配置在受限验证集上取得了0.71818的NDCG@5评分。进一步实验表明，PRISM在生产级金融检索场景中兼具可行性与鲁棒性，其模块化、纯推理的设计特性更契合实际应用需求。源代码已发布于https://bit.ly/prism-ailens。"
    },
    {
        "title": "NeuroPath: Neurobiology-Inspired Path Tracking and Reflection for Semantically Coherent Retrieval",
        "summary": "Retrieval-augmented generation (RAG) greatly enhances large language models (LLMs) performance in knowledge-intensive tasks. However, naive RAG methods struggle with multi-hop question answering due to their limited capacity to capture complex dependencies across documents. Recent studies employ graph-based RAG to capture document connections. However, these approaches often result in a loss of semantic coherence and introduce irrelevant noise during node matching and subgraph construction. To address these limitations, we propose NeuroPath, an LLM-driven semantic path tracking RAG framework inspired by the path navigational planning of place cells in neurobiology. It consists of two steps: Dynamic Path Tracking and Post-retrieval Completion. Dynamic Path Tracking performs goal-directed semantic path tracking and pruning over the constructed knowledge graph (KG), improving noise reduction and semantic coherence. Post-retrieval Completion further reinforces these benefits by conducting second-stage retrieval using intermediate reasoning and the original query to refine the query goal and complete missing information in the reasoning path. NeuroPath surpasses current state-of-the-art baselines on three multi-hop QA datasets, achieving average improvements of 16.3% on recall@2 and 13.5% on recall@5 over advanced graph-based RAG methods. Moreover, compared to existing iter-based RAG methods, NeuroPath achieves higher accuracy and reduces token consumption by 22.8%. Finally, we demonstrate the robustness of NeuroPath across four smaller LLMs (Llama3.1, GLM4, Mistral0.3, and Gemma3), and further validate its scalability across tasks of varying complexity. Code is available at https://github.com/KennyCaty/NeuroPath.",
        "entry_id": "http://arxiv.org/abs/2511.14096v1",
        "pub_date": "2025-11-18",
        "translated_summary": "检索增强生成（RAG）技术显著提升了大型语言模型在知识密集型任务中的表现。然而，传统RAG方法在应对多跳问答任务时，由于难以捕捉文档间的复杂依赖关系而存在局限。近期研究尝试通过基于图结构的RAG方法建立文档关联，但这类方法在节点匹配和子图构建过程中易导致语义连贯性缺失并引入无关噪声。为此，我们受神经生物学中位置细胞路径导航机制的启发，提出NeuroPath——一种基于大语言模型的语义路径追踪RAG框架。该框架包含动态路径追踪与检索后补全两个核心阶段：动态路径追踪通过在构建的知识图谱上进行目标导向的语义路径追踪与剪枝，有效提升噪声抑制与语义连贯性；检索后补全则通过结合中间推理过程与原始查询进行二次检索，优化查询目标并补全推理路径中的缺失信息。在三个多跳问答数据集上的实验表明，NeuroPath相较当前最先进的图结构RAG方法，在召回率@2和@5指标上分别实现16.3%和13.5%的平均提升；与迭代式RAG方法相比，在获得更高准确率的同时降低22.8%的token消耗。此外，我们在四款轻量化大模型（Llama3.1、GLM4、Mistral0.3和Gemma3）上验证了NeuroPath的鲁棒性，并进一步证明了其在处理不同复杂度任务时的可扩展性。项目代码已开源：https://github.com/KennyCaty/NeuroPath。"
    },
    {
        "title": "CORGI: Efficient Pattern Matching With Quadratic Guarantees",
        "summary": "Rule-based systems must solve complex matching problems within tight time constraints to be effective in real-time applications, such as planning and reactive control for AI agents, as well as low-latency relational database querying. Pattern-matching systems can encounter issues where exponential time and space are required to find matches for rules with many underconstrained variables, or which produce combinatorial intermediate partial matches (but are otherwise well-constrained). When online AI systems automatically generate rules from example-driven induction or code synthesis, they can easily produce worst-case matching patterns that slow or halt program execution by exceeding available memory. In our own work with cognitive systems that learn from example, we've found that aggressive forms of anti-unification-based generalization can easily produce these circumstances. To make these systems practical without hand-engineering constraints or succumbing to unpredictable failure modes, we introduce a new matching algorithm called CORGI (Collection-Oriented Relational Graph Iteration). Unlike RETE-based approaches, CORGI offers quadratic time and space guarantees for finding single satisficing matches, and the ability to iteratively stream subsequent matches without committing entire conflict sets to memory. CORGI differs from RETE in that it does not have a traditional $β$-memory for collecting partial matches. Instead, CORGI takes a two-step approach: a graph of grounded relations is built/maintained in a forward pass, and an iterator generates matches as needed by working backward through the graph. This approach eliminates the high-latency delays and memory overflows that can result from populating full conflict sets. In a performance evaluation, we demonstrate that CORGI significantly outperforms RETE implementations from SOAR and OPS5 on a simple combinatorial matching task.",
        "entry_id": "http://arxiv.org/abs/2511.13942v1",
        "pub_date": "2025-11-17",
        "translated_summary": "基于规则的系统必须在严格的时间限制内解决复杂的匹配问题，才能在实时应用中保持高效，例如AI代理的规划与反应控制，以及低延迟关系数据库查询。模式匹配系统可能遇到这样的问题：当规则包含大量欠约束变量，或产生组合爆炸的中间部分匹配时（尽管其他方面约束良好），寻找匹配需要指数级的时间和空间。在线AI系统通过示例驱动归纳或代码合成自动生成规则时，很容易产生最坏情况下的匹配模式，导致程序因超出可用内存而减速或停止。在我们基于示例学习的认知系统研究中发现，采用激进的反泛化泛化方法极易引发此类情况。为使这些系统无需人工设计约束即可投入实用，同时避免不可预测的故障模式，我们提出名为CORGI（面向集合的关系图迭代）的新型匹配算法。与基于RETE的方法不同，CORGI在寻找单个满意匹配时具备二次时间/空间保证，并能通过迭代流式输出后续匹配，而无需将完整冲突集载入内存。CORGI的独特之处在于摒弃了传统用于收集部分匹配的$β$存储器，转而采用两步法：前向传递中构建/维护接地关系图，后向迭代器按需遍历该图生成匹配。这种方法消除了因填充完整冲突集导致的高延迟和内存溢出问题。性能评估显示，在简单组合匹配任务中，CORGI显著优于SOAR和OPS5的RETE实现。"
    },
    {
        "title": "TaoSearchEmb: A Multi-Objective Reinforcement Learning Framework for Dense Retrieval in Taobao Search",
        "summary": "Dense retrieval, as the core component of e-commerce search engines, maps user queries and items into a unified semantic space through pre-trained embedding models to enable large-scale real-time semantic retrieval. Despite the rapid advancement of LLMs gradually replacing traditional BERT architectures for embedding, their training paradigms still adhere to BERT-like supervised fine-tuning and hard negative mining strategies. This approach relies on complex offline hard negative sample construction pipelines, which constrain model iteration efficiency and hinder the evolutionary potential of semantic representation capabilities. Besides, existing multi-task learning frameworks face the seesaw effect when simultaneously optimizing semantic relevance and non-relevance objectives. In this paper, we propose Retrieval-GRPO, a multi-objective reinforcement learning-based dense retrieval framework designed to address these challenges. The method eliminates offline hard negative sample construction by dynamically retrieving Top-K candidate products for each query during training, while introducing a relevance LLM as a reward model to generate real-time feedback. Specifically, the retrieval model dynamically optimizes embedding representations through reinforcement learning, with reward signals combining LLM-generated relevance scores, product quality scores, and multi-way exclusivity metrics to achieve multi-objective user preference alignment and real-time error correction. This mechanism not only removes dependency on hard negatives but also mitigates the seesaw effect through collaborative multi-objective optimization, significantly enhancing the model's semantic generalization capability for complex long-tail queries. Extensive offline and online experiments validate the effectiveness of Retrieval-GRPO, which has been deployed on China's largest e-commerce platform.",
        "entry_id": "http://arxiv.org/abs/2511.13885v1",
        "pub_date": "2025-11-17",
        "translated_summary": "稠密检索作为电商搜索引擎的核心组件，通过预训练嵌入模型将用户查询与商品映射至统一语义空间，以实现大规模实时语义检索。尽管大语言模型的快速发展正逐步替代传统BERT架构进行嵌入，但其训练范式仍遵循类BERT的监督微调与难负例挖掘策略。该方法依赖复杂的离线难负例样本构建流程，制约模型迭代效率并阻碍语义表征能力的进化潜力。此外，现有多任务学习框架在同时优化语义相关性与非相关性目标时存在“跷跷板效应”。本文提出Retrieval-GRPO——基于多目标强化学习的稠密检索框架以应对上述挑战。该方法通过训练期间动态检索每个查询的Top-K候选商品，消除离线难负例构建环节，同时引入相关性大语言模型作为奖励模型生成实时反馈。具体而言，检索模型通过强化学习动态优化嵌入表征，其奖励信号融合了LLM生成的相关性分数、商品质量分及多路排他性指标，实现多目标用户偏好对齐与实时纠偏。该机制不仅消除对难负例的依赖，更通过多目标协同优化缓解跷跷板效应，显著增强模型对复杂长尾查询的语义泛化能力。大量离线与在线实验验证了Retrieval-GRPO的有效性，该方案已在中国头部电商平台完成部署。"
    },
    {
        "title": "CroPS: Improving Dense Retrieval with Cross-Perspective Positive Samples in Short-Video Search",
        "summary": "Dense retrieval has become a foundational paradigm in modern search systems, especially on short-video platforms. However, most industrial systems adopt a self-reinforcing training pipeline that relies on historically exposed user interactions for supervision. This paradigm inevitably leads to a filter bubble effect, where potentially relevant but previously unseen content is excluded from the training signal, biasing the model toward narrow and conservative retrieval. In this paper, we present CroPS (Cross-Perspective Positive Samples), a novel retrieval data engine designed to alleviate this problem by introducing diverse and semantically meaningful positive examples from multiple perspectives. CroPS enhances training with positive signals derived from user query reformulation behavior (query-level), engagement data in recommendation streams (system-level), and world knowledge synthesized by large language models (knowledge-level). To effectively utilize these heterogeneous signals, we introduce a Hierarchical Label Assignment (HLA) strategy and a corresponding H-InfoNCE loss that together enable fine-grained, relevance-aware optimization. Extensive experiments conducted on Kuaishou Search, a large-scale commercial short-video search platform, demonstrate that CroPS significantly outperforms strong baselines both offline and in live A/B tests, achieving superior retrieval performance and reducing query reformulation rates. CroPS is now fully deployed in Kuaishou Search, serving hundreds of millions of users daily.",
        "entry_id": "http://arxiv.org/abs/2511.15443v1",
        "pub_date": "2025-11-19",
        "translated_summary": "稠密检索已成为现代搜索系统的基础范式，尤其在短视频平台中应用广泛。然而大多数工业系统采用自增强训练流程，依赖历史曝光用户交互作为监督信号。这种模式不可避免地导致信息茧房效应——潜在相关但未被用户接触的内容被排除在训练信号之外，使模型偏向于狭窄保守的检索。本文提出CroPS（跨视角正样本），一种通过多视角引入多样化语义正例的新型检索数据引擎。CroPS从用户查询重构行为（查询层面）、推荐流交互数据（系统层面）以及大语言模型合成的世界知识（知识层面）三个维度增强正信号训练。为有效利用这些异构信号，我们提出分层标签分配策略及其对应的H-InfoNCE损失函数，共同实现细粒度、相关性感知的优化。在大型商业短视频搜索平台快手搜索上的大量实验表明，CroPS在离线评估和在线A/B测试中均显著超越强基线模型，既提升了检索性能又降低了用户查询重构率。目前CroPS已在快手搜索全量部署，每日服务数亿用户。"
    },
    {
        "title": "HV-Attack: Hierarchical Visual Attack for Multimodal Retrieval Augmented Generation",
        "summary": "Advanced multimodal Retrieval-Augmented Generation (MRAG) techniques have been widely applied to enhance the capabilities of Large Multimodal Models (LMMs), but they also bring along novel safety issues. Existing adversarial research has revealed the vulnerability of MRAG systems to knowledge poisoning attacks, which fool the retriever into recalling injected poisoned contents. However, our work considers a different setting: visual attack of MRAG by solely adding imperceptible perturbations at the image inputs of users, without manipulating any other components. This is challenging due to the robustness of fine-tuned retrievers and large-scale generators, and the effect of visual perturbation may be further weakened by propagation through the RAG chain. We propose a novel Hierarchical Visual Attack that misaligns and disrupts the two inputs (the multimodal query and the augmented knowledge) of MRAG's generator to confuse its generation. We further design a hierarchical two-stage strategy to obtain misaligned augmented knowledge. We disrupt the image input of the retriever to make it recall irrelevant knowledge from the original database, by optimizing the perturbation which first breaks the cross-modal alignment and then disrupts the multimodal semantic alignment. We conduct extensive experiments on two widely-used MRAG datasets: OK-VQA and InfoSeek. We use CLIP-based retrievers and two LMMs BLIP-2 and LLaVA as generators. Results demonstrate the effectiveness of our visual attack on MRAG through the significant decrease in both retrieval and generation performance.",
        "entry_id": "http://arxiv.org/abs/2511.15435v1",
        "pub_date": "2025-11-19",
        "translated_summary": "先进的多模态检索增强生成技术已被广泛应用于增强大型多模态模型的能力，但同时也带来了新的安全隐患。现有对抗性研究揭示了MRAG系统易受知识投毒攻击的脆弱性，此类攻击会诱使检索器召回被植入的污染内容。然而，本研究探索了一种全新攻击范式：仅通过在用户输入的图像中添加人眼难以察觉的扰动来实现对MRAG的视觉攻击，无需操控其他组件。由于微调后的检索器与大规模生成器具有较强鲁棒性，且视觉扰动在RAG链式传播中会持续衰减，该攻击极具挑战性。我们提出了一种创新的分层视觉攻击方法，通过错位干扰MRAG生成器的两个输入源（多模态查询与增强知识）来扰乱其生成过程。进一步设计了分层双阶段策略来获取错位的增强知识：首先破坏跨模态对齐，进而干扰多模态语义对齐，通过优化扰动使检索器从原始数据库中召回无关知识。我们在OK-VQA和InfoSeek两个主流MRAG数据集上进行了广泛实验，采用CLIP系列检索器及BLIP-2、LLaVA两种大型多模态模型作为生成器。实验结果表明，我们的视觉攻击能显著降低MRAG系统的检索与生成性能，验证了该攻击方法的有效性。"
    },
    {
        "title": "NAMeGEn: Creative Name Generation via A Novel Agent-based Multiple Personalized Goal Enhancement Framework",
        "summary": "Trained on diverse human-authored texts, Large Language Models (LLMs) unlocked the potential for Creative Natural Language Generation (CNLG), benefiting various applications like advertising and storytelling. Nevertheless, CNLG still remains difficult due to two main challenges. (1) Multi-objective flexibility: user requirements are often personalized, fine-grained, and pluralistic, which LLMs struggle to satisfy simultaneously; (2) Interpretive complexity: beyond generation, creativity also involves understanding and interpreting implicit meaning to enhance users' perception. These challenges significantly limit current methods, especially in short-form text generation, in generating creative and insightful content. To address this, we focus on Chinese baby naming, a representative short-form CNLG task requiring adherence to explicit user constraints (e.g., length, semantics, anthroponymy) while offering meaningful aesthetic explanations. We propose NAMeGEn, a novel multi-agent optimization framework that iteratively alternates between objective extraction, name generation, and evaluation to meet diverse requirements and generate accurate explanations. To support this task, we further construct a classical Chinese poetry corpus with 17k+ poems to enhance aesthetics, and introduce CBNames, a new benchmark with tailored metrics. Extensive experiments demonstrate that NAMeGEn effectively generates creative names that meet diverse, personalized requirements while providing meaningful explanations, outperforming six baseline methods spanning various LLM backbones without any training.",
        "entry_id": "http://arxiv.org/abs/2511.15408v1",
        "pub_date": "2025-11-19",
        "translated_summary": "在多样化人工文本训练下，大语言模型（LLMs）释放了创意自然语言生成（CNLG）的潜力，为广告、故事创作等应用场景带来价值。然而CNLG仍面临两大核心挑战：（1）多目标灵活性：用户需求往往具有个性化、细粒度、多元化特征，LLMs难以同时满足；（2）阐释复杂性：创意不仅关乎生成，更需理解与诠释深层含义以提升用户感知。这些挑战严重制约现有方法在短文本生成中产出兼具创意与深度的内容。为此，我们聚焦中文起名这一典型短文本CNLG任务——需满足用户对长度、语义、命名学等显性约束，同时提供具有美学价值的阐释。提出NAMeGEn创新多智能体优化框架，通过目标提取、姓名生成、评估验证三阶段迭代循环，兼顾多元化需求并生成精准阐释。为此任务构建含1.7万首古诗的增强美学诗歌语料库，推出配备定制化评估指标的CBNames基准测试。大量实验表明，NAMeGEn无需训练即可在多种LLM基座上超越六类基线方法，有效生成符合个性化需求的创意姓名并产出有意义阐释。"
    },
    {
        "title": "Unveiling Inference Scaling for Difference-Aware User Modeling in LLM Personalization",
        "summary": "Large Language Models (LLMs) are increasingly integrated into users' daily lives, driving a growing demand for personalized outputs. Prior work has primarily leveraged a user's own history, often overlooking inter-user differences that are critical for effective personalization. While recent methods have attempted to model such differences, their feature extraction processes typically rely on fixed dimensions and quick, intuitive inference (System-1 thinking), limiting both the coverage and granularity of captured user differences. To address these limitations, we propose Difference-aware Reasoning Personalization (DRP), a framework that reconstructs the difference extraction mechanism by leveraging inference scaling to enhance LLM personalization. DRP autonomously identifies relevant difference feature dimensions and generates structured definitions and descriptions, enabling slow, deliberate reasoning (System-2 thinking) over user differences. Experiments on personalized review generation demonstrate that DRP consistently outperforms baseline methods across multiple metrics.",
        "entry_id": "http://arxiv.org/abs/2511.15389v1",
        "pub_date": "2025-11-19",
        "translated_summary": "大型语言模型正日益融入用户的日常生活，推动着对个性化输出的需求增长。现有研究主要利用用户自身的历史数据，往往忽视了对于实现有效个性化至关重要的用户间差异。虽然近期方法尝试对此类差异进行建模，但其特征提取过程通常依赖固定维度和快速直观推断（系统1思维），限制了所捕获用户差异的覆盖范围与精细度。为突破这些局限，我们提出差异感知推理个性化框架，该框架通过利用推理扩展重构差异提取机制，以增强大型语言模型的个性化能力。该框架能自主识别相关的差异特征维度，生成结构化定义与描述，从而实现对用户差异的慢速深度推理（系统2思维）。在个性化评论生成任务上的实验表明，该框架在多项指标上持续优于基线方法。"
    },
    {
        "title": "A Compliance-Preserving Retrieval System for Aircraft MRO Task Search",
        "summary": "Aircraft Maintenance Technicians (AMTs) spend up to 30% of work time searching manuals, a documented efficiency bottleneck in MRO operations where every procedure must be traceable to certified sources. We present a compliance-preserving retrieval system that adapts LLM reranking and semantic search to aviation MRO environments by operating alongside, rather than replacing, certified legacy viewers. The system constructs revision-robust embeddings from ATA chapter hierarchies and uses vision-language parsing to structure certified content, allowing technicians to preview ranked tasks and access verified procedures in existing viewers. Evaluation on 49k synthetic queries achieves >90% retrieval accuracy, while bilingual controlled studies with 10 licensed AMTs demonstrate 90.9% top-10 success rate and 95% reduction in lookup time, from 6-15 minutes to 18 seconds per task. These gains provide concrete evidence that semantic retrieval can operate within strict regulatory constraints and meaningfully reduce operational workload in real-world multilingual MRO workflows.",
        "entry_id": "http://arxiv.org/abs/2511.15383v1",
        "pub_date": "2025-11-19",
        "translated_summary": "飞机维修技师目前需花费高达30%的工作时间查阅技术手册，这在必须确保每个操作步骤都可追溯至认证来源的航空维修场景中，已成为公认的效率瓶颈。我们开发了一套合规检索系统，通过适配大语言模型重排与语义搜索技术，使其在现有认证查阅系统旁并行运行而非替代原有系统。该系统基于ATA章节层级构建版本鲁棒性向量，并运用视觉语言解析技术对认证内容进行结构化处理，使技术人员既能预览排序任务列表，又能通过原有查阅器获取核验流程。在4.9万条合成查询测试中实现超90%检索准确率；针对10名持证技师的跨语言对照研究显示，系统达成90.9%的前十检索成功率，并将单任务查阅时间从6-15分钟压缩至18秒，降幅达95%。这些成果实证表明，语义检索技术能在严格监管框架下有效运行，并为多语言航空维修实践带来实质性效率提升。"
    },
    {
        "title": "Opinion Dynamics Models for Sentiment Evolution in Weibo Blogs",
        "summary": "Online social media platforms enable influencers to distribute content and quickly capture audience reactions, significantly shaping their promotional strategies and advertising agreements. Understanding how sentiment dynamics and emotional contagion unfold among followers is vital for influencers and marketers, as these processes shape engagement, brand perception, and purchasing behavior. While sentiment analysis tools effectively track sentiment fluctuations, dynamical models explaining their evolution remain limited, often neglecting network structures and interactions both among blogs and between their topic-focused follower groups. In this study, we tracked influential tech-focused Weibo bloggers over six months, quantifying follower sentiment from text-mined feedback. By treating each blogger's audience as a single \"macro-agent\", we find that sentiment trajectories follow the principle of iterative averaging -- a foundational mechanism in many dynamical models of opinion formation, a theoretical framework at the intersection of social network analysis and dynamical systems theory. The sentiment evolution aligns closely with opinion-dynamics models, particularly modified versions of the classical French-DeGroot model that incorporate delayed perception and distinguish between expressed and private opinions. The inferred influence structures reveal interdependencies among blogs that may arise from homophily, whereby emotionally similar users subscribe to the same blogs and collectively shape the shared sentiment expressed within these communities.",
        "entry_id": "http://arxiv.org/abs/2511.15303v1",
        "pub_date": "2025-11-19",
        "translated_summary": "在线社交媒体平台使意见领袖能够发布内容并快速获取受众反馈，这显著影响着他们的推广策略与广告合作。理解追随者群体中的情绪动态与情感传染机制对意见领袖和营销者至关重要，因为这些过程直接塑造着用户参与度、品牌认知与消费行为。尽管情感分析工具能有效追踪情绪波动，但解释其演变规律的动态模型仍相对匮乏，往往忽略了博客间的网络结构及其垂直领域粉丝群之间的互动关系。本研究通过持续六个月追踪科技领域微博大V，基于文本挖掘的粉丝反馈量化其情绪走向。当我们将每位博主的受众视为单一“宏观主体”时，发现情绪轨迹遵循迭代平均原则——这一观点形成动态模型中的基础机制，也是社交网络分析与动态系统理论交叉领域的核心框架。情绪演变规律与观点动力学模型高度吻合，尤其是融合延迟感知机制、区分公开与私人意见的改进版French-DeGroot模型。通过推导出的影响力结构，我们发现博客间存在由同质效应产生的相互依赖：情感倾向相似的用户会订阅相同博客，并共同塑造这些社群内显现的集体情绪。"
    },
    {
        "title": "Selective Mixup for Debiasing Question Selection in Computerized Adaptive Testing",
        "summary": "Computerized Adaptive Testing (CAT) is a widely used technology for evaluating learners' proficiency in online education platforms. By leveraging prior estimates of proficiency to select questions and updating the estimates iteratively based on responses, CAT enables personalized learner modeling and has attracted substantial attention. Despite this progress, most existing works focus primarily on improving diagnostic accuracy, while overlooking the selection bias inherent in the adaptive process. Selection Bias arises because the question selection is strongly influenced by the estimated proficiency, such as assigning easier questions to learners with lower proficiency and harder ones to learners with higher proficiency. Since the selection depends on prior estimation, this bias propagates into the diagnosis model, which is further amplified during iterative updates, leading to misalignment and biased predictions. Moreover, the imbalanced nature of learners' historical interactions often exacerbates the bias in diagnosis models. To address this issue, we propose a debiasing framework consisting of two key modules: Cross-Attribute Examinee Retrieval and Selective Mixup-based Regularization. First, we retrieve balanced examinees with relatively even distributions of correct and incorrect responses and use them as neutral references for biased examinees. Then, mixup is applied between each biased examinee and its matched balanced counterpart under label consistency. This augmentation enriches the diversity of bias-conflicting samples and smooths selection boundaries. Finally, extensive experiments on two benchmark datasets with multiple advanced diagnosis models demonstrate that our method substantially improves both the generalization ability and fairness of question selection in CAT.",
        "entry_id": "http://arxiv.org/abs/2511.15241v1",
        "pub_date": "2025-11-19",
        "translated_summary": "计算机化自适应测试是在线教育平台中广泛使用的学习者能力评估技术。该技术通过利用先验能力估计值动态选题，并依据答题结果迭代更新估计值，实现个性化学习者建模，已引起广泛关注。然而现有研究大多聚焦于提升诊断精度，忽视了自适应过程中固有的选择偏差问题。由于选题策略受能力估计值显著影响（如向低能力者分配简单题目，向高能力者分配难题），而题目选择又依赖于先验估计，这种偏差会渗入诊断模型，并在迭代更新过程中不断放大，最终导致预测结果失准。此外，学习者历史交互数据的不平衡性往往加剧诊断模型的偏差。针对该问题，我们提出包含双重核心模块的去偏框架：跨属性考生检索与选择性混合正则化。首先，我们检索具有均衡正误答题分布的考生作为参照基准，以其作为存在偏差考生的中性参照。随后在保持标签一致性的前提下，对存在偏差的考生与其匹配的均衡参照对象实施混合增强。这种数据增强策略有效丰富了偏差冲突样本的多样性，并平滑了选择边界。最终在两大基准数据集上的实验表明，本方法基于多种先进诊断模型，显著提升了计算机化自适应测试中选题策略的泛化能力与公平性。"
    },
    {
        "title": "ItemRAG: Item-Based Retrieval-Augmented Generation for LLM-Based Recommendation",
        "summary": "Recently, large language models (LLMs) have been widely used as recommender systems, owing to their strong reasoning capability and their effectiveness in handling cold-start items. To better adapt LLMs for recommendation, retrieval-augmented generation (RAG) has been incorporated. Most existing RAG methods are user-based, retrieving purchase patterns of users similar to the target user and providing them to the LLM. In this work, we propose ItemRAG, an item-based RAG method for LLM-based recommendation that retrieves relevant items (rather than users) from item-item co-purchase histories. ItemRAG helps LLMs capture co-purchase patterns among items, which are beneficial for recommendations. Especially, our retrieval strategy incorporates semantically similar items to better handle cold-start items and uses co-purchase frequencies to improve the relevance of the retrieved items. Through extensive experiments, we demonstrate that ItemRAG consistently (1) improves the zero-shot LLM-based recommender by up to 43% in Hit-Ratio-1 and (2) outperforms user-based RAG baselines under both standard and cold-start item recommendation settings.",
        "entry_id": "http://arxiv.org/abs/2511.15141v1",
        "pub_date": "2025-11-19",
        "translated_summary": "近年来，大型语言模型凭借其强大的推理能力和处理冷启动物品的有效性，被广泛用作推荐系统。为更好地适配推荐场景，检索增强生成技术被引入应用。现有RAG方法多基于用户视角，通过检索与目标用户相似的用户购买模式，并将其提供给大语言模型。本研究提出ItemRAG——一种基于物品的RAG方法，该方法从物品间协同购买历史中检索相关物品（而非用户），帮助大语言模型捕捉对推荐有益的物品协同购买模式。特别地，我们的检索策略融合语义相似的物品以优化冷启动物品处理，同时利用协同购买频率提升检索物品的相关性。大量实验表明，ItemRAG在以下方面表现卓越：（1）将基于大语言模型的零样本推荐系统的命中率提升最高达43%；（2）在常规场景与冷启动物品推荐场景下均优于基于用户的RAG基线方法。"
    },
    {
        "title": "Multi-Aspect Cross-modal Quantization for Generative Recommendation",
        "summary": "Generative Recommendation (GR) has emerged as a new paradigm in recommender systems. This approach relies on quantized representations to discretize item features, modeling users' historical interactions as sequences of discrete tokens. Based on these tokenized sequences, GR predicts the next item by employing next-token prediction methods. The challenges of GR lie in constructing high-quality semantic identifiers (IDs) that are hierarchically organized, minimally conflicting, and conducive to effective generative model training. However, current approaches remain limited in their ability to harness multimodal information and to capture the deep and intricate interactions among diverse modalities, both of which are essential for learning high-quality semantic IDs and for effectively training GR models. To address this, we propose Multi-Aspect Cross-modal quantization for generative Recommendation (MACRec), which introduces multimodal information and incorporates it into both semantic ID learning and generative model training from different aspects. Specifically, we first introduce cross-modal quantization during the ID learning process, which effectively reduces conflict rates and thus improves codebook usability through the complementary integration of multimodal information. In addition, to further enhance the generative ability of our GR model, we incorporate multi-aspect cross-modal alignments, including the implicit and explicit alignments. Finally, we conduct extensive experiments on three well-known recommendation datasets to demonstrate the effectiveness of our proposed method.",
        "entry_id": "http://arxiv.org/abs/2511.15122v1",
        "pub_date": "2025-11-19",
        "translated_summary": "生成式推荐作为推荐系统的新范式，通过量化表征对项目特征进行离散化处理，将用户历史交互行为建模为离散标记序列，并基于该序列采用下一标记预测方法进行项目推荐。该范式的核心挑战在于构建层次清晰、冲突率低且利于生成模型训练的高质量语义标识符。然而，现有方法在利用多模态信息捕捉深层跨模态交互关系方面仍存在局限，而这些特性对学习优质语义标识符和有效训练生成式推荐模型至关重要。为此，我们提出多视角跨模态量化生成式推荐框架MACRec，从多维度将跨模态信息融入语义标识符学习与生成模型训练全过程。具体而言，在标识符学习阶段引入跨模态量化机制，通过多模态信息的互补融合有效降低冲突率，提升码本可用性；同时构建包含显性与隐性对齐的多视角跨模态对齐策略，进一步增强生成式推荐模型的推理能力。我们在三个知名推荐数据集上的实验结果表明，该方法的性能显著优于现有主流方案。"
    },
    {
        "title": "Beyond GeneGPT: A Multi-Agent Architecture with Open-Source LLMs for Enhanced Genomic Question Answering",
        "summary": "Genomic question answering often requires complex reasoning and integration across diverse biomedical sources. GeneGPT addressed this challenge by combining domain-specific APIs with OpenAI's code-davinci-002 large language model to enable natural language interaction with genomic databases. However, its reliance on a proprietary model limits scalability, increases operational costs, and raises concerns about data privacy and generalization.\n  In this work, we revisit and reproduce GeneGPT in a pilot study using open source models, including Llama 3.1, Qwen2.5, and Qwen2.5 Coder, within a monolithic architecture; this allows us to identify the limitations of this approach. Building on this foundation, we then develop OpenBioLLM, a modular multi-agent framework that extends GeneGPT by introducing agent specialization for tool routing, query generation, and response validation. This enables coordinated reasoning and role-based task execution.\n  OpenBioLLM matches or outperforms GeneGPT on over 90% of the benchmark tasks, achieving average scores of 0.849 on Gene-Turing and 0.830 on GeneHop, while using smaller open-source models without additional fine-tuning or tool-specific pretraining. OpenBioLLM's modular multi-agent design reduces latency by 40-50% across benchmark tasks, significantly improving efficiency without compromising model capability. The results of our comprehensive evaluation highlight the potential of open-source multi-agent systems for genomic question answering. Code and resources are available at https://github.com/ielab/OpenBioLLM.",
        "entry_id": "http://arxiv.org/abs/2511.15061v1",
        "pub_date": "2025-11-19",
        "translated_summary": "基因组问答通常需要复杂推理和跨生物医学数据源的整合。GeneGPT通过将领域专用API与OpenAI的代码生成大模型相结合，实现了与基因组数据库的自然语言交互。然而，其依赖专有模型的特性限制了可扩展性，增加了运营成本，并引发了对数据隐私与泛化能力的担忧。\n\n本研究通过采用开源模型（包括Llama 3.1、Qwen2.5及Qwen2.5 Coder）在单体架构中复现GeneGPT，率先通过实验验证了该方案的局限性。在此基础上，我们开发了OpenBioLLM——采用模块化多智能体框架，通过引入工具路由、查询生成和响应验证的智能体分工机制，扩展了GeneGPT的协同推理与角色化任务执行能力。\n\n在超过90%的基准任务中，OpenBioLLM达到或超越了GeneGPT的性能，在Gene-Turing和GeneHop基准上分别取得0.849和0.830的平均分，且仅使用未经额外微调的小型开源模型。该框架的模块化多智能体设计使基准任务延迟降低40-50%，在保持模型能力的同时显著提升效率。综合评估结果凸显了开源多智能体系统在基因组问答领域的潜力。代码与资源已开源：https://github.com/ielab/OpenBioLLM。"
    },
    {
        "title": "SilverTorch: A Unified Model-based System to Democratize Large-Scale Recommendation on GPUs",
        "summary": "Serving deep learning based recommendation models (DLRM) at scale is challenging. Existing systems rely on CPU-based ANN indexing and filtering services, suffering from non-negligible costs and forgoing joint optimization opportunities. Such inefficiency makes them difficult to support more complex model architectures, such as learned similarities and multi-task retrieval.\n  In this paper, we propose SilverTorch, a model-based system for serving recommendation models on GPUs. SilverTorch unifies model serving by replacing standalone indexing and filtering services with layers of served models. We propose a Bloom index algorithm on GPUs for feature filtering and a tensor-native fused Int8 ANN kernel on GPUs for nearest neighbor search. We further co-design the ANN search index and filtering index to reduce GPU memory utilization and eliminate unnecessary computation. Benefit from SilverTorch's serving paradigm, we introduce a OverArch scoring layer and a Value Model to aggregate results across multi-tasks. These advancements improve the accuracy for retrieval and enable future studies for serving more complex models. For ranking, SilverTorch's design accelerates item embedding calculation by caching the pre-calculated embeddings inside the serving model.\n  Our evaluation on the industry-scale datasets show that SilverTorch achieves up to 5.6x lower latency and 23.7x higher throughput compared to the state-of-the-art approaches. We also demonstrate that SilverTorch's solution is 13.35x more cost-efficient than CPU-based solution while improving accuracy via serving more complex models. SilverTorch serves over hundreds of models online across major products and recommends contents for billions of daily active users.",
        "entry_id": "http://arxiv.org/abs/2511.14881v1",
        "pub_date": "2025-11-18",
        "translated_summary": "基于深度学习的大规模推荐模型服务化部署面临诸多挑战。现有系统依赖基于CPU的近似最近邻索引与过滤服务，存在不可忽视的资源开销且丧失了联合优化机会。这种低效性导致系统难以支撑更复杂的模型架构，例如基于学习的相似度计算和多任务检索。\n\n本文提出SilverTorch——一种基于GPU的推荐模型服务化系统。该系统通过将独立索引与过滤服务替换为模型服务层，实现了模型服务的统一化。我们提出GPU上的布隆索引算法用于特征过滤，并开发了基于张量原生融合的Int8近似最近邻计算内核。通过协同设计近似最近邻搜索索引与过滤索引，有效降低了GPU显存占用并消除了冗余计算。受益于该服务范式，我们引入了顶层架构评分层与价值模型来实现多任务结果聚合，从而提升检索精度并为未来复杂模型服务研究奠定基础。在排序阶段，该系统通过预缓存服务模型内的物品嵌入向量，显著加速了嵌入计算过程。\n\n在工业级数据集上的评估表明，相较于现有最优方案，SilverTorch可实现延迟降低5.6倍、吞吐量提升23.7倍。实验同时证明，在通过部署更复杂模型提升精度的前提下，该方案比基于CPU的解决方案成本效益高出13.35倍。目前SilverTorch已在多个核心产品中在线服务数百个模型，为日均数十亿活跃用户提供内容推荐服务。"
    },
    {
        "title": "Jasper-Token-Compression-600M Technical Report",
        "summary": "This technical report presents the training methodology and evaluation results of the open-source Jasper-Token-Compression-600M model, released in November 2025. Building on previous distillation-based recipes from the English Stella and Jasper models, we successfully extend this approach to a bilingual (English and Chinese) domain, further enhancing model performance through the incorporation of contrastive learning. A key innovation of our model is the introduction of a one-dimensional convolution-based token compression module. We dynamically adjust the compression rate during training, enabling the model to learn more robust and efficient compressed text representations. By combining knowledge distillation with token compression techniques, we achieve significant improvements in both embedding quality and inference efficiency. Our model performs with higher efficiency than a traditional 0.6B model while achieving performance comparable to that of an 8B model. For more information on the model release, visit: https://huggingface.co/infgrad/Jasper-Token-Compression-600M.",
        "entry_id": "http://arxiv.org/abs/2511.14405v2",
        "pub_date": "2025-11-18",
        "translated_summary": "本技术报告介绍了2025年11月发布的开源Jasper-Token-Compression-600M模型的训练方法与评估结果。基于先前英文Stella与Jasper模型的蒸馏方案，我们成功将该方法扩展至双语（英文与中文）领域，并通过引入对比学习进一步提升了模型性能。本模型的核心创新在于提出基于一维卷积的令牌压缩模块，在训练过程中动态调整压缩率，使模型能够学习更鲁棒、更高效的压缩文本表示。通过将知识蒸馏与令牌压缩技术相结合，我们在嵌入质量与推理效率方面均实现显著提升。该模型在达到与80亿参数模型相当性能的同时，运行效率显著优于传统6亿参数模型。更多模型发布信息请访问：https://huggingface.co/infgrad/Jasper-Token-Compression-600M。"
    },
    {
        "title": "PolyMinHash: Efficient Area-Based MinHashing of Polygons for Approximate Nearest Neighbor Search",
        "summary": "Similarity searches are a critical task in data mining. As data sets grow larger, exact nearest neighbor searches quickly become unfeasible, leading to the adoption of approximate nearest neighbor (ANN) searches. ANN has been studied for text data, images, and trajectories. However, there has been little effort to develop ANN systems for polygons in spatial database systems and geographic information systems. We present PolyMinHash, a system for approximate polygon similarity search that adapts MinHashing into a novel 2D polygon-hashing scheme to generate short, similarity-preserving signatures of input polygons. Minhash is generated by counting the number of randomly sampled points needed before the sampled point lands within the polygon's interior area, yielding hash values that preserve area-based Jaccard similarity. We present the tradeoff between search accuracy and runtime of our PolyMinHash system. Our hashing mechanism reduces the number of candidates to be processed in the query refinement phase by up to 98% compared to the number of candidates processed by the brute-force algorithm.",
        "entry_id": "http://arxiv.org/abs/2511.16576v1",
        "pub_date": "2025-11-20",
        "translated_summary": "相似性搜索是数据挖掘中的关键任务。随着数据集规模不断扩大，精确最近邻搜索迅速变得不可行，促使近似最近邻搜索技术得到广泛应用。目前针对文本数据、图像和轨迹的近似最近邻搜索已有深入研究，但在空间数据库系统和地理信息系统中，针对多边形的近似最近邻搜索系统开发却鲜有进展。我们提出了PolyMinHash系统，这是一种近似多边形相似性搜索方案，通过将MinHashing算法创新性地适配为二维多边形哈希方案，生成简洁且保持相似性的输入多边形签名。该哈希机制通过统计随机采样点落入多边形内部区域所需的采样次数来生成哈希值，从而保持基于面积的杰卡德相似性。我们展示了PolyMinHash系统在搜索精度与运行时间之间的权衡关系。实验表明，与暴力算法相比，我们的哈希机制在查询优化阶段需要处理的候选数据量最高可减少98%。"
    },
    {
        "title": "The Oracle and The Prism: A Decoupled and Efficient Framework for Generative Recommendation Explanation",
        "summary": "The integration of Large Language Models (LLMs) into explainable recommendation systems often leads to a performance-efficiency trade-off in end-to-end architectures, where joint optimization of ranking and explanation can result in suboptimal compromises. To resolve this, we propose Prism, a novel decoupled framework that rigorously separates the recommendation process into a dedicated ranking stage and an explanation generation stage.\n  Inspired by knowledge distillation, Prism leverages a powerful teacher LLM (e.g., FLAN-T5-XXL) as an Oracle to produce high-fidelity explanatory knowledge. A compact, fine-tuned student model (e.g., BART-Base), the Prism, then specializes in synthesizing this knowledge into personalized explanations. This decomposition ensures that each component is optimized for its specific objective, eliminating inherent conflicts in coupled models.\n  Extensive experiments on benchmark datasets demonstrate that our 140M-parameter Prism model significantly outperforms its 11B-parameter teacher in human evaluations of faithfulness and personalization, while achieving a 24 times speedup and a 10 times reduction in memory consumption during inference. These results validate that decoupling, coupled with targeted distillation, provides an efficient and effective pathway to high-quality explainable recommendation.",
        "entry_id": "http://arxiv.org/abs/2511.16543v1",
        "pub_date": "2025-11-20",
        "translated_summary": "将大语言模型（LLM）融入可解释推荐系统时，端到端架构常面临性能与效率的权衡——排序与解释的联合优化往往导致双重妥协。为此，我们提出Prism这一创新解耦框架，将推荐过程严格分离为独立排序阶段和解释生成阶段。\n\n受知识蒸馏启发，Prism引入强力教师LLM（如FLAN-T5-XXL）作为预言机，生成高保真解释性知识；随后由精调后的轻量级学生模型Prism（如BART-Base）专门将这些知识合成为个性化解释。这种解耦架构确保各组件专注于特定目标，消除了耦合模型的内在冲突。\n\n在基准数据集上的大量实验表明：仅1.4亿参数的Prism模型在忠实度与个性化的人类评估中显著优于110亿参数的教师模型，推理速度提升24倍，内存消耗降低10倍。这些结果验证了“解耦+定向蒸馏”能为高质量可解释推荐提供高效可行的技术路径。"
    },
    {
        "title": "TurkColBERT: A Benchmark of Dense and Late-Interaction Models for Turkish Information Retrieval",
        "summary": "Neural information retrieval systems excel in high-resource languages but remain underexplored for morphologically rich, lower-resource languages such as Turkish. Dense bi-encoders currently dominate Turkish IR, yet late-interaction models -- which retain token-level representations for fine-grained matching -- have not been systematically evaluated. We introduce TurkColBERT, the first comprehensive benchmark comparing dense encoders and late-interaction models for Turkish retrieval. Our two-stage adaptation pipeline fine-tunes English and multilingual encoders on Turkish NLI/STS tasks, then converts them into ColBERT-style retrievers using PyLate trained on MS MARCO-TR. We evaluate 10 models across five Turkish BEIR datasets covering scientific, financial, and argumentative domains. Results show strong parameter efficiency: the 1.0M-parameter colbert-hash-nano-tr is 600$\\times$ smaller than the 600M turkish-e5-large dense encoder while preserving over 71\\% of its average mAP. Late-interaction models that are 3--5$\\times$ smaller than dense encoders significantly outperform them; ColmmBERT-base-TR yields up to +13.8\\% mAP on domain-specific tasks. For production-readiness, we compare indexing algorithms: MUVERA+Rerank is 3.33$\\times$ faster than PLAID and offers +1.7\\% relative mAP gain. This enables low-latency retrieval, with ColmmBERT-base-TR achieving 0.54 ms query times under MUVERA. We release all checkpoints, configs, and evaluation scripts. Limitations include reliance on moderately sized datasets ($\\leq$50K documents) and translated benchmarks, which may not fully reflect real-world Turkish retrieval conditions; larger-scale MUVERA evaluations remain necessary.",
        "entry_id": "http://arxiv.org/abs/2511.16528v1",
        "pub_date": "2025-11-20",
        "translated_summary": "神经信息检索系统在高资源语言中表现优异，但在土耳其语等形态复杂、资源相对匮乏的语言中仍有待探索。目前稠密双编码器主导土耳其信息检索领域，而保留词元级表征进行细粒度匹配的延迟交互模型尚未得到系统评估。我们推出TurkColBERT——首个针对土耳其语检索的稠密编码器与延迟交互模型的综合基准。通过两阶段适配流程：先在土耳其自然语言推理/语义文本相似性任务上微调英语和多语言编码器，再利用基于MS MARCO-TR训练的PyLate将其转换为ColBERT风格检索器。我们在覆盖科学、金融及论证领域的五个土耳其BEIR数据集上评估10个模型，结果显示：参数量仅100万的colbert-hash-nano-tr比6亿参数的turkish-e5-large稠密编码器缩小600倍，却能保持其71%以上的平均平均精度。延迟交互模型体积比稠密编码器小3-5倍，性能却显著更优：ColmmBERT-base-TR在特定领域任务中平均精度提升高达13.8%。为满足生产需求，我们对比索引算法：MUVERA+重排序比PLAID快3.33倍，并带来1.7%的相对平均精度提升。这使得ColmmBERT-base-TR在MUVERA下实现0.54毫秒查询延迟。我们公开所有检查点、配置和评估脚本。当前局限包括依赖中等规模数据集（≤5万文档）及翻译基准，可能无法完全反映真实土耳其语检索环境；更大规模的MUVERA评估仍有待进行。"
    },
    {
        "title": "Music Recommendation with Large Language Models: Challenges, Opportunities, and Evaluation",
        "summary": "Music Recommender Systems (MRS) have long relied on an information-retrieval framing, where progress is measured mainly through accuracy on retrieval-oriented subtasks. While effective, this reductionist paradigm struggles to address the deeper question of what makes a good recommendation, and attempts to broaden evaluation, through user studies or fairness analyses, have had limited impact. The emergence of Large Language Models (LLMs) disrupts this framework: LLMs are generative rather than ranking-based, making standard accuracy metrics questionable. They also introduce challenges such as hallucinations, knowledge cutoffs, non-determinism, and opaque training data, rendering traditional train/test protocols difficult to interpret. At the same time, LLMs create new opportunities, enabling natural-language interaction and even allowing models to act as evaluators.\n  This work argues that the shift toward LLM-driven MRS requires rethinking evaluation. We first review how LLMs reshape user modeling, item modeling, and natural-language recommendation in music. We then examine evaluation practices from NLP, highlighting methodologies and open challenges relevant to MRS. Finally, we synthesize insights-focusing on how LLM prompting applies to MRS, to outline a structured set of success and risk dimensions. Our goal is to provide the MRS community with an updated, pedagogical, and cross-disciplinary perspective on evaluation.",
        "entry_id": "http://arxiv.org/abs/2511.16478v1",
        "pub_date": "2025-11-20",
        "translated_summary": "音乐推荐系统长期依赖信息检索框架，其进展主要通过检索导向子任务的准确度来衡量。这种简化范式虽有效，却难以回答\"何为优质推荐\"的核心问题，而通过用户研究或公平性分析来拓宽评估维度的尝试收效甚微。大语言模型的出现打破了这一框架：其生成式特性与基于排序的传统方法截然不同，使得标准准确度指标不再适用。同时，大语言模型也带来幻觉、知识截止期、非确定性及训练数据不透明等新挑战，导致传统训练/测试方案难以奏效。但另一方面，它们也创造了自然语言交互乃至让模型充当评估者的新机遇。\n\n本文主张，大语言模型驱动的音乐推荐系统需要重建评估体系。我们首先梳理大语言模型如何重塑用户建模、内容建模及自然语言推荐三个维度，继而考察自然语言处理领域的评估实践，提炼适用于音乐推荐系统的方法论与开放挑战。最后通过聚焦提示工程在音乐推荐系统的应用，我们构建出包含成功维度与风险维度的结构化评估框架。本研究旨在为音乐推荐领域提供与时俱进的、具有教学意义的跨学科评估视角。"
    },
    {
        "title": "ESGBench: A Benchmark for Explainable ESG Question Answering in Corporate Sustainability Reports",
        "summary": "We present ESGBench, a benchmark dataset and evaluation framework designed to assess explainable ESG question answering systems using corporate sustainability reports. The benchmark consists of domain-grounded questions across multiple ESG themes, paired with human-curated answers and supporting evidence to enable fine-grained evaluation of model reasoning. We analyze the performance of state-of-the-art LLMs on ESGBench, highlighting key challenges in factual consistency, traceability, and domain alignment. ESGBench aims to accelerate research in transparent and accountable ESG-focused AI systems.",
        "entry_id": "http://arxiv.org/abs/2511.16438v1",
        "pub_date": "2025-11-20",
        "translated_summary": "我们推出ESGBench——一个基于企业可持续发展报告的ESG可解释问答系统评估基准数据集与评估框架。该基准包含跨越多维度ESG主题的领域扎根问题，并配备人工精校的参考答案与佐证依据，支持对模型推理过程进行细粒度评估。通过对前沿大语言模型在ESGBench上的表现分析，我们揭示了其在事实一致性、答案溯源性及领域适配性方面的核心挑战。该基准旨在推动面向ESG领域的透明可信人工智能系统研究进程。"
    },
    {
        "title": "An Efficient LLM-based Evolutional Recommendation with Locate-Forget-Update Paradigm",
        "summary": "Nowadays, Large Language Models (LLMs) have shown exceptional performance in sequential recommendations, and the adoption of LLM-based recommender systems (LLMRec) is becoming increasingly widespread in existing e-commerce platforms. Despite the impressive performance, the constant high volume of new user-item interactions makes it difficult to adapt to the evolution of user preference over time, especially for LLM-based recommender systems. The challenge arises from the large number of parameters in LLMs, which makes traditional evolution methods (i.e., Re-training or Fine-tuning) impractical. Specifically, Re-training with all interactions results in prohibitively high computational costs. On the other hand, fine-tuning with only new interactions leads to preference forgetting among inactive users, ultimately compromising overall performance. To tackle this problem, we propose EvoRec, an efficient Locate-Forget-Update framework designed for LLM-based recommender systems to model the evolution of user preferences. EvoRec identifies a small set of parameters associated with preference changes and updates them precisely, thereby saving computational resources while maintaining strong recommendation performance. Notably, the modified parameters account for only 30\\% of LoRA adapter parameters, with no additional parameters introduced. Extensive experiments on two real-world datasets demonstrate that, compared to existing methods, EvoRec not only efficiently evolves LLMRec to adapt to the preferences of active users, but also preserves the interests of inactive users from being disturbed during evolution.",
        "entry_id": "http://arxiv.org/abs/2511.16414v1",
        "pub_date": "2025-11-20",
        "translated_summary": "当前，大语言模型在序列推荐任务中展现出卓越性能，基于大语言模型的推荐系统在电商平台中的应用日益广泛。然而，尽管性能优异，持续涌入的新用户-物品交互数据使其难以适应用户偏好的动态演化，这一挑战对大语言模型推荐系统尤为突出。其根源在于大语言模型参数量庞大，使得传统演化方法（如重训练或微调）难以实施：若采用全量交互数据重训练，将产生难以承受的计算开销；若仅用新交互数据微调，又会导致非活跃用户的偏好遗忘，最终影响整体性能。为此，我们提出EvoRec——一个面向大语言模型推荐系统的高效“定位-遗忘-更新”框架，通过精准识别与偏好演化相关的极小参量子集并进行定向更新，在节约计算资源的同时保持强劲的推荐性能。值得注意的是，该方法仅需调整相当于LoRA适配器30%的参数量，且未引入任何额外参数。在两个真实数据集上的大量实验表明，相较于现有方法，EvoRec不仅能高效推动大语言模型推荐系统适应用户偏好演化，还能在演化过程中有效保护非活跃用户的兴趣不受干扰。"
    },
    {
        "title": "ARK: Answer-Centric Retriever Tuning via KG-augmented Curriculum Learning",
        "summary": "Retrieval-Augmented Generation (RAG) has emerged as a powerful framework for knowledge-intensive tasks, yet its effectiveness in long-context scenarios is often bottlenecked by the retriever's inability to distinguish sparse yet crucial evidence. Standard retrievers, optimized for query-document similarity, frequently fail to align with the downstream goal of generating a precise answer. To bridge this gap, we propose a novel fine-tuning framework that optimizes the retriever for Answer Alignment. Specifically, we first identify high-quality positive chunks by evaluating their sufficiency to generate the correct answer. We then employ a curriculum-based contrastive learning scheme to fine-tune the retriever. This curriculum leverages LLM-constructed Knowledge Graphs (KGs) to generate augmented queries, which in turn mine progressively challenging hard negatives. This process trains the retriever to distinguish the answer-sufficient positive chunks from these nuanced distractors, enhancing its generalization. Extensive experiments on 10 datasets from the Ultradomain and LongBench benchmarks demonstrate that our fine-tuned retriever achieves state-of-the-art performance, improving 14.5% over the base model without substantial architectural modifications and maintaining strong efficiency for long-context RAG. Our work presents a robust and effective methodology for building truly answer-centric retrievers.",
        "entry_id": "http://arxiv.org/abs/2511.16326v1",
        "pub_date": "2025-11-20",
        "translated_summary": "检索增强生成（RAG）已成为处理知识密集型任务的重要框架，但其在长文本场景中的效果常受限于检索器难以识别稀疏却关键的证据。传统检索器虽针对查询-文档相似度进行优化，却往往无法与生成精确答案的下游目标对齐。为弥补这一差距，我们提出了一个创新微调框架，通过答案对齐机制优化检索器。具体而言，我们首先通过评估文本块生成正确答案的充分性来筛选高质量正样本，随后采用基于课程学习的对比训练方案，利用大语言模型构建的知识图谱生成增强查询，进而挖掘难度渐增的困难负样本。该方法训练检索器从精妙设计的干扰项中识别足以支撑答案的正样本，从而提升其泛化能力。在Ultradomain和LongBench基准的10个数据集上的实验表明，经微调的检索器实现了最先进性能，较基础模型提升14.5%且无需重大结构改动，同时在长文本RAG场景中保持高效性。本研究为构建真正以答案为中心的检索器提供了稳健有效的解决方案。"
    },
    {
        "title": "Incorporating Token Importance in Multi-Vector Retrieval",
        "summary": "ColBERT introduced a late interaction mechanism that independently encodes queries and documents using BERT, and computes similarity via fine-grained interactions over token-level vector representations. This design enables expressive matching while allowing efficient computation of scores, as the multi-vector document representations could be pre-computed offline. ColBERT models distance using a Chamfer-style function: for each query token, it selects the closest document token and sums these distances across all query tokens.\n  In our work, we explore enhancements to the Chamfer distance function by computing a weighted sum over query token contributions, where weights reflect the token importance. Empirically, we show that this simple extension, requiring only token-weight training while keeping the multi-vector representations fixed, further enhances the expressiveness of late interaction multi-vector mechanism. In particular, on the BEIR benchmark, our method achieves an average improvement of 1.28\\% in Recall@10 in the zero-shot setting using IDF-based weights, and 3.66\\% through few-shot fine-tuning.",
        "entry_id": "http://arxiv.org/abs/2511.16106v1",
        "pub_date": "2025-11-20",
        "translated_summary": "ColBERT通过引入延迟交互机制，采用BERT分别编码查询和文档，并基于词元级向量表示进行细粒度交互计算相似度。该设计在实现高效表达匹配的同时，支持离线预计算多向量文档表示以提升评分效率。该模型采用Chamfer风格的距离函数：为每个查询词元选取最接近的文档词元，并将所有查询词元的距离求和。\n\n本研究针对Chamfer距离函数提出改进方案，通过计算查询词元贡献度的加权和来增强模型性能，其中权重反映词元重要性。实证研究表明，在保持多向量表示固定的前提下，仅需进行词元权重训练，这一简单扩展即可进一步提升延迟交互多向量机制的表达能力。具体而言，在BEIR基准测试中，基于IDF权重的零样本设置下Recall@10指标平均提升1.28%，而经过少量样本微调后，该指标提升幅度可达3.66%。"
    },
    {
        "title": "QueryGym: A Toolkit for Reproducible LLM-Based Query Reformulation",
        "summary": "We present QueryGym, a lightweight, extensible Python toolkit that supports large language model (LLM)-based query reformulation. This is an important tool development since recent work on llm-based query reformulation has shown notable increase in retrieval effectiveness. However, while different authors have sporadically shared the implementation of their methods, there is no unified toolkit that provides a consistent implementation of such methods, which hinders fair comparison, rapid experimentation, consistent benchmarking and reliable deployment. QueryGym addresses this gap by providing a unified framework for implementing, executing, and comparing llm-based reformulation methods. The toolkit offers: (1) a Python API for applying diverse LLM-based methods, (2) a retrieval-agnostic interface supporting integration with backends such as Pyserini and PyTerrier, (3) a centralized prompt management system with versioning and metadata tracking, (4) built-in support for benchmarks like BEIR and MS MARCO, and (5) a completely open-source extensible implementation available to all researchers. QueryGym is publicly available at https://github.com/radinhamidi/QueryGym.",
        "entry_id": "http://arxiv.org/abs/2511.15996v1",
        "pub_date": "2025-11-20",
        "translated_summary": "我们推出QueryGym——一个轻量级、可扩展的Python工具包，专门支持基于大语言模型（LLM）的查询重构。这一工具的开发具有重要意义，因为近期研究表明基于LLM的查询重构能显著提升检索效果。然而，尽管不同研究者曾零散地分享过各自方法的实现，目前仍缺乏统一的工具包来提供标准化的实现方案，这阻碍了公平比较、快速实验、一致性基准测试和可靠部署。QueryGym通过提供统一的框架来解决这一痛点，支持基于LLM的重构方法的实施、执行与比较。该工具包具备五大特性：（1）提供应用多种LLM方法的Python API；（2）采用检索无关接口设计，支持与Pyserini、PyTerrier等后端系统集成；（3）建立集中式提示管理系统，支持版本控制与元数据追踪；（4）内置对BEIR、MS MARCO等基准测试的支持；（5）完全开源的扩展实现，向所有研究者开放。QueryGym已在https://github.com/radinhamidi/QueryGym 公开。"
    },
    {
        "title": "Selective Mixup for Debiasing Question Selection in Computerized Adaptive Testing",
        "summary": "Computerized Adaptive Testing (CAT) is a widely used technology for evaluating learners' proficiency in online education platforms. By leveraging prior estimates of proficiency to select questions and updating the estimates iteratively based on responses, CAT enables personalized learner modeling and has attracted substantial attention. Despite this progress, most existing works focus primarily on improving diagnostic accuracy, while overlooking the selection bias inherent in the adaptive process. Selection Bias arises because the question selection is strongly influenced by the estimated proficiency, such as assigning easier questions to learners with lower proficiency and harder ones to learners with higher proficiency. Since the selection depends on prior estimation, this bias propagates into the diagnosis model, which is further amplified during iterative updates, leading to misalignment and biased predictions. Moreover, the imbalanced nature of learners' historical interactions often exacerbates the bias in diagnosis models. To address this issue, we propose a debiasing framework consisting of two key modules: Cross-Attribute Examinee Retrieval and Selective Mixup-based Regularization. First, we retrieve balanced examinees with relatively even distributions of correct and incorrect responses and use them as neutral references for biased examinees. Then, mixup is applied between each biased examinee and its matched balanced counterpart under label consistency. This augmentation enriches the diversity of bias-conflicting samples and smooths selection boundaries. Finally, extensive experiments on two benchmark datasets with multiple advanced diagnosis models demonstrate that our method substantially improves both the generalization ability and fairness of question selection in CAT.",
        "entry_id": "http://arxiv.org/abs/2511.15241v2",
        "pub_date": "2025-11-19",
        "translated_summary": "计算机化自适应测试是在线教育平台中广泛使用的学习者能力评估技术。该技术通过基于能力预估值动态选题，并依据答题结果迭代更新能力估计，实现个性化学习者建模，已引起广泛关注。然而现有研究大多聚焦于提升诊断精度，忽视了自适应过程中固有的选择偏差问题。由于选题策略受能力估计值强烈影响（如向低能力者分配简单题目、向高能力者分配难题），而题目选择又依赖于先验估计，这种偏差会渗入诊断模型，并在迭代更新过程中被不断放大，最终导致预测结果失准。此外，学习者历史交互数据的不平衡性往往会加剧诊断模型的偏差。为解决该问题，我们提出包含双重核心模块的去偏框架：跨属性考生检索与选择性混合正则化。首先检索具有均衡正误答题分布的考生作为偏斜考生的中性参照，随后在保持标签一致性的前提下对偏斜考生与其匹配的均衡参照实施混合增强。该方法有效丰富了偏差冲突样本的多样性，平滑了选择边界。最终在两大基准数据集上的实验表明，我们的方案能显著提升计算机化自适应测试中选题策略的泛化能力与公平性。"
    },
    {
        "title": "A Little More Like This: Text-to-Image Retrieval with Vision-Language Models Using Relevance Feedback",
        "summary": "Large vision-language models (VLMs) enable intuitive visual search using natural language queries. However, improving their performance often requires fine-tuning and scaling to larger model variants. In this work, we propose a mechanism inspired by traditional text-based search to improve retrieval performance at inference time: relevance feedback. While relevance feedback can serve as an alternative to fine-tuning, its model-agnostic design also enables use with fine-tuned VLMs. Specifically, we introduce and evaluate four feedback strategies for VLM-based retrieval. First, we revise classical pseudo-relevance feedback (PRF), which refines query embeddings based on top-ranked results. To address its limitations, we propose generative relevance feedback (GRF), which uses synthetic captions for query refinement. Furthermore, we introduce an attentive feedback summarizer (AFS), a custom transformer-based model that integrates multimodal fine-grained features from relevant items. Finally, we simulate explicit feedback using ground-truth captions as an upper-bound baseline. Experiments on Flickr30k and COCO with the VLM backbones show that GRF, AFS, and explicit feedback improve retrieval performance by 3-5% in MRR@5 for smaller VLMs, and 1-3% for larger ones, compared to retrieval with no feedback. Moreover, AFS, similarly to explicit feedback, mitigates query drift and is more robust than GRF in iterative, multi-turn retrieval settings. Our findings demonstrate that relevance feedback can consistently enhance retrieval across VLMs and open up opportunities for interactive and adaptive visual search.",
        "entry_id": "http://arxiv.org/abs/2511.17255v1",
        "pub_date": "2025-11-21",
        "translated_summary": "大型视觉语言模型（VLMs）能够通过自然语言查询实现直观的视觉搜索。然而，提升其性能通常需要对模型进行微调或扩展至更大规模。本研究受传统文本搜索机制启发，提出在推理阶段通过相关性反馈提升检索性能的方法。该模型无关的设计既可替代微调，也可与经过微调的VLMs协同使用。具体而言，我们针对基于VLM的检索提出并评估了四种反馈策略：首先改进经典伪相关性反馈（PRF），通过top-ranked结果优化查询嵌入；为克服其局限性，提出生成式相关性反馈（GRF），利用合成描述文本进行查询优化；进一步设计注意力反馈汇总器（AFS），这是一种基于Transformer的定制模型，可整合相关项目的多模态细粒度特征；最后通过真实标注文本模拟显式反馈作为性能上限基准。在Flickr30k和COCO数据集上的实验表明，相较于无反馈检索，GRF、AFS与显式反馈能使较小VLM的MRR@5提升3-5%，较大模型提升1-3%。值得注意的是，AFS与显式反馈类似，能有效抑制查询漂移现象，并在迭代式多轮检索中表现出比GRF更强的鲁棒性。本研究证实相关性反馈能持续增强不同VLM的检索性能，为交互式自适应视觉搜索开辟了新路径。"
    },
    {
        "title": "Parametric Retrieval-Augmented Generation using Latent Routing of LoRA Adapters",
        "summary": "Parametric Retrieval-Augmented Generation (PRAG) is a novel RAG paradigm that integrates external knowledge directly into a Large Language Model (LLM) by parameterizing documents using LoRA adapters, demonstrating reduced inference costs compared to traditional RAG approaches. However, current PRAG approaches adopt a \\textbf{one-to-one} document encoding scheme, using a dedicated LoRA adapter for each individual document. This scheme introduces two major limitations: First, it leads to data scarcity, as the training datasets for individual LoRA adapters are limited. Second, it incurs high overhead during inference, requiring the merging of LLM weights with a new LoRA adapter for every candidate passage, which is computationally inefficient. To overcome these challenges, we propose a novel paradigm for encoding passages in PRAG that utilizes a latent routing encoding process (Poly-PRAG). During offline encoding, we treat the encoding of a set of documents as a multi-task learning process, where each passage is assigned a unique task identifier. By employing a routing function, we use a small set of latent LoRA adapters to encode the entire passage space. During online inference, this routing function selectively activates a subset of latent experts based on the input query. We conduct comprehensive evaluations of Poly-PRAG across multiple knowledge-intensive NLP tasks. Our extensive experiments demonstrate the effectiveness of the proposed method, achieving state-of-the-art results on four distinct datasets.",
        "entry_id": "http://arxiv.org/abs/2511.17044v1",
        "pub_date": "2025-11-21",
        "translated_summary": "参数化检索增强生成（PRAG）是一种新型RAG范式，它通过LoRA适配器对文档进行参数化，将外部知识直接整合到大语言模型中，相比传统RAG方法显著降低了推理成本。然而，现有PRAG方法采用**一对一**的文档编码方案，为每个独立文档配备专属LoRA适配器。这种方案存在两大局限：首先，由于单个LoRA适配器的训练数据有限，会导致数据稀疏问题；其次，在推理过程中需要为每个候选文本段合并新的LoRA适配器与LLM权重，产生了高昂的计算开销。为突破这些限制，我们提出了一种新颖的PRAG文本编码范式——潜在路由编码机制（Poly-PRAG）。在离线编码阶段，我们将文档集的编码视为多任务学习过程，为每个文本段分配唯一任务标识符。通过路由函数调度，仅需少量潜在LoRA适配器即可覆盖整个文本空间的编码需求。在线推理时，该路由函数会根据输入查询动态激活对应的潜在专家子集。我们在多个知识密集型NLP任务上对Poly-PRAG进行了全面评估，大量实验证明该方法的有效性，在四个不同数据集上均取得了最先进的性能表现。"
    },
    {
        "title": "CLLMRec: LLM-powered Cognitive-Aware Concept Recommendation via Semantic Alignment and Prerequisite Knowledge Distillation",
        "summary": "The growth of Massive Open Online Courses (MOOCs) presents significant challenges for personalized learning, where concept recommendation is crucial. Existing approaches typically rely on heterogeneous information networks or knowledge graphs to capture conceptual relationships, combined with knowledge tracing models to assess learners' cognitive states. However, these methods face significant limitations due to their dependence on high-quality structured knowledge graphs, which are often scarce in real-world educational scenarios. To address this fundamental challenge, this paper proposes CLLMRec, a novel framework that leverages Large Language Models through two synergistic technical pillars: Semantic Alignment and Prerequisite Knowledge Distillation. The Semantic Alignment component constructs a unified representation space by encoding unstructured textual descriptions of learners and concepts. The Prerequisite Knowledge Distillation paradigm employs a teacher-student architecture, where a large teacher LLM (implemented as the Prior Knowledge Aware Component) extracts conceptual prerequisite relationships from its internalized world knowledge and distills them into soft labels to train an efficient student ranker. Building upon these foundations, our framework incorporates a fine-ranking mechanism that explicitly models learners' real-time cognitive states through deep knowledge tracing, ensuring recommendations are both structurally sound and cognitively appropriate. Extensive experiments on two real-world MOOC datasets demonstrate that CLLMRec significantly outperforms existing baseline methods across multiple evaluation metrics, validating its effectiveness in generating truly cognitive-aware and personalized concept recommendations without relying on explicit structural priors.",
        "entry_id": "http://arxiv.org/abs/2511.17041v1",
        "pub_date": "2025-11-21",
        "translated_summary": "大规模在线开放课程(MOOC)的快速发展为个性化学习带来了重大挑战，其中概念推荐尤为关键。现有方法通常依赖异构信息网络或知识图谱来捕捉概念关系，并结合知识追踪模型评估学习者认知状态。然而，这些方法因依赖高质量结构化知识图谱而存在明显局限，而现实教育场景中此类图谱往往稀缺。为应对这一根本性挑战，本文提出CLLMRec创新框架，通过两大协同技术支柱利用大语言模型：语义对齐与先修知识蒸馏。语义对齐组件通过编码学习者与概念的非结构化文本描述，构建统一表征空间；先修知识蒸馏范式采用师生架构，由大型教师LLM（实现为先验知识感知组件）从其内化的世界知识中提取概念先修关系，并将其蒸馏为软标签以训练高效的学生排序器。在此基础上，我们的框架引入精细排序机制，通过深度知识追踪显式建模学习者实时认知状态，确保推荐既符合知识结构又契合认知水平。在两个真实MOOC数据集上的大量实验表明，CLLMRec在多项评估指标上显著优于现有基线方法，验证了该框架在不依赖显式结构先验的情况下，能有效生成真正具有认知意识且个性化的概念推荐。"
    },
    {
        "title": "RASTP: Representation-Aware Semantic Token Pruning for Generative Recommendation with Semantic Identifiers",
        "summary": "Generative recommendation systems typically leverage Semantic Identifiers (SIDs), which represent each item as a sequence of tokens that encode semantic information. However, representing item ID with multiple SIDs significantly increases input sequence length, which is a major determinant of computational complexity and memory consumption. While existing efforts primarily focus on optimizing attention computation and KV cache, we propose RASTP (Representation-Aware Semantic Token Pruning), which directly prunes less informative tokens in the input sequence. Specifically, RASTP evaluates token importance by combining semantic saliency, measured via representation magnitude, and attention centrality, derived from cumulative attention weights. Since RASTP dynamically prunes low-information or irrelevant semantic tokens, experiments on three real-world Amazon datasets show that RASTP reduces training time by 26.7\\%, while maintaining or slightly improving recommendation performance. The code has been open-sourced at https://github.com/Yuzt-zju/RASTP.",
        "entry_id": "http://arxiv.org/abs/2511.16943v1",
        "pub_date": "2025-11-21",
        "translated_summary": "生成式推荐系统通常利用语义标识符（SID），将每个物品表示为编码语义信息的标记序列。然而，使用多个SID表示物品ID会显著增加输入序列长度，这成为计算复杂度和内存消耗的主要制约因素。现有研究主要聚焦于优化注意力计算和KV缓存，而本文提出RASTP（表征感知语义标记剪枝）方法，直接对输入序列中信息量较低的标记进行剪枝。具体而言，RASTP通过结合语义显著性（通过表征幅度度量）和注意力中心性（源自累积注意力权重）来评估标记重要性。由于RASTP能动态剪枝低信息量或不相关的语义标记，在三个真实亚马逊数据集上的实验表明，该方法在保持或略微提升推荐性能的同时，将训练时间缩短了26.7%。相关代码已开源：https://github.com/Yuzt-zju/RASTP。"
    },
    {
        "title": "δ-EMG: A Monotonic Graph Index for Approximate Nearest Neighbor Search",
        "summary": "Approximate nearest neighbor (ANN) search in high-dimensional spaces is a foundational component of many modern retrieval and recommendation systems. Currently, almost all algorithms follow an $ε$-Recall-Bounded principle when comparing performance: they require the ANN search results to achieve a recall of more than $1-ε$ and then compare query-per-second (QPS) performance. However, this approach only accounts for the recall of true positive results and does not provide guarantees on the deviation of incorrect results. To address this limitation, we focus on an Error-Bounded ANN method, which ensures that the returned results are a $(1/δ)$-approximation of the true values. Our approach adopts a graph-based framework. To enable Error-Bounded ANN search, we propose a $δ$-EMG (Error-bounded Monotonic Graph), which, for the first time, provides a provable approximation for arbitrary queries. By enforcing a $δ$-monotonic geometric constraint during graph construction, $δ$-EMG ensures that any greedy search converges to a $(1/δ)$-approximate neighbor without backtracking. Building on this foundation, we design an error-bounded top-$k$ ANN search algorithm that adaptively controls approximation accuracy during query time. To make the framework practical at scale, we introduce $δ$-EMQG (Error-bounded Monotonic Quantized Graph), a localized and degree-balanced variant with near-linear construction complexity. We further integrate vector quantization to accelerate distance computation while preserving theoretical guarantees. Extensive experiments on the ANN-Benchmarks dataset demonstrate the effectiveness of our approach. Under a recall requirement of 0.99, our algorithm achieves 19,000 QPS on the SIFT1M dataset, outperforming other methods by more than 40\\%.",
        "entry_id": "http://arxiv.org/abs/2511.16921v1",
        "pub_date": "2025-11-21",
        "translated_summary": "高维空间中的近似最近邻搜索是现代检索与推荐系统的核心组件。当前算法在性能比较时普遍遵循$ε$-召回率约束原则：要求搜索结果达到$1-ε$以上的召回率后比较每秒查询率。但这种方法仅考虑正样本召回率，无法保证错误结果的偏离程度。为突破这一局限，我们提出误差有界的近似最近邻方法，确保返回结果与真实值构成$(1/δ)$-近似。该框架采用图结构实现，我们首次提出具备可证明近似能力的$δ$-误差有界单调图，通过在构图阶段强制施加$δ$-单调几何约束，使得任意查询的贪婪搜索无需回溯即可收敛至$(1/δ)$-近似解。基于该结构，我们设计了误差有界的Top-$k$搜索算法，在查询时自适应控制近似精度。为实现大规模应用，我们进一步提出$δ$-误差有界量化图，这种具备局部性与度平衡特性的变体具有近线性构建复杂度，并通过向量量化加速距离计算且保持理论保证。在ANN-Benchmarks数据集上的实验表明，当召回率要求为0.99时，我们的算法在SIFT1M数据集上实现19,000 QPS，较现有方法提升超40%。"
    },
    {
        "title": "Revisiting Feedback Models for HyDE",
        "summary": "Recent approaches that leverage large language models (LLMs) for pseudo-relevance feedback (PRF) have generally not utilized well-established feedback models like Rocchio and RM3 when expanding queries for sparse retrievers like BM25. Instead, they often opt for a simple string concatenation of the query and LLM-generated expansion content. But is this optimal? To answer this question, we revisit and systematically evaluate traditional feedback models in the context of HyDE, a popular method that enriches query representations with LLM-generated hypothetical answer documents. Our experiments show that HyDE's effectiveness can be substantially improved when leveraging feedback algorithms such as Rocchio to extract and weight expansion terms, providing a simple way to further enhance the accuracy of LLM-based PRF methods.",
        "entry_id": "http://arxiv.org/abs/2511.19349v1",
        "pub_date": "2025-11-24",
        "translated_summary": "当前利用大语言模型进行伪相关反馈的研究，在扩展BM25等稀疏检索器的查询时，通常未采用Rocchio、RM3等成熟反馈模型，而是直接将原始查询与LLM生成的扩展内容进行字符串拼接。这种简单处理是否最优？为解答该问题，我们以HyDE方法为研究对象——该方法通过LLM生成假设性答案文档来丰富查询表征，系统性地重新评估了传统反馈模型的应用价值。实验表明：当采用Rocchio等反馈算法对扩展词项进行提取和加权时，HyDE的检索效果可获得显著提升，这为增强基于LLM的伪相关反馈方法准确率提供了一条简洁有效的改进路径。"
    },
    {
        "title": "Generative Query Expansion with Multilingual LLMs for Cross-Lingual Information Retrieval",
        "summary": "Query expansion is the reformulation of a user query by adding semantically related information, and is an essential component of monolingual and cross-lingual information retrieval used to ensure that relevant documents are not missed. Recently, multilingual large language models (mLLMs) have shifted query expansion from semantic augmentation with synonyms and related words to pseudo-document generation. Pseudo-documents both introduce additional relevant terms and bridge the gap between short queries and long documents, which is particularly beneficial in dense retrieval. This study evaluates recent mLLMs and fine-tuned variants across several generative expansion strategies to identify factors that drive cross-lingual retrieval performance. Results show that query length largely determines which prompting technique is effective, and that more elaborate prompts often do not yield further gains. Substantial linguistic disparities persist: cross-lingual query expansion can produce the largest improvements for languages with the weakest baselines, yet retrieval is especially poor between languages written in different scripts. Fine-tuning is found to lead to performance gains only when the training and test data are of similar format. These outcomes underline the need for more balanced multilingual and cross-lingual training and evaluation resources.",
        "entry_id": "http://arxiv.org/abs/2511.19325v1",
        "pub_date": "2025-11-24",
        "translated_summary": "查询扩展是通过添加语义相关信息对用户查询进行重构的技术，是单语与跨语言信息检索中确保相关文档不被遗漏的关键环节。随着多语种大语言模型（mLLMs）的发展，查询扩展已从同义词和关联词语义增强转向伪文档生成。伪文档不仅能引入更多相关术语，更能弥合简短查询与长文档之间的鸿沟，这对稠密检索尤为有利。本研究通过多种生成式扩展策略评估了当前主流mLLMs及其微调变体，以探究驱动跨语言检索性能的关键因素。结果显示：查询长度很大程度上决定了提示技术的有效性，而更复杂的提示往往无法带来额外收益；语言差异问题依然显著——基线性能最弱的语言通过跨语言查询扩展可获得最大提升，但不同文字体系语言间的检索效果仍不理想；微调仅当训练与测试数据格式相近时才能提升性能。这些发现凸显了建立更均衡的多语言与跨语言训练及评估资源的迫切性。"
    },
    {
        "title": "What Drives Cross-lingual Ranking? Retrieval Approaches with Multilingual Language Models",
        "summary": "Cross-lingual information retrieval (CLIR) enables access to multilingual knowledge but remains challenging due to disparities in resources, scripts, and weak cross-lingual semantic alignment in embedding models. Existing pipelines often rely on translation and monolingual retrieval heuristics, which add computational overhead and noise, degrading performance. This work systematically evaluates four intervention types, namely document translation, multilingual dense retrieval with pretrained encoders, contrastive learning at word, phrase, and query-document levels, and cross-encoder re-ranking, across three benchmark datasets. We find that dense retrieval models trained specifically for CLIR consistently outperform lexical matching methods and derive little benefit from document translation. Contrastive learning mitigates language biases and yields substantial improvements for encoders with weak initial alignment, and re-ranking can be effective, but depends on the quality of the cross-encoder training data. Although high-resource languages still dominate overall performance, gains over lexical and document-translated baselines are most pronounced for low-resource and cross-script pairs. These findings indicate that cross-lingual search systems should prioritise semantic multilingual embeddings and targeted learning-based alignment over translation-based pipelines, particularly for cross-script and under-resourced languages.",
        "entry_id": "http://arxiv.org/abs/2511.19324v1",
        "pub_date": "2025-11-24",
        "translated_summary": "跨语言信息检索虽能帮助人们获取多语言知识，但由于资源差异、文字体系不同以及嵌入模型中跨语言语义对齐能力较弱，该技术仍面临挑战。现有流程通常依赖翻译和单语检索启发式方法，这会增加计算开销并引入噪声，导致性能下降。本研究系统评估了四种干预类型——文档翻译、基于预训练编码器的多语言稠密检索、在词汇/短语/查询-文档层面的对比学习，以及交叉编码器重排序——在三个基准数据集上的表现。我们发现：专门针对跨语言检索训练的稠密检索模型持续优于词汇匹配方法，且几乎无法从文档翻译中获益；对比学习能有效缓解语言偏见，对初始对齐能力较弱的编码器带来显著提升；重排序虽具有潜力，但其效果取决于交叉编码器训练数据的质量。尽管高资源语言在整体性能上仍占优势，但针对低资源语言及跨文字体系语言对的检索效果，相比词汇匹配和文档翻译基线方法提升最为显著。这些发现表明，跨语言搜索系统应优先考虑基于语义的多语言嵌入和有针对性的学习对齐方法，而非依赖翻译流程，这对跨文字体系及资源匮乏语言尤为重要。"
    },
    {
        "title": "From Raw Features to Effective Embeddings: A Three-Stage Approach for Multimodal Recipe Recommendation",
        "summary": "Recipe recommendation has become an essential task in web-based food platforms. A central challenge is effectively leveraging rich multimodal features beyond user-recipe interactions. Our analysis shows that even simple uses of multimodal signals yield competitive performance, suggesting that systematic enhancement of these signals is highly promising. We propose TESMR, a 3-stage framework for recipe recommendation that progressively refines raw multimodal features into effective embeddings through: (1) content-based enhancement using foundation models with multimodal comprehension, (2) relation-based enhancement via message propagation over user-recipe interactions, and (3) learning-based enhancement through contrastive learning with learnable embeddings. Experiments on two real-world datasets show that TESMR outperforms existing methods, achieving 7-15% higher Recall@10.",
        "entry_id": "http://arxiv.org/abs/2511.19176v1",
        "pub_date": "2025-11-24",
        "translated_summary": "食谱推荐已成为在线美食平台的核心任务，其关键挑战在于如何有效利用用户-食谱交互之外的多模态特征。分析表明，即使简单运用多模态信号也能取得可观效果，这预示着系统化增强此类信号具有巨大潜力。我们提出TESMR三阶段推荐框架，通过以下方式将原始多模态特征逐步优化为高效嵌入表示：（1）基于多模态理解基础模型的内容增强；（2）通过用户-食谱交互消息传递的关系增强；（3）结合可学习嵌入对比学习的学习增强。在两个真实数据集上的实验表明，TESMR以7-15%的Recall@10提升率超越现有方法。"
    },
    {
        "title": "Heterogeneous Multi-treatment Uplift Modeling for Trade-off Optimization in Short-Video Recommendation",
        "summary": "The rapid proliferation of short videos on social media platforms presents unique challenges and opportunities for recommendation systems. Users exhibit diverse preferences, and the responses resulting from different strategies often conflict with one another, potentially exhibiting inverse correlations between metrics such as watch time and video view counts. Existing uplift models face limitations in handling the heterogeneous multi-treatment scenarios of short-video recommendations, often failing to effectively capture both the synergistic and individual causal effects of different strategies. Furthermore, traditional fixed-weight approaches for balancing these responses lack personalization and can result in biased decision-making. To address these issues, we propose a novel Heterogeneous Multi-treatment Uplift Modeling (HMUM) framework for trade-off optimization in short-video recommendations. HMUM comprises an Offline Hybrid Uplift Modeling (HUM) module, which captures the synergistic and individual effects of multiple strategies, and an Online Dynamic Decision-Making (DDM) module, which estimates the value weights of different user responses in real-time for personalized decision-making. Evaluated on two public datasets, an industrial dataset, and through online A/B experiments on the Kuaishou platform, our model demonstrated superior offline performance and significant improvements in key metrics. It is now fully deployed on the platform, benefiting hundreds of millions of users.",
        "entry_id": "http://arxiv.org/abs/2511.18997v1",
        "pub_date": "2025-11-24",
        "translated_summary": "社交媒体平台上短视频的快速传播为推荐系统带来了独特的挑战与机遇。用户偏好呈现多元化特征，不同策略引发的响应常相互冲突，观看时长与视频点击量等指标间甚至可能呈现负相关性。现有提升模型在处理短视频推荐中的异构多策略场景时存在局限，往往难以同时捕捉不同策略的协同效应与独立因果影响。此外，传统固定权重的响应平衡方法缺乏个性化考量，易导致决策偏差。针对这些问题，我们提出一种新颖的异构多策略提升模型（HMUM）框架，用于短视频推荐中的权衡优化。该框架包含离线混合提升建模（HUM）模块——用于捕捉多策略的协同与独立效应，以及在线动态决策（DDM）模块——通过实时评估不同用户响应的价值权重实现个性化决策。在两组公开数据集、一组工业数据集及快手平台的在线A/B测试中，我们的模型展现出卓越的离线性能及关键指标的显著提升。目前该模型已在平台全面部署，服务数亿用户。"
    },
    {
        "title": "STORE: Semantic Tokenization, Orthogonal Rotation and Efficient Attention for Scaling Up Ranking Models",
        "summary": "Ranking models have become an important part of modern personalized recommendation systems. However, significant challenges persist in handling high-cardinality, heterogeneous, and sparse feature spaces, particularly regarding model scalability and efficiency. We identify two key bottlenecks: (i) Representation Bottleneck: Driven by the high cardinality and dynamic nature of features, model capacity is forced into sparse-activated embedding layers, leading to low-rank representations. This, in turn, triggers phenomena like \"One-Epoch\" and \"Interaction-Collapse,\" ultimately hindering model scalability.(ii) Computational Bottleneck: Integrating all heterogeneous features into a unified model triggers an explosion in the number of feature tokens, rendering traditional attention mechanisms computationally demanding and susceptible to attention dispersion. To dismantle these barriers, we introduce STORE, a unified and scalable token-based ranking framework built upon three core innovations: (1) Semantic Tokenization fundamentally tackles feature heterogeneity and sparsity by decomposing high-cardinality sparse features into a compact set of stable semantic tokens; and (2) Orthogonal Rotation Transformation is employed to rotate the subspace spanned by low-cardinality static features, which facilitates more efficient and effective feature interactions; and (3) Efficient attention that filters low-contributing tokens to improve computional efficiency while preserving model accuracy. Across extensive offline experiments and online A/B tests, our framework consistently improves prediction accuracy(online CTR by 2.71%, AUC by 1.195%) and training effeciency (1.84 throughput).",
        "entry_id": "http://arxiv.org/abs/2511.18805v1",
        "pub_date": "2025-11-24",
        "translated_summary": "排序模型已成为现代个性化推荐系统的重要组成部分。然而在处理高基数、异构且稀疏的特征空间时，尤其在模型可扩展性与效率方面仍存在显著挑战。我们识别出两大核心瓶颈：（i）表征瓶颈：受高基数特征动态特性驱动，模型容量被迫集中于稀疏激活的嵌入层，导致低秩表征，进而引发\"单周期\"与\"交互坍缩\"现象，最终制约模型扩展性；（ii）计算瓶颈：将所有异构特征整合至统一模型会引发特征令牌数量激增，使得传统注意力机制计算成本高昂且易受注意力分散影响。为突破这些障碍，我们提出STORE——基于三大核心创新的统一可扩展令牌排序框架：（1）语义令牌化通过将高基数稀疏特征解构为紧凑的稳定语义令牌集合，从根本上解决特征异构性与稀疏性问题；（2）采用正交旋转变换对低基数静态特征张成的子空间进行旋转，促进更高效的特征交互；（3）通过过滤低贡献令牌的高效注意力机制，在保持模型精度的同时提升计算效率。经过大量离线实验与在线A/B测试，本框架持续提升预测准确率（在线CTR提升2.71%，AUC提升1.195%）与训练效率（吞吐量提升1.84倍）。"
    },
    {
        "title": "Large Language Models Require Curated Context for Reliable Political Fact-Checking -- Even with Reasoning and Web Search",
        "summary": "Large language models (LLMs) have raised hopes for automated end-to-end fact-checking, but prior studies report mixed results. As mainstream chatbots increasingly ship with reasoning capabilities and web search tools -- and millions of users already rely on them for verification -- rigorous evaluation is urgent. We evaluate 15 recent LLMs from OpenAI, Google, Meta, and DeepSeek on more than 6,000 claims fact-checked by PolitiFact, comparing standard models with reasoning- and web-search variants. Standard models perform poorly, reasoning offers minimal benefits, and web search provides only moderate gains, despite fact-checks being available on the web. In contrast, a curated RAG system using PolitiFact summaries improved macro F1 by 233% on average across model variants. These findings suggest that giving models access to curated high-quality context is a promising path for automated fact-checking.",
        "entry_id": "http://arxiv.org/abs/2511.18749v1",
        "pub_date": "2025-11-24",
        "translated_summary": "大型语言模型为自动化端到端事实核查带来了希望，但先前研究得出的结果好坏参半。随着主流聊天机器人普遍配备推理能力和网络搜索工具——且已有数百万用户依赖其进行信息验证——开展严谨评估已刻不容缓。我们基于PolitiFact核查的6000余条声明，对OpenAI、谷歌、Meta和DeepSeek的15款最新大模型进行评估，对比了标准模型与具备推理能力及网络搜索功能的变体。结果显示：标准模型表现欠佳，推理能力带来的提升微乎其微，尽管网络中存在事实核查记录，网络搜索仅带来有限改进。相比之下，采用PolitiFact摘要的定向检索增强生成系统，在不同模型变体上平均将宏观F1值提升了233%。这些发现表明，为模型提供经过筛选的高质量上下文，是实现自动化事实核查的有效路径。"
    },
    {
        "title": "Multimodal Large Language Models with Adaptive Preference Optimization for Sequential Recommendation",
        "summary": "Recent advances in Large Language Models (LLMs) have opened new avenues for sequential recommendation by enabling natural language reasoning over user behavior sequences. A common approach formulates recommendation as a language modeling task, where interaction histories are transformed into prompts and user preferences are learned via supervised fine-tuning. However, these methods operate solely in the textual modality and often miss users' fine-grained interests, especially when shaped by rich visual signals such as product images or movie posters. Multimodal Large Language Models (MLLMs) offer a promising alternative by aligning text and vision in a shared semantic space. A prevalent training paradigm applies Supervised Fine-Tuning (SFT) followed by Direct Preference Optimization (DPO) to model user preferences. Yet, two core challenges remain: 1) Imbalanced sample hardness, where random negative sampling causes overfitting on easy examples and under-training on hard ones; 2) Cross-modal semantic bias, where the fixed reference model in DPO prevents the policy model from correcting modality misalignments--especially over long sequences. To address these issues, we propose a Multimodal LLM framework that integrates Hardness-aware and Noise-regularized preference optimization for Recommendation (HaNoRec). Specifically, HaNoRec dynamically adjusts optimization weights based on both the estimated hardness of each training sample and the policy model's real-time responsiveness, prioritizing harder examples. It further introduces Gaussian-perturbed distribution optimization on output logits to enhance cross-modal semantic consistency and reduce modality bias inherited from the reference model.",
        "entry_id": "http://arxiv.org/abs/2511.18740v1",
        "pub_date": "2025-11-24",
        "translated_summary": "大型语言模型（LLM）的最新进展通过实现对用户行为序列的自然语言推理，为序列推荐开辟了新途径。主流方法将推荐任务构建为语言建模问题：将交互历史转换为提示文本，通过监督微调学习用户偏好。然而这些方法仅基于文本模态，往往忽略用户的细粒度兴趣——尤其是当这些兴趣由商品图片、电影海报等丰富视觉信号塑造时。多模态大语言模型（MLLM）通过将文本与视觉对齐到共享语义空间，提供了更有前景的解决方案。当前主流训练范式采用监督微调（SFT）与直接偏好优化（DPO）相结合的方式来建模用户偏好，但仍存在两大核心挑战：1）样本难度失衡，随机负采样会导致模型过拟合简单样本而难以样本训练不足；2）跨模态语义偏差，DPO中固定的参考模型会阻碍策略模型修正模态未对齐问题（在长序列中尤为突出）。为此，我们提出HaNoRec多模态大语言模型框架，通过集成面向推荐的硬度感知与噪声正则化偏好优化方法，动态根据样本预估难度和策略模型实时响应度调整优化权重，优先处理困难样本；同时引入输出逻辑的高斯扰动分布优化，以增强跨模态语义一致性，降低参考模型继承的模态偏差。"
    },
    {
        "title": "When and What to Recommend: Joint Modeling of Timing and Content for Active Sequential Recommendation",
        "summary": "Sequential recommendation models user preferences to predict the next target item. Most existing work is passive, where the system responds only when users open the application, missing chances after closure. We investigate active recommendation, which predicts the next interaction time and actively delivers items. Two challenges: accurately estimating the Time of Interest (ToI) and generating Item of Interest (IoI) conditioned on the predicted ToI. We propose PASRec, a diffusion-based framework that aligns ToI and IoI via a joint objective. Experiments on five benchmarks show superiority over eight state-of-the-art baselines under leave-one-out and temporal splits.",
        "entry_id": "http://arxiv.org/abs/2511.18717v1",
        "pub_date": "2025-11-24",
        "translated_summary": "序列推荐通过建模用户偏好来预测下一目标项目。现有研究大多采用被动推荐模式，仅在用户打开应用时进行响应，错失了应用关闭后的推荐机会。本文研究主动推荐范式，通过预测下次交互时间并主动推送项目。该模式面临两大挑战：如何精准预测兴趣时间点，以及如何基于预测时间生成兴趣项目。我们提出PASRec——基于扩散模型的推荐框架，通过联合优化目标实现兴趣时间与兴趣项目的协同对齐。在五个基准数据集上的实验表明，该方法在留一法和时间分割两种评估策略下均优于八种前沿基线模型。"
    },
    {
        "title": "A Recommender System Based on Binary Matrix Representations for Cognitive Disorders",
        "summary": "Diagnosing cognitive (mental health) disorders is a delicate and complex task. Identifying the next most informative symptoms to assess, in order to distinguish between possible disorders, presents an additional challenge. This process requires comprehensive knowledge of diagnostic criteria and symptom overlap across disorders, making it difficult to navigate based on symptoms alone. This research aims to develop a recommender system for cognitive disorder diagnosis using binary matrix representations. The core algorithm utilizes a binary matrix of disorders and their symptom combinations. It filters through the rows and columns based on the patient's current symptoms to identify potential disorders and recommend the most informative next symptoms to examine. A prototype of the recommender system was implemented in Python. Using synthetic test and some real-life data, the system successfully identified plausible disorders from an initial symptom set and recommended further symptoms to refine the diagnosis. It also provided additional context on the symptom-disorder relationships. Although this is a prototype, the recommender system shows potential as a clinical support tool. A fully-developed application of this recommender system may assist mental health professionals in identifying relevant disorders more efficiently and guiding symptom-specific follow-up investigations to improve diagnostic accuracy.",
        "entry_id": "http://arxiv.org/abs/2511.18645v1",
        "pub_date": "2025-11-23",
        "translated_summary": "认知障碍（心理健康）诊断是一项精细而复杂的任务。如何从可能的障碍中筛选出最具信息量的待评估症状，构成了额外挑战。该过程需要掌握诊断标准与症状跨障碍重叠的全面知识，仅凭症状本身难以准确判断。本研究旨在开发一种基于二元矩阵表征的认知障碍诊断推荐系统，其核心算法通过构建障碍与症状组合的二元矩阵，根据患者当前症状对行列进行筛选，从而识别潜在障碍并推荐最具诊断价值的下阶段待查症状。研究采用Python实现了该推荐系统的原型，通过合成测试数据与部分真实数据验证，系统成功从初始症状集中识别出合理障碍，给出优化诊断的后续症状建议，并提供症状-障碍关联的补充信息。尽管目前仅为原型系统，但其已展现出作为临床辅助工具的潜力。该推荐系统的完整应用版本有望帮助心理健康从业者更高效地识别相关障碍，并通过针对性症状追踪调查提升诊断准确性。"
    },
    {
        "title": "General Agentic Memory Via Deep Research",
        "summary": "Memory is critical for AI agents, yet the widely-adopted static memory, aiming to create readily available memory in advance, is inevitably subject to severe information loss. To address this limitation, we propose a novel framework called \\textbf{general agentic memory (GAM)}. GAM follows the principle of \"\\textbf{just-in time (JIT) compilation}\" where it focuses on creating optimized contexts for its client at runtime while keeping only simple but useful memory during the offline stage. To this end, GAM employs a duo-design with the following components. 1) \\textbf{Memorizer}, which highlights key historical information using a lightweight memory, while maintaining complete historical information within a universal page-store. 2) \\textbf{Researcher}, which retrieves and integrates useful information from the page-store for its online request guided by the pre-constructed memory. This design allows GAM to effectively leverage the agentic capabilities and test-time scalability of frontier large language models (LLMs), while also facilitating end-to-end performance optimization through reinforcement learning. In our experimental study, we demonstrate that GAM achieves substantial improvement on various memory-grounded task completion scenarios against existing memory systems.",
        "entry_id": "http://arxiv.org/abs/2511.18423v1",
        "pub_date": "2025-11-23",
        "translated_summary": "记忆对AI智能体至关重要，然而当前广泛采用的静态记忆系统试图预先构建现成可用的记忆，这不可避免地会导致严重的信息丢失。为突破这一局限，我们提出名为“通用智能记忆（GAM）”的创新框架。该框架遵循“即时编译”原则，在离线阶段仅保留简洁有效的记忆，而在运行时专注于为客户端生成优化上下文。为实现这一目标，GAM采用双模块设计：1）记忆模块通过轻量级记忆库提炼关键历史信息，同时在通用页面存储中保存完整历史记录；2）研究模块基于预构建记忆的指引，从页面存储中检索并整合在线请求所需的有效信息。这种设计使GAM能充分发挥前沿大语言模型的智能能力与测试时扩展性，同时通过强化学习实现端到端的性能优化。实验结果表明，在多种需要记忆支撑的任务场景中，GAM相较现有记忆系统均取得显著性能提升。"
    },
    {
        "title": "Multi-Agent Collaborative Filtering: Orchestrating Users and Items for Agentic Recommendations",
        "summary": "Agentic recommendations cast recommenders as large language model (LLM) agents that can plan, reason, use tools, and interact with users of varying preferences in web applications. However, most existing agentic recommender systems focus on generic single-agent plan-execute workflows or multi-agent task decomposition pipelines. Without recommendation-oriented design, they often underuse the collaborative signals in the user-item interaction history, leading to unsatisfying recommendation results. To address this, we propose the Multi-Agent Collaborative Filtering (MACF) framework for agentic recommendations, drawing an analogy between traditional collaborative filtering algorithms and LLM-based multi-agent collaboration. Specifically, given a target user and query, we instantiate similar users and relevant items as LLM agents with unique profiles. Each agent is able to call retrieval tools, suggest candidate items, and interact with other agents. Different from the static preference aggregation in traditional collaborative filtering, MACF employs a central orchestrator agent to adaptively manage the collaboration between user and item agents via dynamic agent recruitment and personalized collaboration instruction. Experimental results on datasets from three different domains show the advantages of our MACF framework compared to strong agentic recommendation baselines.",
        "entry_id": "http://arxiv.org/abs/2511.18413v1",
        "pub_date": "2025-11-23",
        "translated_summary": "代理式推荐将推荐系统视为大型语言模型（LLM）智能体，这些智能体能够在网络应用中规划、推理、使用工具并与不同偏好的用户互动。然而，现有的大多数代理式推荐系统主要关注通用的单智能体规划执行流程或多智能体任务分解流程。由于缺乏面向推荐的设计，这些系统往往未能充分利用用户-物品交互历史中的协同信号，导致推荐结果不尽如人意。为解决这一问题，我们借鉴传统协同过滤算法与基于LLM的多智能体协作之间的相似性，提出了面向代理式推荐的多智能体协同过滤框架（MACF）。具体而言，针对目标用户和查询，我们将相似用户和相关物品实例化为具有独特配置文件的LLM智能体。每个智能体能够调用检索工具、推荐候选物品并与其他智能体交互。与传统协同过滤中静态的偏好聚合不同，MACF通过中央协调智能体，采用动态智能体招募和个性化协作指令的方式，自适应地管理用户与物品智能体之间的协作。在三个不同领域数据集上的实验结果表明，我们的MACF框架相较于强大的代理式推荐基线方法具有显著优势。"
    },
    {
        "title": "A Multimodal Conversational Agent for Tabular Data Analysis",
        "summary": "Large language models (LLMs) can reshape information processing by handling data analysis, visualization, and interpretation in an interactive, context-aware dialogue with users, including voice interaction, while maintaining high performance. In this article, we present Talk2Data, a multimodal LLM-driven conversational agent for intuitive data exploration. The system lets users query datasets with voice or text instructions and receive answers as plots, tables, statistics, or spoken explanations. Built on LLMs, the suggested design combines OpenAI Whisper automatic speech recognition (ASR) system, Qwen-coder code generation LLM/model, custom sandboxed execution tools, and Coqui library for text-to-speech (TTS) within an agentic orchestration loop. Unlike text-only analysis tools, it adapts responses across modalities and supports multi-turn dialogues grounded in dataset context. In an evaluation of 48 tasks on three datasets, our prototype achieved 95.8% accuracy with model-only generation time under 1.7 seconds (excluding ASR and execution time). A comparison across five LLM sizes (1.5B-32B) revealed accuracy-latency-cost trade-offs, with a 7B model providing the best balance for interactive use. By routing between conversation with user and code execution, constrained to a transparent sandbox, with simultaneously grounding prompts in schema-level context, the Talk2Data agent reliably retrieves actionable insights from tables while making computations verifiable. In the article, except for the Talk2Data agent itself, we discuss implications for human-data interaction, trust in LLM-driven analytics, and future extensions toward large-scale multimodal assistants.",
        "entry_id": "http://arxiv.org/abs/2511.18405v1",
        "pub_date": "2025-11-23",
        "translated_summary": "大型语言模型（LLM）能够通过与用户进行包含语音交互的情境感知对话，在保持高性能的同时处理数据分析、可视化和解读，从而重塑信息处理模式。本文提出Talk2Data——一个基于多模态LLM驱动的对话式智能体，用于实现直观的数据探索。该系统允许用户通过语音或文本指令查询数据集，并以图表、表格、统计量或语音解释形式获取答案。该架构以LLM为核心，整合了OpenAI Whisper自动语音识别系统、Qwen-coder代码生成模型、定制化沙箱执行工具以及Coqui文本转语音库，形成智能体协同工作回路。与纯文本分析工具不同，该系统支持跨模态响应适配，并能基于数据集上下文进行多轮对话。在三个数据集48项任务的评估中，原型系统实现95.8%准确率，纯模型生成时间低于1.7秒（不含语音识别与执行时间）。通过对五种参数量（1.5B-32B）LLM的对比实验，揭示了准确率-延迟-成本的平衡关系，其中7B模型在交互场景中表现最佳。通过在与用户对话和代码执行之间建立路由机制（约束于透明沙箱），同时将提示词锚定于模式级上下文，Talk2Data智能体在确保计算可验证的前提下，能可靠地从表格数据中提取可操作的洞察。除系统本身外，本文还探讨了该技术对人机数据交互、LLM驱动分析可信度的影响，以及面向大规模多模态助手的未来拓展方向。"
    },
    {
        "title": "Toward an AI-Native Internet: Rethinking the Web Architecture for Semantic Retrieval",
        "summary": "The rise of Generative AI Search is fundamentally transforming how users and intelligent systems interact with the Internet. LLMs increasingly act as intermediaries between humans and web information. Yet the web remains optimized for human browsing rather than AI-driven semantic retrieval, resulting in wasted network bandwidth, lower information quality, and unnecessary complexity for developers. We introduce the concept of an AI-Native Internet, a web architecture in which servers expose semantically relevant information chunks rather than full documents, supported by a Web-native semantic resolver that allows AI applications to discover relevant information sources before retrieving fine-grained chunks. Through motivational experiments, we quantify the inefficiencies of current HTML-based retrieval, and outline architectural directions and open challenges for evolving today's document-centric web into an AI-oriented substrate that better supports semantic access to web content.",
        "entry_id": "http://arxiv.org/abs/2511.18354v1",
        "pub_date": "2025-11-23",
        "translated_summary": "生成式AI搜索的兴起正在从根本上改变用户及智能系统与互联网的交互方式。大语言模型日益成为人类与网络信息之间的中介桥梁。然而当前网络仍以人类浏览体验为核心进行优化，而非面向AI驱动的语义检索，这导致网络带宽浪费、信息质量下降，并为开发者带来不必要的复杂性。我们提出“AI原生互联网”概念——该架构要求服务器提供语义关联的信息块而非完整文档，并辅以网络原生语义解析器，使AI应用能在检索细粒度信息块前先行发现相关信源。通过动机实验，我们量化了当前基于HTML检索模式的效能损耗，并勾勒出将以文档为核心的现有网络演进为AI导向基础设施的架构路径，以及实现网络内容语义化访问所需的开放挑战。"
    },
    {
        "title": "Time Matters: Enhancing Sequential Recommendations with Time-Guided Graph Neural ODEs",
        "summary": "Sequential recommendation (SR) is widely deployed in e-commerce platforms, streaming services, etc., revealing significant potential to enhance user experience. However, existing methods often overlook two critical factors: irregular user interests between interactions and highly uneven item distributions over time. The former factor implies that actual user preferences are not always continuous, and long-term historical interactions may not be relevant to current purchasing behavior. Therefore, relying only on these historical interactions for recommendations may result in a lack of user interest at the target time. The latter factor, characterized by peaks and valleys in interaction frequency, may result from seasonal trends, special events, or promotions. These externally driven distributions may not align with individual user interests, leading to inaccurate recommendations. To address these deficiencies, we propose TGODE to both enhance and capture the long-term historical interactions. Specifically, we first construct a user time graph and item evolution graph, which utilize user personalized preferences and global item distribution information, respectively. To tackle the temporal sparsity caused by irregular user interactions, we design a time-guided diffusion generator to automatically obtain an augmented time-aware user graph. Additionally, we devise a user interest truncation factor to efficiently identify sparse time intervals and achieve balanced preference inference. After that, the augmented user graph and item graph are fed into a generalized graph neural ordinary differential equation (ODE) to align with the evolution of user preferences and item distributions. This allows two patterns of information evolution to be matched over time. Experimental results demonstrate that TGODE outperforms baseline methods across five datasets, with improvements ranging from 10% to 46%.",
        "entry_id": "http://arxiv.org/abs/2511.18347v1",
        "pub_date": "2025-11-23",
        "translated_summary": "序列推荐系统在电商平台和流媒体服务等领域应用广泛，在提升用户体验方面展现出巨大潜力。然而现有方法往往忽略两个关键因素：交互间不规则的兴趣波动，以及随时间高度不均衡的物品分布。前者意味着用户真实偏好并非持续存在，长期历史交互可能与当前购买行为无关，仅依赖这些历史记录进行推荐可能导致目标时刻缺乏用户兴趣指向；后者表现为交互频率的峰谷波动，可能源于季节趋势、特殊事件或促销活动，这种外部驱动的分布模式若与个体兴趣不匹配将导致推荐失准。为解决这些问题，我们提出TGODE模型，通过增强与捕捉长期历史交互实现精准推荐。具体而言，我们首先构建分别融合用户个性化偏好和全局物品分布信息的用户时间图与物品演化图；针对不规则交互导致的时间稀疏性，设计时间引导的扩散生成器自动获取增强型时间感知用户图；同时开发用户兴趣截断因子，有效识别稀疏时间区间并实现均衡偏好推断。随后将增强的用户图与物品图输入广义图神经常微分方程，使其与用户偏好和物品分布的演化过程对齐，实现双模式信息随时间的动态匹配。实验结果表明，TGODE在五个数据集上均优于基线方法，性能提升幅度达10%至46%。"
    },
    {
        "title": "UFO: Unfair-to-Fair Evolving Mitigates Unfairness in LLM-based Recommender Systems via Self-Play Fine-tuning",
        "summary": "Large language model-based Recommender Systems (LRSs) have demonstrated superior recommendation performance by integrating pre-training with Supervised Fine-Tuning (SFT). However, this approach introduces item-side unfairness. Existing studies primarily attribute this issue to the absence of fairness constraints during SFT and attempt to mitigate unfairness via re-weighting and re-ranking methods. In this paper, we find that unfairness arises not only from SFT but also from pre-training, where inherent biases are further amplified during SFT. This finding underscores the failure of current methods to address the root causes of unfairness. Moreover, current methods struggle to preserve satisfactory recommendation performance. To tackle these issues, we propose an Unfair-to-Fair evOlving (UFO) framework using a self-play mechanism, formulating unfairness mitigation as a two-player game. UFO alternates between two player roles: the \\textit{judger}, which identifies unfairness from both pre-training and SFT, and the \\textit{corrector}, which adjusts the LRS to address identified unfairness while preserving recommendation performance. Iterative optimization between these roles enables UFO to completely resolve unfairness. Extensive experiments demonstrate that UFO effectively mitigates unfairness while improving recommendation performance.",
        "entry_id": "http://arxiv.org/abs/2511.18342v1",
        "pub_date": "2025-11-23",
        "translated_summary": "基于大语言模型的推荐系统（LRSs）通过将预训练与监督微调（SFT）相结合，展现出卓越的推荐性能。然而这种方法会引发项目侧的不公平问题。现有研究主要将该问题归因于SFT阶段缺乏公平性约束，并尝试通过重加权和重排序方法缓解不公平性。本文发现，不公平性不仅源于SFT阶段，预训练阶段固有的偏见也会在SFT过程中被进一步放大。这一发现揭示了现有方法未能解决不公平性根本原因的局限性。此外，现有方法难以保持令人满意的推荐性能。为解决这些问题，我们提出基于自我博弈机制的“不公平-公平演化”（UFO）框架，将不公平缓解问题构建为双玩家博弈。UFO交替执行两种角色：\\textit{评判者}（从预训练和SFT中识别不公平现象）与\\textit{校正者}（在保持推荐性能的同时调整LRS以解决已识别的不公平问题）。通过角色间的迭代优化，UFO能彻底消除不公平性。大量实验表明，UFO在有效缓解不公平性的同时，还能提升推荐性能。"
    },
    {
        "title": "Path-Constrained Retrieval: A Structural Approach to Reliable LLM Agent Reasoning Through Graph-Scoped Semantic Search",
        "summary": "Large Language Model agents often retrieve context from knowledge bases that lack structural consistency with the agent's current reasoning state, leading to incoherent reasoning chains. We introduce Path-Constrained Retrieval (PCR), a retrieval method that combines structural graph constraints with semantic search to ensure retrieved information maintains logical relationships within a knowledge graph. PCR restricts the search space to nodes reachable from an anchor node, preventing retrieval of structurally disconnected information that may lead to inconsistent reasoning. We evaluate PCR on PathRAG-6, a benchmark spanning six domains with 180 nodes and 360 edges. Our results show that PCR achieves full structural consistency compared to 24-32 percent in baseline methods, while maintaining strong relevance scores. On the technology domain, PCR obtains full relevance at rank 10 with full structural consistency, significantly outperforming vector search and hybrid retrieval. PCR reduces the average graph distance of retrieved context by 78 percent compared to baselines, demonstrating retrieval of more structurally consistent information. These findings suggest that path-constrained retrieval is an effective approach for improving the reliability and coherence of LLM agent reasoning systems.",
        "entry_id": "http://arxiv.org/abs/2511.18313v1",
        "pub_date": "2025-11-23",
        "translated_summary": "大型语言模型智能体在从知识库中检索上下文时，常因知识库结构与当前推理状态缺乏一致性而导致推理链条断裂。我们提出路径约束检索方法，通过将图结构约束与语义搜索相结合，确保检索信息在知识图谱中保持逻辑关联。该方法将搜索范围限定在锚点节点可达的节点子集，从根源上避免因检索结构断裂信息而引发的推理不一致问题。我们在PathRAG-6基准上验证该方法，该基准覆盖六大领域、包含180个节点和360条边。实验表明：相较于基线方法24%-32%的结构一致性，PCR实现了完全结构一致性，同时保持优异的相关性评分；在技术领域，PCR在排序10位时实现100%相关性且保持完全结构一致性，显著优于向量搜索与混合检索；与基线相比，PCR使检索上下文的平均图距离降低78%，证明其能获取结构更一致的信息。这些发现表明，路径约束检索能有效提升LLM智能体推理系统的可靠性与连贯性。"
    },
    {
        "title": "Large Language Model Enhanced Graph Invariant Contrastive Learning for Out-of-Distribution Recommendation",
        "summary": "Out-of-distribution (OOD) generalization has emerged as a significant challenge in graph recommender systems. Traditional graph neural network algorithms often fail because they learn spurious environmental correlations instead of stable causal relationships, leading to substantial performance degradation under distribution shifts. While recent advancements in Large Language Models (LLMs) offer a promising avenue due to their vast world knowledge and reasoning capabilities, effectively integrating this knowledge with the fine-grained topology of specific graphs to solve the OOD problem remains a significant challenge. To address these issues, we propose {$\\textbf{Inv}$ariant $\\textbf{G}$raph $\\textbf{C}$ontrastive Learning with $\\textbf{LLM}$s for Out-of-Distribution Recommendation (InvGCLLM)}, an innovative causal learning framework that synergistically integrates the strengths of data-driven models and knowledge-driven LLMs. Our framework first employs a data-driven invariant learning model to generate causal confidence scores for each user-item interaction. These scores then guide an LLM to perform targeted graph refinement, leveraging its world knowledge to prune spurious connections and augment missing causal links. Finally, the structurally purified graphs provide robust supervision for a causality-guided contrastive learning objective, enabling the model to learn representations that are resilient to spurious correlations. Experiments conducted on four public datasets demonstrate that InvGCLLM achieves significant improvements in out-of-distribution recommendation, consistently outperforming state-of-the-art baselines.",
        "entry_id": "http://arxiv.org/abs/2511.18282v1",
        "pub_date": "2025-11-23",
        "translated_summary": "分布外泛化已成为图推荐系统面临的重大挑战。传统图神经网络算法因学习虚假的环境相关性而非稳定的因果关系，在分布变化下会出现显著性能衰退。尽管大语言模型凭借其丰富的世界知识和推理能力为此提供了新思路，但如何有效融合其知识体系与具体图谱的细粒度拓扑结构以解决分布外问题仍具挑战。为此，我们提出基于大语言模型的因果不变图对比学习框架InvGCLLM，该创新性因果学习框架实现了数据驱动模型与知识驱动大语言模型的协同融合。该框架首先通过数据驱动的因果不变学习模型生成用户-物品交互的因果置信度，进而引导大语言模型基于世界知识执行定向图结构优化——剪除虚假连接并补全缺失因果边。最终，经结构纯化的图谱为因果引导的对比学习目标提供鲁棒监督信号，使模型能够学习抵御虚假相关性的表征。在四个公开数据集上的实验表明，InvGCLLM在分布外推荐任务中实现显著提升，持续超越现有最优基线模型。"
    },
    {
        "title": "Democratic Recommendation with User and Item Representatives Produced by Graph Condensation",
        "summary": "The challenges associated with large-scale user-item interaction graphs have attracted increasing attention in graph-based recommendation systems, primarily due to computational inefficiencies and inadequate information propagation. Existing methods provide partial solutions but suffer from notable limitations: model-centric approaches, such as sampling and aggregation, often struggle with generalization, while data-centric techniques, including graph sparsification and coarsening, lead to information loss and ineffective handling of bipartite graph structures. Recent advances in graph condensation offer a promising direction by reducing graph size while preserving essential information, presenting a novel approach to mitigating these challenges. Inspired by the principles of democracy, we propose \\textbf{DemoRec}, a framework that leverages graph condensation to generate user and item representatives for recommendation tasks. By constructing a compact interaction graph and clustering nodes with shared characteristics from the original graph, DemoRec significantly reduces graph size and computational complexity. Furthermore, it mitigates the over-reliance on high-order information, a critical challenge in large-scale bipartite graphs. Extensive experiments conducted on four public datasets demonstrate the effectiveness of DemoRec, showcasing substantial improvements in recommendation performance, computational efficiency, and robustness compared to SOTA methods.",
        "entry_id": "http://arxiv.org/abs/2511.18279v1",
        "pub_date": "2025-11-23",
        "translated_summary": "大规模用户-物品交互图带来的挑战在基于图的推荐系统中日益受到关注，主要源于计算效率低下与信息传播不足。现有方法虽提供部分解决方案，但存在明显局限：以模型为中心的方法（如采样与聚合）常面临泛化能力不足，而以数据为中心的技术（如图稀疏化与粗化）则会导致信息丢失及对二分图结构处理失效。图压缩技术的最新进展通过缩减图规模同时保留关键信息，为应对这些挑战提供了新思路。受民主原则启发，我们提出\\textbf{DemoRec}框架，利用图压缩生成用户与物品代表节点以完成推荐任务。通过构建紧凑交互图并聚类原图中具有共同特征的节点，DemoRec显著降低图规模与计算复杂度，同时有效缓解大规模二分图中过度依赖高阶信息的关键问题。在四个公开数据集上的大量实验表明，DemoRec在推荐性能、计算效率和鲁棒性方面均优于现有最优方法，展现出显著优势。"
    },
    {
        "title": "LLM Reasoning for Cold-Start Item Recommendation",
        "summary": "Large Language Models (LLMs) have shown significant potential for improving recommendation systems through their inherent reasoning capabilities and extensive knowledge base. Yet, existing studies predominantly address warm-start scenarios with abundant user-item interaction data, leaving the more challenging cold-start scenarios, where sparse interactions hinder traditional collaborative filtering methods, underexplored. To address this limitation, we propose novel reasoning strategies designed for cold-start item recommendations within the Netflix domain. Our method utilizes the advanced reasoning capabilities of LLMs to effectively infer user preferences, particularly for newly introduced or rarely interacted items. We systematically evaluate supervised fine-tuning, reinforcement learning-based fine-tuning, and hybrid approaches that combine both methods to optimize recommendation performance. Extensive experiments on real-world data demonstrate significant improvements in both methodological efficacy and practical performance in cold-start recommendation contexts. Remarkably, our reasoning-based fine-tuned models outperform Netflix's production ranking model by up to 8% in certain cases.",
        "entry_id": "http://arxiv.org/abs/2511.18261v1",
        "pub_date": "2025-11-23",
        "translated_summary": "大型语言模型凭借其内在的推理能力与海量知识库，在改进推荐系统方面展现出巨大潜力。然而现有研究主要聚焦于用户-物品交互数据充足的暖启动场景，对于交互数据稀疏、传统协同过滤方法难以奏效的冷启动场景探索不足。为突破这一局限，我们针对Netflix领域的冷启动物品推荐提出创新推理策略。该方法利用大型语言模型的先进推理能力，有效推断用户偏好，尤其适用于新上架或交互极少的物品。我们系统评估了监督微调、基于强化学习的微调以及融合两种方法的混合方案，以优化推荐性能。基于真实数据的大规模实验表明，该方案在冷启动推荐场景中实现了方法论效能与实际性能的双重提升。值得注意的是，基于推理的微调模型在特定情况下比Netflix现行排序模型性能提升最高达8%。"
    },
    {
        "title": "HVD: Human Vision-Driven Video Representation Learning for Text-Video Retrieval",
        "summary": "The success of CLIP has driven substantial progress in text-video retrieval. However, current methods often suffer from \"blind\" feature interaction, where the model struggles to discern key visual information from background noise due to the sparsity of textual queries. To bridge this gap, we draw inspiration from human cognitive behavior and propose the Human Vision-Driven (HVD) model. Our framework establishes a coarse-to-fine alignment mechanism comprising two key components: the Frame Features Selection Module (FFSM) and the Patch Features Compression Module (PFCM). FFSM mimics the human macro-perception ability by selecting key frames to eliminate temporal redundancy. Subsequently, PFCM simulates micro-perception by aggregating patch features into salient visual entities through an advanced attention mechanism, enabling precise entity-level matching. Extensive experiments on five benchmarks demonstrate that HVD not only captures human-like visual focus but also achieves state-of-the-art performance.",
        "entry_id": "http://arxiv.org/abs/2601.16155v1",
        "pub_date": "2026-01-22",
        "translated_summary": "CLIP 的成功推动了文本—视频检索领域的显著进展。然而，现有方法常常陷入“盲目”特征交互：由于查询文本稀疏，模型难以从背景噪声中区分关键视觉信息。为弥合这一鸿沟，我们借鉴人类认知行为，提出 Human Vision-Driven（HVD）模型。该框架建立了一种由粗到精的对齐机制，包含两个核心组件：帧特征选择模块（FFSM）与片段特征压缩模块（PFCM）。FFSM 模拟人类的宏观感知，通过选取关键帧消除时间冗余；PFCM 则模仿微观感知，利用先进的注意力机制将片段特征聚合为显著视觉实体，实现精准的实体级匹配。在五个基准数据集上的大量实验表明，HVD 不仅能象人类一样聚焦关键视觉线索，还取得了当前最优性能。"
    },
    {
        "title": "Rethinking Composed Image Retrieval Evaluation: A Fine-Grained Benchmark from Image Editing",
        "summary": "Composed Image Retrieval (CIR) is a pivotal and complex task in multimodal understanding. Current CIR benchmarks typically feature limited query categories and fail to capture the diverse requirements of real-world scenarios. To bridge this evaluation gap, we leverage image editing to achieve precise control over modification types and content, enabling a pipeline for synthesizing queries across a broad spectrum of categories. Using this pipeline, we construct EDIR, a novel fine-grained CIR benchmark. EDIR encompasses 5,000 high-quality queries structured across five main categories and fifteen subcategories. Our comprehensive evaluation of 13 multimodal embedding models reveals a significant capability gap; even state-of-the-art models (e.g., RzenEmbed and GME) struggle to perform consistently across all subcategories, highlighting the rigorous nature of our benchmark. Through comparative analysis, we further uncover inherent limitations in existing benchmarks, such as modality biases and insufficient categorical coverage. Furthermore, an in-domain training experiment demonstrates the feasibility of our benchmark. This experiment clarifies the task challenges by distinguishing between categories that are solvable with targeted data and those that expose intrinsic limitations of current model architectures.",
        "entry_id": "http://arxiv.org/abs/2601.16125v1",
        "pub_date": "2026-01-22",
        "translated_summary": "组合式图像检索（CIR）是多模态理解中一项关键且复杂的任务。现有的 CIR 评测基准普遍存在查询类别单一、难以反映真实场景多样需求的问题。为弥补这一评估差距，本文利用图像编辑对修改类型和内容进行精准控制，设计了一条可在极广类别范围内合成查询流的流水线。借助该流水线，我们构建了细粒度的 CIR 评测基准——EDIR。  \nEDIR 包含 5,000 条高质量查询，按五大主类、十五个子类精细组织。我们对 13 种最先进的多模态嵌入模型进行了全面评测，发现显著的性能缺口：即使在如 RzenEmbed 和 GME 等顶级模型上，各子类间仍存在显著差异，凸显了本基准的严苛性。通过对比分析，我们还揭示了现有基准在模态偏差和类别覆盖不足等方面的内在缺陷。  \n进一步地，我们开展了领域内训练实验，验证了该基准的可操作性，并通过区分“可通过针对性数据解决的类别”与“揭示现有架构固有局限的类别”，明确了任务面临的根本挑战。"
    },
    {
        "title": "Unveiling and Simulating Short-Video Addiction Behaviors via Economic Addiction Theory",
        "summary": "Short-video applications have attracted substantial user traffic. However, these platforms also foster problematic usage patterns, commonly referred to as short-video addiction, which pose risks to both user health and the sustainable development of platforms. Prior studies on this issue have primarily relied on questionnaires or volunteer-based data collection, which are often limited by small sample sizes and population biases. In contrast, short-video platforms have large-scale behavioral data, offering a valuable foundation for analyzing addictive behaviors. To examine addiction-aware behavior patterns, we combine economic addiction theory with users' implicit behavior captured by recommendation systems. Our analysis shows that short-video addiction follows functional patterns similar to traditional forms of addictive behavior (e.g., substance abuse) and that its intensity is consistent with findings from previous social science studies. To develop a simulator that can learn and model these patterns, we introduce a novel training framework, AddictSim. To consider the personalized addiction patterns, AddictSim uses a mean-to-adapted strategy with group relative policy optimization training. Experiments on two large-scale datasets show that AddictSim consistently outperforms existing training strategies. Our simulation results show that integrating diversity-aware algorithms can mitigate addictive behaviors well.",
        "entry_id": "http://arxiv.org/abs/2601.15975v1",
        "pub_date": "2026-01-22",
        "translated_summary": "短视频应用吸引了庞大用户流量，但这些平台也催生了被称为“短视频成瘾”的问题性使用模式，既损害用户健康，也威胁平台的可持续发展。现有研究多依赖问卷调查或小规模自愿样本，存在样本量小、人群偏差等局限。相较之下，短视频平台积累了海量行为数据，为探讨成瘾行为提供了宝贵基石。我们将经济学成瘾理论与推荐系统所捕获的隐性用户行为相结合，揭示短视频成瘾在机制上与传统成瘾（如物质滥用）具有相似的功能模式，其强度也与既往社会科学研究的发现一致。为学习并建模这些模式，我们提出新型训练框架 AddictSim；该框架采用“均值–自适应”策略，结合“群体相对策略优化”训练，兼顾个性化成瘾差异。在两大规模数据集的实验表明，AddictSim 显著优于现有训练策略。模拟结果进一步显示，融入多样性感知算法可有效缓解成瘾行为。"
    },
    {
        "title": "MMGRid: Navigating Temporal-aware and Cross-domain Generative Recommendation via Model Merging",
        "summary": "Model merging (MM) offers an efficient mechanism for integrating multiple specialized models without access to original training data or costly retraining. While MM has demonstrated success in domains like computer vision, its role in recommender systems (RSs) remains largely unexplored. Recently, Generative Recommendation (GR) has emerged as a new paradigm in RSs, characterized by rapidly growing model scales and substantial computational costs, making MM particularly appealing for cost-sensitive deployment scenarios. In this work, we present the first systematic study of MM in GR through a contextual lens. We focus on a fundamental yet underexplored challenge in real-world: how to merge generative recommenders specialized to different real-world contexts, arising from temporal evolving user behaviors and heterogeneous application domains. To this end, we propose a unified framework MMGRid, a structured contextual grid of GR checkpoints that organizes models trained under diverse contexts induced by temporal evolution and domain diversity. All checkpoints are derived from a shared base LLM but fine-tuned on context-specific data, forming a realistic and controlled model space for systematically analyzing MM across GR paradigms and merging algorithms. Our investigation reveals several key insights. First, training GR models from LLMs can introduce parameter conflicts during merging due to token distribution shifts and objective disparities; such conflicts can be alleviated by disentangling task-aware and context-specific parameter changes via base model replacement. Second, incremental training across contexts induces recency bias, which can be effectively balanced through weighted contextual merging. Notably, we observe that optimal merging weights correlate with context-dependent interaction characteristics, offering practical guidance for weight selection in real-world deployments.",
        "entry_id": "http://arxiv.org/abs/2601.15930v1",
        "pub_date": "2026-01-22",
        "translated_summary": "模型融合（MM）为在不接触原始训练数据且无需昂贵重训的情况下整合多个专业化模型提供了一种高效机制。尽管MM已在计算机视觉等领域取得成功，但其在推荐系统（RS）中的作用仍甚少研究。最近，生成式推荐（GR）作为RS的新范式出现，其特点是模型规模迅速扩大、计算成本高昂，因而在成本敏感场景中MM尤为诱人。本文首次从情境化视角对GR中的MM进行系统研究。我们关注一个在实际应用中既根本又未被充分探讨的挑战：如何合并分别针对多种真实情境训练而成的生成式推荐模型，这些情境源于用户行为的时序演进和异构应用场景。\n\n为此，我们提出统一框架MMGRid——一种结构化的GR检查点情境网格。该网格按由时序演化与领域多样性共同诱导的多种情境组织模型，所有检查点均共享同一基础大语言模型（LLM），但在情境特化数据上微调，从而构建出一个既真实又可控制的模型空间，用于在不同GR范式与融合算法间系统分析MM。我们的研究揭示了若干关键洞察：第一，从LLM训练GR模型时，因词元分布迁移和目标函数差异会导致融合时的参数冲突；通过用基模型替换来解耦任务感知与情境特定的参数变化可有效缓解此冲突。第二，在跨情境的增量训练会引入“近期偏好”偏差，可通过加权情境融合有效平衡。值得注意的是，我们观察到最优融合权重与情境依赖的交互特征显著相关，为真实部署中的权重选择提供了可操作指导。"
    },
    {
        "title": "STAR: Semantic Table Representation with Header-Aware Clustering and Adaptive Weighted Fusion",
        "summary": "Table retrieval is the task of retrieving the most relevant tables from large-scale corpora given natural language queries. However, structural and semantic discrepancies between unstructured text and structured tables make embedding alignment particularly challenging. Recent methods such as QGpT attempt to enrich table semantics by generating synthetic queries, yet they still rely on coarse partial-table sampling and simple fusion strategies, which limit semantic diversity and hinder effective query-table alignment. We propose STAR (Semantic Table Representation), a lightweight framework that improves semantic table representation through semantic clustering and weighted fusion. STAR first applies header-aware K-means clustering to group semantically similar rows and selects representative centroid instances to construct a diverse partial table. It then generates cluster-specific synthetic queries to comprehensively cover the table's semantic space. Finally, STAR employs weighted fusion strategies to integrate table and query embeddings, enabling fine-grained semantic alignment. This design enables STAR to capture complementary information from structured and textual sources, improving the expressiveness of table representations. Experiments on five benchmarks show that STAR achieves consistently higher Recall than QGpT on all datasets, demonstrating the effectiveness of semantic clustering and adaptive weighted fusion for robust table representation. Our code is available at https://github.com/adsl135789/STAR.",
        "entry_id": "http://arxiv.org/abs/2601.15860v1",
        "pub_date": "2026-01-22",
        "translated_summary": "表格检索任务旨在从大规模语料中根据自然语言查询找到最相关的表格。然而，非结构化文本与结构化表格之间在结构和语义上的差异，使得嵌入对齐尤为困难。近期方法如 QGpT 尝试通过生成合成查询来丰富表格语义，但仍依赖粗略的局部表采样和简单的融合策略，限制了语义多样性，并阻碍了有效的查询-表格对齐。\n\n为此，我们提出轻量级框架 STAR（Semantic Table Representation），通过语义聚类与加权融合提升表格的语义表示。STAR 首先基于表头感知的 K-means 聚类，将语义相似的行分组；随后选取代表每个聚类中心的实例，组成丰富多样的局部表。接着，STAR 针对不同聚类生成专门的合成查询，以全面覆盖表格语义空间。最后，STAR 采用加权融合策略整合表格与查询嵌入，实现细粒度的语义对齐。该设计使 STAR 能够从结构化和文本来源中捕获互补信息，显著提升语义表示的表达能力。\n\n在五个基准数据集上的实验表明，STAR 在所有数据集的 Recall 指标上均显著优于 QGpT，验证了语义聚类与自适应加权融合在提升表格表示稳健性方面的有效性。代码开源地址：https://github.com/adsl135789/STAR"
    },
    {
        "title": "CGPT: Cluster-Guided Partial Tables with LLM-Generated Supervision for Table Retrieval",
        "summary": "General-purpose embedding models have demonstrated strong performance in text retrieval but remain suboptimal for table retrieval, where highly structured content leads to semantic compression and query-table mismatch. Recent LLM-based retrieval augmentation methods mitigate this issue by generating synthetic queries, yet they often rely on heuristic partial-table selection and seldom leverage these synthetic queries as supervision to improve the embedding model. We introduce CGPT, a training framework that enhances table retrieval through LLM-generated supervision. CGPT constructs semantically diverse partial tables by clustering table instances using K-means and sampling across clusters to broaden semantic coverage. An LLM then generates synthetic queries for these partial tables, which are used in hard-negative contrastive fine-tuning to refine the embedding model. Experiments across four public benchmarks (MimoTable, OTTQA, FetaQA, and E2E-WTQ) show that CGPT consistently outperforms retrieval baselines, including QGpT, with an average R@1 improvement of 16.54 percent. In a unified multi-domain corpus setting, CGPT further demonstrates strong cross-domain generalization and remains effective even when using smaller LLMs for synthetic query generation. These results indicate that semantically guided partial-table construction, combined with contrastive training from LLM-generated supervision, provides an effective and scalable paradigm for large-scale table retrieval. Our code is available at https://github.com/yumeow0122/CGPT.",
        "entry_id": "http://arxiv.org/abs/2601.15849v1",
        "pub_date": "2026-01-22",
        "translated_summary": "尽管通用型文本嵌入模型在文本检索中表现优异，但在表格检索场景下却难以达到最佳状态：高度结构化的表格内容导致语义压缩，并引发查询与表格之间的语义错配。近期通过大语言模型（LLM）进行检索增强的方法，采用合成查询来缓解这一问题，然而它们通常依赖启发式的局部表选择，极少把生成的合成查询用作监督信号来进一步优化嵌入模型。我们提出 CGPT——一种利用 LLM 监督信号来增强表格检索的训练框架。CGPT 首先对表格实例进行 K-means 聚类，跨簇采样以构建语义更加丰富的局部表；再由 LLM 为这些局部表生成合成查询，并以此进行硬负例对比微调，从而精炼嵌入模型。在 MimoTable、OTTQA、FetaQA 与 E2E-WTQ 四个公开基准上的实验表明，CGPT 全面且显著地超越了包括 QGpT 在内的检索基线，R@1 平均提升 16.54%。在统一的多领域语料场景下，CGPT 进一步展现了强劲的跨领域泛化能力，即使使用更小的 LLM 生成合成查询仍保持有效性。这些结果说明：将面向语义的局部表构建与对比微调相结合、并以 LLM 生成的监督信号为驱动，是大规模表格检索的一种高效且可扩展的新范式。代码开源： https://github.com/yumeow0122/CGPT"
    },
    {
        "title": "CoNRec: Context-Discerning Negative Recommendation with LLMs",
        "summary": "Understanding what users like is relatively straightforward; understanding what users dislike, however, remains a challenging and underexplored problem. Research into users' negative preferences has gained increasing importance in modern recommendation systems. Numerous platforms have introduced explicit negative feedback mechanisms and leverage such signals to refine their recommendation models. Beyond traditional business metrics, user experience-driven metrics, such as negative feedback rates, have become critical indicators for evaluating system performance. However, most existing approaches primarily use negative feedback as an auxiliary signal to enhance positive recommendations, paying little attention to directly modeling negative interests, which can be highly valuable in offline applications. Moreover, due to the inherent sparsity of negative feedback data, models often suffer from context understanding biases induced by positive feedback dominance. To address these challenges, we propose the first large language model framework for negative feedback modeling with special designed context-discerning modules. We use semantic ID Representation to replace text-based item descriptions and introduce an item-level alignment task that enhances the LLM's understanding of the semantic context behind negative feedback. Furthermore, we design a Progressive GRPO training paradigm that enables the model to dynamically balance the positive and negative behavioral context utilization. Besides, our investigation further reveals a fundamental misalignment between the conventional next-negative-item prediction objective and users' true negative preferences, which is heavily influenced by the system's recommendation order. To mitigate this, we propose a novel reward function and evaluation metric grounded in multi-day future negative feedback and their collaborative signals.",
        "entry_id": "http://arxiv.org/abs/2601.15721v1",
        "pub_date": "2026-01-22",
        "translated_summary": "理解用户喜欢什么是相对容易的；然而，理解用户讨厌什么仍是一项充满挑战且研究不足的课题。在当代推荐系统中，对用户负面偏好的研究正日益凸显其重要性。许多平台已引入显式负反馈机制，并借此信号来进一步优化推荐模型。除传统业务指标外，用户体验驱动的指标——尤其是负反馈率——已成为评估系统性能的关键标尺。然而，现有方法大多仅将负反馈作为辅助信号来提升正向推荐，很少有工作直接建模用户的负向兴趣，而这在线下场景中可能极具价值。此外，缘于负反馈数据固有的稀疏性，模型往往由于正向反馈的主导而陷入上下文理解偏差。\n\n为应对上述挑战，我们首次提出一个面向负反馈建模的大语言模型框架，并辅以专门设计的“上下文辨析”模块。框架用语义ID表示取代文本化的物品描述，并通过引入物品级对齐任务来增强大模型对负反馈背后语义语境的把握。进一步，我们设计了渐进式GRPO训练范式，使模型能够动态调谐正向与负向行为上下文的利用力度。此外，我们的研究还发现，传统的“下一负项预测”目标与用户的真实负面偏好存在根本错配问题，这种错配深受系统推荐顺序的影响。为此，我们提出一种新型奖励函数及评估指标，基于多日未来负反馈及其协同信号，以缓解这一错配。"
    },
    {
        "title": "Connect the Dots: Knowledge Graph-Guided Crawler Attack on Retrieval-Augmented Generation Systems",
        "summary": "Retrieval-augmented generation (RAG) systems integrate document retrieval with large language models and have been widely adopted. However, in privacy-related scenarios, RAG introduces a new privacy risk: adversaries can issue carefully crafted queries to exfiltrate sensitive content from the underlying corpus gradually. Although recent studies have demonstrated multi-turn extraction attacks, they rely on heuristics and fail to perform long-term extraction planning. To address these limitations, we formulate the RAG extraction attack as an adaptive stochastic coverage problem (ASCP). In ASCP, each query is treated as a probabilistic action that aims to maximize conditional marginal gain (CMG), enabling principled long-term planning under uncertainty. However, integrating ASCP with practical RAG attack faces three key challenges: unobservable CMG, intractability in the action space, and feasibility constraints. To overcome these challenges, we maintain a global attacker-side state to guide the attack. Building on this idea, we introduce RAGCRAWLER, which builds a knowledge graph to represent revealed information, uses this global state to estimate CMG, and plans queries in semantic space that target unretrieved regions. In comprehensive experiments across diverse RAG architectures and datasets, our proposed method, RAGCRAWLER, consistently outperforms all baselines. It achieves up to 84.4% corpus coverage within a fixed query budget and deliver an average improvement of 20.7% over the top-performing baseline. It also maintains high semantic fidelity and strong content reconstruction accuracy with low attack cost. Crucially, RAGCRAWLER proves its robustness by maintaining effectiveness against advanced RAG systems employing query rewriting and multi-query retrieval strategies. Our work reveals significant security gaps and highlights the pressing need for stronger safeguards for RAG.",
        "entry_id": "http://arxiv.org/abs/2601.15678v1",
        "pub_date": "2026-01-22",
        "translated_summary": "检索增强生成（RAG）系统通过将文档检索与大型语言模型相结合，已被广泛部署。但在涉及隐私的场景中，RAG引入了一种新的隐私风险：攻击者可构造精心设计的查询，逐步从底层语料库中窃取敏感内容。现有研究虽已提出多轮窃取攻击，却依赖启发式策略，缺乏长期提取规划。为此，我们将 RAG 窃取攻击形式化为自适应随机覆盖问题（ASCP）——每轮查询视为旨在最大化条件边际增益（CMG）的概率动作，在不确定性支持下进行有原则的远期规划。\n\n然而，实际 RAG 攻击与 ASCP 融合面临三大挑战：CMG 不可观测、动作空间难以处理以及可行性约束。为解决这些问题，我们在全局攻击者侧维护一个持久状态，以引导攻击。基于此，我们提出 RAGCRAWLER：构建知识图谱表明显露信息，利用该全局状态估计 CMG，并在语义空间规划指向尚未检索区域的查询。\n\n在覆盖多种 RAG 架构及数据集的全面实验中，RAGCRAWLER 始终优于全部基线方法：在限定查询预算内可实现最高 84.4% 的语料覆盖率，比表现最佳基线提升 20.7%；同时保持高语义保真度与强内容重建精度，攻击成本低廉。尤其值得注意的是，即使在采用查询重写与多查询检索策略的最新 RAG 系统面前，RAGCRAWLER 仍保持有效性，展现了其鲁棒性。我们的研究揭示了 RAG 的显著安全缺口，呼吁对 RAG 提供更强有力的防护。"
    },
    {
        "title": "Enhancing guidance for missing data in diffusion-based sequential recommendation",
        "summary": "Contemporary sequential recommendation methods are becoming more complex, shifting from classification to a diffusion-guided generative paradigm. However, the quality of guidance in the form of user information is often compromised by missing data in the observed sequences, leading to suboptimal generation quality. Existing methods address this by removing locally similar items, but overlook ``critical turning points'' in user interest, which are crucial for accurately predicting subsequent user intent. To address this, we propose a novel Counterfactual Attention Regulation Diffusion model (CARD), which focuses on amplifying the signal from key interest-turning-point items while concurrently identifying and suppressing noise within the user sequence. CARD consists of (1) a Dual-side Thompson Sampling method to identify sequences undergoing significant interest shift, and (2) a counterfactual attention mechanism for these sequences to quantify the importance of each item. In this manner, CARD provides the diffusion model with a high-quality guidance signal composed of dynamically re-weighted interaction vectors to enable effective generation. Experiments show our method works well on real-world data without being computationally expensive. Our code is available at https://github.com/yanqilong3321/CARD.",
        "entry_id": "http://arxiv.org/abs/2601.15673v1",
        "pub_date": "2026-01-22",
        "translated_summary": "当代序列推荐方法日益复杂，正由传统的分类范式转向以扩散模型为核心的生成范式。然而，指导信号的来源——用户历史序列信息——常常因缺失数据而导致质量下降，进而影响生成效果。现有研究通过剔除局部相似项来缓解这一问题，却忽视了用户兴趣中的“关键转折点”。这些转折点对准确预测用户后续意图至关重要，却未被利用。\n\n为解决此缺陷，我们提出了一种新型反事实注意力调控扩散模型（Counterfactual Attention Regulation Diffusion, CARD）。其核心思路是：放大序列中“关键兴趣转折点”所产生的信号，同时识别并抑制其他噪声。CARD 包含两大组件：\n\n1. 双边 Thompson 采样（Dual-side Thompson Sampling）：在训练过程中动态识别经历了显著兴趣漂移的序列；\n2. 反事实注意力机制：为这些序列中的每一件物品计算其重要性得分，从而完成动态重加权。\n\n借助经过重加权的交互向量，CARD 向扩散模型提供高可信度的指导信号，显著提高生成质量。实验表明，CARD 在真实数据集上表现优越，且计算成本可控。项目代码开源： https://github.com/yanqilong3321/CARD"
    },
    {
        "title": "Blockchain-Based Spectrum Resource Securitization via Semi-Fungible Token-Lock",
        "summary": "As 6G networks evolve, spectrum assets require flexible, dynamic, and efficient utilization, motivating blockchain based spectrum securitization. Existing approaches based on ERC404 style hybrid token models rely on frequent minting and burning during asset transfers, which disrupt token identity continuity and increase on chain overhead. This paper proposes the Semi Fungible Token Lock (SFT Lock) method, a lock/unlock based mechanism that preserves NFT identity and historical traceability while enabling fractional ownership and transferability. By replacing mint/burn operations with deterministic state transitions, SFT Lock ensures consistent lifecycle representation of spectrum assets and significantly reduces on chain operations. Based on this mechanism, a modular smart contract architecture is designed to support spectrum authorization, securitization, and sharing, and a staking mechanism is introduced to enhance asset liquidity. Experimental results on a private Ethereum network demonstrate that, compared with ERC404 style hybrid token models, the proposed method achieves substantial gas savings while maintaining functional correctness and traceability.",
        "entry_id": "http://arxiv.org/abs/2601.15594v1",
        "pub_date": "2026-01-22",
        "translated_summary": "随着 6G 网络的发展，频谱资源需要灵活、动态且高效的利用，这推动了基于区块链的频谱证券化需求。现有的 ERC404 式混合代币模型在资产转移时依赖频繁的铸造与销毁，既打断了代币身份的连续性，又增加了链上开销。本文提出“半同质代币锁定（SFT Lock）”方法，一种基于锁定/解锁的机制：在保留 NFT 身份和历史可追溯性的同时，实现了所有权分割和可转让性。该机制用确定性状态转换取代铸造/销毁操作，使频谱资产的全生命周期在链上保持一致表达，并显著减少链上操作。依托这一机制，论文进一步设计了模块化智能合约架构，支持频谱授权、证券化与共享，并引入质押机制以提升资产流动性。在私有以太坊网络上的实验结果表明，与 ERC404 式混合代币模型相比，SFT Lock 在保证功能正确性和可追溯性的前提下，可显著降低 Gas 开销。"
    },
    {
        "title": "PromptHelper: A Prompt Recommender System for Encouraging Creativity in AI Chatbot Interactions",
        "summary": "Prompting is central to interaction with AI systems, yet many users struggle to explore alternative directions, articulate creative intent, or understand how variations in prompts shape model outputs. We introduce prompt recommender systems (PRS) as an interaction approach that supports exploration, suggesting contextually relevant follow-up prompts. We present PromptHelper, a PRS prototype integrated into an AI chatbot that surfaces semantically diverse prompt suggestions while users work on real writing tasks. We evaluate PromptHelper in a 2x2 fully within-subjects study (N=32) across creative and academic writing tasks. Results show that PromptHelper significantly increases users' perceived exploration and expressiveness without increasing cognitive workload. Qualitative findings illustrate how prompt recommendations help users branch into new directions, overcome uncertainty about what to ask next, and better articulate their intent. We discuss implications for designing AI interfaces that scaffold exploratory interaction while preserving user agency, and release open-source resources to support research on prompt recommendation.",
        "entry_id": "http://arxiv.org/abs/2601.15575v1",
        "pub_date": "2026-01-22",
        "translated_summary": "虽然提示词是与 AI 系统交互的核心，但许多用户在实际写作过程中难以探索新的创作方向、表达创意意图，或理解提示词变化如何影响模型输出。我们提出“提示词推荐系统”（Prompt Recommender Systems，PRS），作为一种支持探索性的交互方式，能为用户提供情境相关的后续提示词建议。我们开发了 PromptHelper——嵌入聊天机器人的 PRS 原型；在用户的真实写作任务中，它会智能地呈现语义多样的提示词建议。\n\n通过一项 2×2 的完全被试内实验（N = 32），我们比较了 PromptHelper 在创意写作与学术写作两种任务中的表现。结果显示，PromptHelper 显著提升了用户对探索空间和表达能力的感知，同时并未增加认知负荷。质性研究进一步表明，提示词推荐能帮助用户分叉出全新的思路、克服“接下来问什么”的不确定感，并更清晰地把创意目标语言化。\n\n我们讨论了如何设计能够支持探索式交互、同时保留用户自主权的 AI 界面，并开源了相关资源，以促进提示词推荐研究。"
    },
    {
        "title": "DS@GT at TREC TOT 2025: Bridging Vague Recollection with Fusion Retrieval and Learned Reranking",
        "summary": "We develop a two-stage retrieval system that combines multiple complementary retrieval methods with a learned reranker and LLM-based reranking, to address the TREC Tip-of-the-Tongue (ToT) task. In the first stage, we employ hybrid retrieval that merges LLM-based retrieval, sparse (BM25), and dense (BGE-M3) retrieval methods. We also introduce topic-aware multi-index dense retrieval that partitions the Wikipedia corpus into 24 topical domains. In the second stage, we evaluate both a trained LambdaMART reranker and LLM-based reranking. To support model training, we generate 5000 synthetic ToT queries using LLMs. Our best system achieves recall of 0.66 and NDCG@1000 of 0.41 on the test set by combining hybrid retrieval with Gemini-2.5-flash reranking, demonstrating the effectiveness of fusion retrieval.",
        "entry_id": "http://arxiv.org/abs/2601.15518v1",
        "pub_date": "2026-01-21",
        "translated_summary": "我们提出了一种两阶段检索系统，融合多种互补检索方法与可学习的重排器及基于大语言模型（LLM）的再排序，以应对 TREC “话到嘴边”(ToT) 任务。第一阶段采用混合检索，将 LLM 检索、稀疏检索（BM25）与稠密检索（BGE-M3）相结合，并引入“主题感知”多索引稠密检索，把 Wikipedia 语料切分成 24 个主题域。第二阶段分别评测训练后的 LambdaMART 重排模型与 LLM 再排序。为了训练上述模型，我们使用 LLM 生成了 5000 条人工合成的 ToT 查询。最终，通过将混合检索与 Gemini-2.5-flash 再排序结合，系统在测试集上实现召回率 0.66、NDCG@1000 0.41，验证了融合检索的有效性。"
    },
    {
        "title": "Is Grokipedia Right-Leaning? Comparing Political Framing in Wikipedia and Grokipedia on Controversial Topics",
        "summary": "Online encyclopedias are central to contemporary information infrastructures and have become focal points of debates over ideological bias. Wikipedia, in particular, has long been accused of left-leaning bias, while Grokipedia, an AI-generated encyclopedia launched by xAI, has been framed as a right-leaning alternative. This paper presents a comparative analysis of Wikipedia and Grokipedia on well-established politically contested topics. Specifically, we examine differences in semantic framing, political orientation, and content prioritization. We find that semantic similarity between the two platforms decays across article sections and diverges more strongly on controversial topics than on randomly sampled ones. Additionally, we show that both encyclopedias predominantly exhibit left-leaning framings, although Grokipedia exhibits a more bimodal distribution with increased prominence of right-leaning content. The experimental code is publicly available.",
        "entry_id": "http://arxiv.org/abs/2601.15484v1",
        "pub_date": "2026-01-21",
        "translated_summary": "在线百科全书已成为当代信息基础设施的核心，并逐渐成为意识形态偏见争论的焦点。其中，维基百科长期以来被指责具有左倾偏向；而由 xAI 推出的 AI 生成百科全书 Grokipedia，则被定位为右倾替代方案。本文对两平台在若干已有定论、却具有政治争议的话题上进行了比较分析，重点关注语义框架、政治取向和内容侧重点的差异。研究发现，两平台文章各版块之间的语义相似度随段落深入而迅速下降，在争议话题上的分歧显著高于随机抽样主题。此外，尽管两部百科全书均主要呈现左倾框架，Grokipedia 的分布更趋双峰，右倾内容的占比明显提升。实验代码已公开。"
    },
    {
        "title": "Chunking, Retrieval, and Re-ranking: An Empirical Evaluation of RAG Architectures for Policy Document Question Answering",
        "summary": "The integration of Large Language Models (LLMs) into the public health policy sector offers a transformative approach to navigating the vast repositories of regulatory guidance maintained by agencies such as the Centers for Disease Control and Prevention (CDC). However, the propensity for LLMs to generate hallucinations, defined as plausible but factually incorrect assertions, presents a critical barrier to the adoption of these technologies in high-stakes environments where information integrity is non-negotiable. This empirical evaluation explores the effectiveness of Retrieval-Augmented Generation (RAG) architectures in mitigating these risks by grounding generative outputs in authoritative document context. Specifically, this study compares a baseline Vanilla LLM against Basic RAG and Advanced RAG pipelines utilizing cross-encoder re-ranking. The experimental framework employs a Mistral-7B-Instruct-v0.2 model and an all-MiniLM-L6-v2 embedding model to process a corpus of official CDC policy analytical frameworks and guidance documents. The analysis measures the impact of two distinct chunking strategies, recursive character-based and token-based semantic splitting, on system accuracy, measured through faithfulness and relevance scores across a curated set of complex policy scenarios. Quantitative findings indicate that while Basic RAG architectures provide a substantial improvement in faithfulness (0.621) over Vanilla baselines (0.347), the Advanced RAG configuration achieves a superior faithfulness average of 0.797. These results demonstrate that two-stage retrieval mechanisms are essential for achieving the precision required for domain-specific policy question answering, though structural constraints in document segmentation remain a significant bottleneck for multi-step reasoning tasks.",
        "entry_id": "http://arxiv.org/abs/2601.15457v1",
        "pub_date": "2026-01-21",
        "translated_summary": "将大型语言模型（LLMs）引入公共卫生政策领域，可为高效梳理疾控中心（CDC）等机构的庞大监管指导文件库提供变革性手段。然而，LLM 倾向于“幻觉”——即生成看似合理却事实错误的陈述——这在信息完整性不容妥协的高风险场景中，成为技术落地的一大障碍。本实证研究探索检索增强生成（RAG）架构能否通过将生成结果锚定于权威文档来缓解上述风险。具体而言，本文对比了三种设置：纯生成（Vanilla LLM）、基础 RAG，以及采用交叉编码器重排的高级 RAG。实验基于 Mistral-7B-Instruct-v0.2 及 all-MiniLM-L6-v2 嵌入模型，处理 CDC 官方政策分析框架与指导文件的语料，并在精心设计的复杂政策问题基准上评估系统准确性。研究还考察了两种分块策略——递归字符切分与基于 token 的语义切分——对结果的差异。\n\n定量结果显示：与 Vanilla LLM（忠实度 0.347）相比，基础 RAG 显著提升忠实度至 0.621；而高级 RAG 进一步达到 0.797，表明二级检索机制是满足政策问答所需精度的关键。然而，文档分割结构限制仍是多步推理任务的瓶颈。"
    },
    {
        "title": "MEDFORD in a Box: Improvements and Future Directions for a Metadata Description Language",
        "summary": "Scientific research metadata is vital to ensure the validity, reusability, and cost-effectiveness of research efforts. The MEDFORD metadata language was previously introduced to simplify the process of writing and maintaining metadata for non-programmers. However, barriers to entry and usability remain, including limited automatic validation, difficulty of data transport, and user unfamiliarity with text file editing. To address these issues, we introduce MEDFORD-in-a-Box (MIAB), a documentation ecosystem to facilitate researcher adoption and earlier metadata capture. MIAB contains many improvements, including an updated MEDFORD parser with expanded validation routines and BagIt export capability. MIAB also includes an improved VS Code extension that supports these changes through a visual IDE. By simplifying metadata generation, this new tool supports the creation of correct, consistent, and reusable metadata, ultimately improving research reproducibility.",
        "entry_id": "http://arxiv.org/abs/2601.15432v1",
        "pub_date": "2026-01-21",
        "translated_summary": "科学研究元数据对于确保研究的真实性、可重用性与成本效益至关重要。此前提出的 MEDFORD 元数据语言旨在让非程序员能够轻松地编写和维护元数据，但依然存在入门门槛高、可用性不足的问题，包括自动验证有限、数据迁移困难，以及用户不熟悉文本文件编辑。为了解决这些问题，本文推出 MEDFORD-in-a-Box（MIAB）。这是一个综合性文档工具生态，旨在促进研究者快速采纳并尽早记录元数据。MIAB 带来了多项改进：MEDFORD 解析器已更新，支持更完善的验证流程，并可导出 BagIt 格式；同时，配套的 VS Code 扩展也全面升级，以可视化 IDE 的形式支撑上述功能。借助更简洁的元数据生成方式，新工具能够帮助研究人员创建正确、一致且可重用的元数据，最终提升研究的可再现性。"
    },
    {
        "title": "Beyond the Geometric Curse: High-Dimensional N-Gram Hashing for Dense Retrieval",
        "summary": "Why do even the most powerful 7B-parameter embedding models struggle with simple retrieval tasks that the decades old BM25 handles with ease? Recent theory suggests that this happens because of a dimensionality bottleneck. This occurs when we force infinite linguistic nuances into small, fixed-length learned vectors. We developed NUMEN to break this bottleneck by removing the learning process entirely. Instead of training heavy layers to map text to a constrained space, NUMEN uses deterministic character hashing to project language directly onto high-dimensional vectors. This approach requires no training, supports an unlimited vocabulary, and allows the geometric capacity scale as needed. On the LIMIT benchmark, NUMEN achieves 93.90 % Recall@100 at 32,768 dimensions. This makes it the first dense retrieval model to officially surpass the sparse BM25 baseline 93.6 %. Our findings show that the real problem in dense retrieval isn't the architecture, but the embedding layer itself. The solution isn't necessarily smarter training, but simply providing more room to breathe.",
        "entry_id": "http://arxiv.org/abs/2601.15205v1",
        "pub_date": "2026-01-21",
        "translated_summary": "即便是最强的 7B 参数级嵌入模型，为何也会在 BM25 这类已问世数十年的稀疏方法面前败下阵来？最新理论指出，症结在于“维度瓶颈”：必须把无限的语言细节塞进一个又小又固定的可学习向量之中。为此，我们提出 NUMEN——一种彻底抛弃学习方式、以打破瓶颈的检索模型。NUMEN 不再用重参数网络把文本约束到低维空间，而是利用确定性字符级哈希，直接将语言映射到极高维向量；无须训练、词表无限、几何容量按需扩展。在 LIMIT 基准上，NUMEN 在 32,768 维便获得 93.90 % 的 Recall@100，首次让稠密模型正式超越 BM25 的 93.6 % 基线。实验表明，稠密检索的真正瓶颈不在网络结构，而在那一层嵌入本身；解决之道并非更聪明的训练，而只是“给它足够的空间呼吸”。"
    },
    {
        "title": "Supporting Humans in Evaluating AI Summaries of Legal Depositions",
        "summary": "While large language models (LLMs) are increasingly used to summarize long documents, this trend poses significant challenges in the legal domain, where the factual accuracy of deposition summaries is crucial. Nugget-based methods have been shown to be extremely helpful for the automated evaluation of summarization approaches. In this work, we translate these methods to the user side and explore how nuggets could directly assist end users. Although prior systems have demonstrated the promise of nugget-based evaluation, its potential to support end users remains underexplored. Focusing on the legal domain, we present a prototype that leverages a factual nugget-based approach to support legal professionals in two concrete scenarios: (1) determining which of two summaries is better, and (2) manually improving an automatically generated summary.",
        "entry_id": "http://arxiv.org/abs/2601.15182v1",
        "pub_date": "2026-01-21",
        "translated_summary": "尽管大型语言模型（LLM）越来越多地被用于长文档摘要，这一趋势在法律领域却带来严峻挑战——证人陈述摘要的事实准确性至关重要。基于信息“金块”（nugget）的方法已被证明对自动评估摘要质量极有助益。本研究将这一方法迁移到用户侧，探索如何让金块直接赋能终端用户。以往系统虽展示了金块式评估的潜力，但其支撑终端使用者的潜能仍缺乏深入研究。聚焦于法律场景，我们开发了一款原型工具：它以事实级金块为核心，在两种具体情境中为法律工作者提供助力：（1）在两篇摘要中判断哪篇更优；（2）就自动生成的摘要进行手动修正与提升。"
    },
    {
        "title": "From Insight to Intervention: Interpretable Neuron Steering for Controlling Popularity Bias in Recommender Systems",
        "summary": "Popularity bias is a pervasive challenge in recommender systems, where a few popular items dominate attention while the majority of less popular items remain underexposed. This imbalance can reduce recommendation quality and lead to unfair item exposure. Although existing mitigation methods address this issue to some extent, they often lack transparency in how they operate. In this paper, we propose a post-hoc approach, PopSteer, that leverages a Sparse Autoencoder (SAE) to both interpret and mitigate popularity bias in recommendation models. The SAE is trained to replicate a trained model's behavior while enabling neuron-level interpretability. By introducing synthetic users with strong preferences for either popular or unpopular items, we identify neurons encoding popularity signals through their activation patterns. We then steer recommendations by adjusting the activations of the most biased neurons. Experiments on three public datasets with a sequential recommendation model demonstrate that PopSteer significantly enhances fairness with minimal impact on accuracy, while providing interpretable insights and fine-grained control over the fairness-accuracy trade-off.",
        "entry_id": "http://arxiv.org/abs/2601.15122v1",
        "pub_date": "2026-01-21",
        "translated_summary": "流行度偏差是推荐系统中普遍存在的难题：少数热门商品占据绝大部分曝光机会，而多数长尾商品则长期被忽视。这种失衡不仅降低推荐质量，还可能造成商品曝光的不公平。现有缓解方法虽在一定程度上有所改善，但其内部机制缺乏透明度。本文提出一种事后矫正框架 PopSteer：借助稀疏自编码器（SAE）实现对推荐模型中流行度偏差的可解释分析与干预。SAE 被训练用于复现已训练模型的推荐行为，同时支持神经元层面的可视化与解读。通过构造对热门或非热门商品具有强烈偏好的合成用户，我们从激活模式中定位出编码流行度信号的神经元。随后，通过微调这些最偏置神经元的激活值，实现对推荐结果的导向式修正。在三个公开数据集及序列化推荐模型上的实验表明，PopSteer 在几乎不影响推荐准确率的前提下，显著提升公平性；同时提供可解释洞察，并以细粒度方式平衡公平性与准确性间的取舍。"
    },
    {
        "title": "Incentive-Tuning: Understanding and Designing Incentives for Empirical Human-AI Decision-Making Studies",
        "summary": "AI has revolutionised decision-making across various fields. Yet human judgement remains paramount for high-stakes decision-making. This has fueled explorations of collaborative decision-making between humans and AI systems, aiming to leverage the strengths of both. To explore this dynamic, researchers conduct empirical studies, investigating how humans use AI assistance for decision-making and how this collaboration impacts results. A critical aspect of conducting these studies is the role of participants, often recruited through crowdsourcing platforms. The validity of these studies hinges on the behaviours of the participants, hence effective incentives that can potentially affect these behaviours are a key part of designing and executing these studies. In this work, we aim to address the critical role of incentive design for conducting empirical human-AI decision-making studies, focusing on understanding, designing, and documenting incentive schemes. Through a thematic review of existing research, we explored the current practices, challenges, and opportunities associated with incentive design for human-AI decision-making empirical studies. We identified recurring patterns, or themes, such as what comprises the components of an incentive scheme, how incentive schemes are manipulated by researchers, and the impact they can have on research outcomes. Leveraging the acquired understanding, we curated a set of guidelines to aid researchers in designing effective incentive schemes for their studies, called the Incentive-Tuning Framework, outlining how researchers can undertake, reflect on, and document the incentive design process. By advocating for a standardised yet flexible approach to incentive design and contributing valuable insights along with practical tools, we hope to pave the way for more reliable and generalizable knowledge in the field of human-AI decision-making.",
        "entry_id": "http://arxiv.org/abs/2601.15064v1",
        "pub_date": "2026-01-21",
        "translated_summary": "人工智能已在众多领域彻底变革了决策方式，然而在高风险决策中，人类判断仍不可或缺。这一现状推动了人机协同决策的探索，旨在充分融合双方优势。为了深入理解这一协作机制，研究者开展实证研究，探究人类如何借助 AI 协助进行决策，以及这种协作对最终结果的影响。此类研究的关键在于参与者——他们通常通过众包平台招募。研究的效度依赖参与者的真实行为，因此，可能左右这些行为的激励机制便成为研究设计与实施的核心环节。\n\n本文聚焦于人机决策实证研究中激励机制设计的关键价值，围绕“理解—设计—记录”三大维度展开。通过对现有文献的主题式系统回顾，我们梳理了激励设计的当前做法、主要挑战与未来机遇，并对其中反复出现的规律或主题进行归纳：（1）激励方案的构成要素；（2）研究者如何操纵激励变量；（3）激励设置对研究结果的潜在影响。基于所得洞见，我们提出一套可供研究者在研究中设计高效激励的指南——“激励调适框架”（Incentive-Tuning Framework）。该框架明确了如何启动、反思与记录激励设计流程，倡导一种既标准化又具灵活性的激励设计方法。\n\n借助标准化而灵活的方法论，以及随框架附带的实用工具，我们期望为人机协同决策领域奠定更可靠、更可推广的知识基础。"
    },
    {
        "title": "What Should I Cite? A RAG Benchmark for Academic Citation Prediction",
        "summary": "With the rapid growth of Web-based academic publications, more and more papers are being published annually, making it increasingly difficult to find relevant prior work. Citation prediction aims to automatically suggest appropriate references, helping scholars navigate the expanding scientific literature. Here we present \\textbf{CiteRAG}, the first comprehensive retrieval-augmented generation (RAG)-integrated benchmark for evaluating large language models on academic citation prediction, featuring a multi-level retrieval strategy, specialized retrievers, and generators. Our benchmark makes four core contributions: (1) We establish two instances of the citation prediction task with different granularity. Task 1 focuses on coarse-grained list-specific citation prediction, while Task 2 targets fine-grained position-specific citation prediction. To enhance these two tasks, we build a dataset containing 7,267 instances for Task 1 and 8,541 instances for Task 2, enabling comprehensive evaluation of both retrieval and generation. (2) We construct a three-level large-scale corpus with 554k papers spanning many major subfields, using an incremental pipeline. (3) We propose a multi-level hybrid RAG approach for citation prediction, fine-tuning embedding models with contrastive learning to capture complex citation relationships, paired with specialized generation models. (4) We conduct extensive experiments across state-of-the-art language models, including closed-source APIs, open-source models, and our fine-tuned generators, demonstrating the effectiveness of our framework. Our open-source toolkit enables reproducible evaluation and focuses on academic literature, providing the first comprehensive evaluation framework for citation prediction and serving as a methodological template for other scientific domains. Our source code and data are released at https://github.com/LQgdwind/CiteRAG.",
        "entry_id": "http://arxiv.org/abs/2601.14949v1",
        "pub_date": "2026-01-21",
        "translated_summary": "随着网络学术出版物的迅猛增长，每年发布的论文数量不断上升，寻找相关前期工作变得愈发困难。引文预测旨在自动推荐合适参考文献，帮助学者在膨胀的科学文献中导航。在此，我们发布 **CiteRAG**，这是首个全面集成检索增强生成（RAG）的基准，用于评估大语言模型在学术引文预测中的表现。它采用了多层次检索策略、专用检索器与专用生成器。我们的基准在四个核心方面做出贡献：\n\n(1) 设定两个粒度不同的引文预测任务。任务1面向粗粒度的“列表级”引文预测，任务2聚焦细粒度的“位置级”引文预测。为了支撑这两项任务，我们构建了一个包含7,267个实例的数据集用于任务1，以及8,541个实例的数据集用于任务2，从而同时全面评估检索与生成性能。  \n(2) 采用增量式流水线，构建了一个涵盖海量主要子领域、包含55.4万篇论文的三级大规模语料库。  \n(3) 提出面向引文预测的多级混合RAG方法：通过对比学习微调嵌入模型，以捕捉复杂的引用关系，并配备专用生成模型。  \n(4) 在最新大语言模型上进行了大量实验，涵盖闭源API、开源模型和我们微调后的生成器，证明了框架的有效性。  \n\n我们的开源工具包确保了可复现的评估，专注于学术文献，为引文预测提供了首个全面评估框架，并可作为其他科学领域的方法学模板。源码与数据已发布：https://github.com/LQgdwind/CiteRAG。"
    },
    {
        "title": "Empowering Medical Equipment Sustainability in Low-Resource Settings: An AI-Powered Diagnostic and Support Platform for Biomedical Technicians",
        "summary": "In low- and middle-income countries (LMICs), a significant proportion of medical diagnostic equipment remains underutilized or non-functional due to a lack of timely maintenance, limited access to technical expertise, and minimal support from manufacturers, particularly for devices acquired through third-party vendors or donations. This challenge contributes to increased equipment downtime, delayed diagnoses, and compromised patient care. This research explores the development and validation of an AI-powered support platform designed to assist biomedical technicians in diagnosing and repairing medical devices in real-time. The system integrates a large language model (LLM) with a user-friendly web interface, enabling imaging technologists/radiographers and biomedical technicians to input error codes or device symptoms and receive accurate, step-by-step troubleshooting guidance. The platform also includes a global peer-to-peer discussion forum to support knowledge exchange and provide additional context for rare or undocumented issues. A proof of concept was developed using the Philips HDI 5000 ultrasound machine, achieving 100% precision in error code interpretation and 80% accuracy in suggesting corrective actions. This study demonstrates the feasibility and potential of AI-driven systems to support medical device maintenance, with the aim of reducing equipment downtime to improve healthcare delivery in resource-constrained environments.",
        "entry_id": "http://arxiv.org/abs/2601.16967v1",
        "pub_date": "2026-01-23",
        "translated_summary": "在低收入和中等收入国家（LMICs），由于缺乏及时维护、获取专业技术支持有限，以及制造商——尤其是通过第三方供应商或捐赠渠道获得的设备——几乎不提供支援，大量医疗诊断设备长期处于闲置或故障状态。这一问题加剧了设备停机时间、诊断延误和患者护理质量下降。本研究提出并验证了一种面向生物医学技术人员的AI实时支持平台，用以协助诊断与修复医疗设备。该平台将大型语言模型（LLM）与用户友好的 Web 界面相结合，使影像技师/放射师及生物医学技术人员可输入错误代码或设备异常症状，并获得准确的分步故障排除指南。平台还内置全球同行互助论坛，促进稀有或未记录问题的知识共享与背景补充。以飞利浦 HDI 5000 超声机为概念验证对象，系统对错误代码识别的精准度达 100%，纠正方案推荐的准确率达 80%。研究结果表明，在资源受限环境中，AI 驱动的医疗设备维护支持系统具有可行性和广阔前景，有望显著减少设备停机时间，进而提升医疗服务质量。"
    },
    {
        "title": "Explaining Group Recommendations via Counterfactuals",
        "summary": "Group recommender systems help users make collective choices but often lack transparency, leaving group members uncertain about why items are suggested. Existing explanation methods focus on individuals, offering limited support for groups where multiple preferences interact. In this paper, we propose a framework for group counterfactual explanations, which reveal how removing specific past interactions would change a group recommendation. We formalize this concept, introduce utility and fairness measures tailored to groups, and design heuristic algorithms, such as Pareto-based filtering and grow-and-prune strategies, for efficient explanation discovery. Experiments on MovieLens and Amazon datasets show clear trade-offs: low-cost methods produce larger, less fair explanations, while other approaches yield concise and balanced results at higher cost. Furthermore, the Pareto-filtering heuristic demonstrates significant efficiency improvements in sparse settings.",
        "entry_id": "http://arxiv.org/abs/2601.16882v1",
        "pub_date": "2026-01-23",
        "translated_summary": "群体推荐系统帮助用户作出集体决策，但往往缺乏透明度，使得成员难以知晓为何某项内容被推荐。现有的解释方法主要针对个人，在面对多重偏好交织的群体场景时显得力不从心。本文提出了一套面向群体的反事实解释框架：通过展示若移除某些具体历史交互会使群体推荐结果发生怎样的变化来解释推荐原因。我们首先对该概念进行形式化定义，随后引入专为群体设计的效用与公平性度量，并基于此设计了启发式算法，包括基于帕累托的前置过滤与“增长-修剪”策略，以实现高效的解释发现。在 MovieLens 和 Amazon 数据集上的实验揭示了清晰的权衡：低成本方法生成的解释规模更大且更不公平；而其他方法虽然成本较高，却能产出简洁且均衡的解释。此外，帕累托过滤启发算法在稀疏场景下显著提升了效率。"
    },
    {
        "title": "From Atom to Community: Structured and Evolving Agent Memory for User Behavior Modeling",
        "summary": "User behavior modeling lies at the heart of personalized applications like recommender systems. With LLM-based agents, user preference representation has evolved from latent embeddings to semantic memory. While existing memory mechanisms show promise in textual dialogues, modeling non-textual behaviors remains challenging, as preferences must be inferred from implicit signals like clicks without ground truth supervision. Current approaches rely on a single unstructured summary, updated through simple overwriting. However, this is suboptimal: users exhibit multi-faceted interests that get conflated, preferences evolve yet naive overwriting causes forgetting, and sparse individual interactions necessitate collaborative signals. We present STEAM (\\textit{\\textbf{ST}ructured and \\textbf{E}volving \\textbf{A}gent \\textbf{M}emory}), a novel framework that reimagines how agent memory is organized and updated. STEAM decomposes preferences into atomic memory units, each capturing a distinct interest dimension with explicit links to observed behaviors. To exploit collaborative patterns, STEAM organizes similar memories across users into communities and generates prototype memories for signal propagation. The framework further incorporates adaptive evolution mechanisms, including consolidation for refining memories and formation for capturing emerging interests. Experiments on three real-world datasets demonstrate that STEAM substantially outperforms state-of-the-art baselines in recommendation accuracy, simulation fidelity, and diversity.",
        "entry_id": "http://arxiv.org/abs/2601.16872v1",
        "pub_date": "2026-01-23",
        "translated_summary": "用户行为建模是个性化应用（如推荐系统）的核心所在。借助基于大语言模型的智能体，用户对偏好的表示已从潜在嵌入演进为语义化记忆。现有记忆机制在文本对话中颇具成效，但在建模非文本行为时仍面临挑战：此时必须从点击这类隐式信号中推断偏好，而缺乏真实标签作为监督。现有方法多依赖单一非结构化摘要，并以简单覆盖的方式进行更新。然而，这种做法并不理想：用户的兴趣是多方面的，易在单一摘要中混淆；偏好会持续变化，而粗暴覆盖会导致遗忘；个体交互稀疏，需要借助协同信号。我们提出了STEAM（结构化且演化的智能体记忆）框架，从组织与更新两个维度重塑智能体记忆。STEAM将偏好拆分为原子式记忆单元，每个单元聚焦单一兴趣维度，并通过显式链接对应到可观察行为。借助协同模式，STEAM将用户间的相似记忆聚为社区，生成原型记忆以实现信号传播。此外，框架还引入自适应演化机制，通过巩固（refining memories）精炼既有记忆，通过生成（capturing emerging interests）捕捉新兴兴趣。在三个真实数据集的实验表明，STEAM在推荐精度、仿真逼真度和多样性方面均显著优于最新基线。"
    },
    {
        "title": "Navigating the Shift: A Comparative Analysis of Web Search and Generative AI Response Generation",
        "summary": "The rise of generative AI as a primary information source presents a paradigm shift from traditional web search. This paper presents a large-scale empirical study quantifying the fundamental differences between the results returned by Google Search and leading generative AI services. We analyze multiple dimensions, demonstrating that AI-generated answers and web search results diverge significantly in their consulted source domains, the typology of these domains (e.g., earned media vs. owned, social), query intent and the freshness of the information provided. We then investigate the role of LLM pre-training as a key factor shaping these differences, analyzing how this intrinsic knowledge base interacts with and influences real-time web search when enabled. Our findings reveal the distinct mechanics of these two information ecosystems, leading to critical observations on the emergent field of Answer Engine Optimization (AEO) and its contrast with traditional Search Engine Optimization (SEO).",
        "entry_id": "http://arxiv.org/abs/2601.16858v1",
        "pub_date": "2026-01-23",
        "translated_summary": "生成式人工智能作为首要信息来源的崛起，标志着信息获取方式从传统网页搜索的范式转变。本文通过大规模实证研究，量化分析了谷歌搜索与主流生成式人工智能服务返回结果的本质差异。我们从多个维度展开分析，发现人工智能生成答案与网页搜索结果在以下方面存在显著差异：引用的源网站域名、域名类型（例如付费媒体、社交媒体、自有媒体）、查询意图以及所提供信息的时效性。在此基础上，我们探讨了大语言模型预训练作为形成这些差异的关键因素，分析了这种内在知识库在与实时网页检索协同工作时如何产生互动与影响。我们的发现揭示了两个截然不同信息生态系统的运作机制，从而对新兴的回答引擎优化（AEO）领域提出重要观察，并指出其与传统搜索引擎优化（SEO）的本质区别。"
    },
    {
        "title": "PI2I: A Personalized Item-Based Collaborative Filtering Retrieval Framework",
        "summary": "Efficiently selecting relevant content from vast candidate pools is a critical challenge in modern recommender systems. Traditional methods, such as item-to-item collaborative filtering (CF) and two-tower models, often fall short in capturing the complex user-item interactions due to uniform truncation strategies and overdue user-item crossing. To address these limitations, we propose Personalized Item-to-Item (PI2I), a novel two-stage retrieval framework that enhances the personalization capabilities of CF. In the first Indexer Building Stage (IBS), we optimize the retrieval pool by relaxing truncation thresholds to maximize Hit Rate, thereby temporarily retaining more items users might be interested in. In the second Personalized Retrieval Stage (PRS), we introduce an interactive scoring model to overcome the limitations of inner product calculations, allowing for richer modeling of intricate user-item interactions. Additionally, we construct negative samples based on the trigger-target (item-to-item) relationship, ensuring consistency between offline training and online inference. Offline experiments on large-scale real-world datasets demonstrate that PI2I outperforms traditional CF methods and rivals Two-Tower models. Deployed in the \"Guess You Like\" section on Taobao, PI2I achieved a 1.05% increase in online transaction rates. In addition, we have released a large-scale recommendation dataset collected from Taobao, containing 130 million real-world user interactions used in the experiments of this paper. The dataset is publicly available at https://huggingface.co/datasets/PI2I/PI2I, which could serve as a valuable benchmark for the research community.",
        "entry_id": "http://arxiv.org/abs/2601.16815v1",
        "pub_date": "2026-01-23",
        "translated_summary": "从海量候选项中高效地遴选相关内容，是现代推荐系统面临的关键挑战。传统的 item-to-item 协同过滤（CF）与双塔模型，由于采用统一的截断策略及滞后的 user–item 交互建模，往往难以刻画复杂的用户-物品关系。为此，我们提出 Personalized Item-to-Item（PI2I），一种两阶段检索框架，显著提升了 CF 在个性化方面的能力。在第一阶段「索引构建阶段」（IBS）中，我们通过放宽截断阈值来优化检索池，以最大化命中率（Hit Rate），进而暂时保留更多潜在兴趣物品。第二阶段「个性化检索阶段」（PRS）引入交互式打分模型，克服了内积计算的限制，能够更丰富地建模精细的用户-物品交互。此外，我们以触发-目标（item-to-item）关系构建负样本，使离线训练与在线推断保持一致。大规模真实数据集的离线实验表明，PI2I 的表现优于传统 CF 方法，并与双塔模型势均力敌。在淘宝「猜你喜欢」场景上线后，PI2I 为在线交易转化率带来了 1.05% 的提升。我们还公开发布了源自淘宝的大规模推荐数据集，包含 1.3 亿条真实用户交互，用于本研究的实验验证，数据下载地址：https://huggingface.co/datasets/PI2I/PI2I，可为学界提供宝贵基准。"
    },
    {
        "title": "LLM-powered Real-time Patent Citation Recommendation for Financial Technologies",
        "summary": "Rapid financial innovation has been accompanied by a sharp increase in patenting activity, making timely and comprehensive prior-art discovery more difficult. This problem is especially evident in financial technologies, where innovations develop quickly, patent collections grow continuously, and citation recommendation systems must be updated as new applications arrive. Existing patent retrieval and citation recommendation methods typically rely on static indexes or periodic retraining, which limits their ability to operate effectively in such dynamic settings. In this study, we propose a real-time patent citation recommendation framework designed for large and fast-changing financial patent corpora. Using a dataset of 428,843 financial patents granted by the China National Intellectual Property Administration (CNIPA) between 2000 and 2024, we build a three-stage recommendation pipeline. The pipeline uses large language model (LLM) embeddings to represent the semantic content of patent abstracts, applies efficient approximate nearest-neighbor search to construct a manageable candidate set, and ranks candidates by semantic similarity to produce top-k citation recommendations. In addition to improving recommendation accuracy, the proposed framework directly addresses the dynamic nature of patent systems. By using an incremental indexing strategy based on hierarchical navigable small-world (HNSW) graphs, newly issued patents can be added without rebuilding the entire index. A rolling day-by-day update experiment shows that incremental updating improves recall while substantially reducing computational cost compared with rebuild-based indexing. The proposed method also consistently outperforms traditional text-based baselines and alternative nearest-neighbor retrieval approaches.",
        "entry_id": "http://arxiv.org/abs/2601.16775v1",
        "pub_date": "2026-01-23",
        "translated_summary": "金融创新的加速伴随着专利申请的激增，使得及时而全面的在先技术检索愈发困难。这一问题在金融科技领域尤为突出：技术迭代迅速，专利库持续膨胀，且每当出现新申请时，已有引用推荐系统就必须随之更新。现有专利检索与引用推荐方法多依赖静态索引或周期性重训，难以胜任如此动态的场景。针对这一挑战，本文提出一套面向大规模、高速变化金融专利库的实时引用推荐框架。基于中国国家知识产权局（CNIPA）2000–2024 年间授权的全部 428,843 件金融专利，我们构建了三阶段推荐流水线：首先利用大语言模型（LLM）嵌入专利摘要的语义表示；随后通过高效的近似最近邻搜索生成可控候选集；最后按语义相似度排序，输出 top-k 引用结果。除提升推荐精度外，该框架直接解决了专利系统的动态性。借助基于分层可导航小世界（HNSW）图的增量索引策略，新授权专利可直接插入，无需重建整个索引。逐日滚动更新实验表明，增量索引不仅提升了召回率，还显著减少了计算开销。与传统文本检索基线和其他近邻检索方法相比，本文方法始终保持优势。"
    },
    {
        "title": "Better Generalizing to Unseen Concepts: An Evaluation Framework and An LLM-Based Auto-Labeled Pipeline for Biomedical Concept Recognition",
        "summary": "Generalization to unseen concepts is a central challenge due to the scarcity of human annotations in Mention-agnostic Biomedical Concept Recognition (MA-BCR). This work makes two key contributions to systematically address this issue. First, we propose an evaluation framework built on hierarchical concept indices and novel metrics to measure generalization. Second, we explore LLM-based Auto-Labeled Data (ALD) as a scalable resource, creating a task-specific pipeline for its generation. Our research unequivocally shows that while LLM-generated ALD cannot fully substitute for manual annotations, it is a valuable resource for improving generalization, successfully providing models with the broader coverage and structural knowledge needed to approach recognizing unseen concepts. Code and datasets are available at https://github.com/bio-ie-tool/hi-ald.",
        "entry_id": "http://arxiv.org/abs/2601.16711v1",
        "pub_date": "2026-01-23",
        "translated_summary": "鉴于人工标注在提及无关型生物医学概念识别（MA-BCR）中的稀缺，如何泛化到未见概念成为核心挑战。本研究通过两大贡献系统性地应对这一问题。首先，我们提出一套评估框架，包括层级概念索引与全新指标，以量化模型泛化能力。其次，我们探索利用大语言模型自动生成标注数据（ALD），并构建面向任务的生成管线，实现可扩展的知识资源补充。实验充分表明，尽管LLM生成的ALD无法完全替代人工注释，但其显著提升模型泛化性能，可提供更广泛的覆盖及结构化知识，使模型更趋近识别未见概念。代码与数据集开源地址：https://github.com/bio-ie-tool/hi-ald。"
    },
    {
        "title": "PRISM: Purified Representation and Integrated Semantic Modeling for Generative Sequential Recommendation",
        "summary": "Generative Sequential Recommendation (GSR) has emerged as a promising paradigm, reframing recommendation as an autoregressive sequence generation task over discrete Semantic IDs (SIDs), typically derived via codebook-based quantization. Despite its great potential in unifying retrieval and ranking, existing GSR frameworks still face two critical limitations: (1) impure and unstable semantic tokenization, where quantization methods struggle with interaction noise and codebook collapse, resulting in SIDs with ambiguous discrimination; and (2) lossy and weakly structured generation, where reliance solely on coarse-grained discrete tokens inevitably introduces information loss and neglects items' hierarchical logic. To address these issues, we propose a novel generative recommendation framework, PRISM, with Purified Representation and Integrated Semantic Modeling. Specifically, to ensure high-quality tokenization, we design a Purified Semantic Quantizer that constructs a robust codebook via adaptive collaborative denoising and hierarchical semantic anchoring mechanisms. To compensate for information loss during quantization, we further propose an Integrated Semantic Recommender, which incorporates a dynamic semantic integration mechanism to integrate fine-grained semantics and enforces logical validity through a semantic structure alignment objective. PRISM consistently outperforms state-of-the-art baselines across four real-world datasets, demonstrating substantial performance gains, particularly in high-sparsity scenarios.",
        "entry_id": "http://arxiv.org/abs/2601.16556v1",
        "pub_date": "2026-01-23",
        "translated_summary": "生成式序列推荐（GSR）作为一种新兴范式，将推荐任务重塑为基于离散语义 ID（SID）的自回归序列生成，这些 SID 一般通过基于码本的量化获得。尽管这一范式在统一检索与排序方面显示出巨大潜力，现有 GSR 框架仍面临两大关键局限：（1）失真且不稳定的高维语义标记化——量化方法难以应对交互噪声与码本崩溃，导致 SID 判别性模糊；（2）信息缺失且结构薄弱的生成过程——仅依赖粗粒度离散标记会不可避免地损失信息，并忽视物品的层次结构逻辑。\n\n针对上述问题，本文提出 PRISM 框架，通过“提纯表征”和“整合语义建模”实现更高质量的生成式推荐。首先，为保证高保真标记化，我们设计了“提纯语义量化器”，利用自适应协同去噪与层次语义锚定机制构建鲁棒码本。其次，为弥补量化阶段的信息损失，我们进一步提出“整合语义推荐器”，引入动态语义整合机制融合细粒度语义，并通过语义结构对齐目标确保逻辑一致性。在四个真实数据集上的广泛实验表明，PRISM 不仅在整体性能上全面超越现有最强基线，尤其在极端稀疏场景下展现了显著增益。"
    },
    {
        "title": "LLM-based Semantic Search for Conversational Queries in E-commerce",
        "summary": "Conversational user queries are increasingly challenging traditional e-commerce platforms, whose search systems are typically optimized for keyword-based queries. We present an LLM-based semantic search framework that effectively captures user intent from conversational queries by combining domain-specific embeddings with structured filters. To address the challenge of limited labeled data, we generate synthetic data using LLMs to guide the fine-tuning of two models: an embedding model that positions semantically similar products close together in the representation space, and a generative model for converting natural language queries into structured constraints. By combining similarity-based retrieval with constraint-based filtering, our framework achieves strong precision and recall across various settings compared to baseline approaches on a real-world dataset.",
        "entry_id": "http://arxiv.org/abs/2601.16492v1",
        "pub_date": "2026-01-23",
        "translated_summary": "传统电子商务平台的搜索系统通常为关键词优化，面对日益复杂的对话式用户查询已力不从心。本文提出一种基于大型语言模型的语义搜索框架，利用领域特定的嵌入表示与结构化过滤器相结合，从对话中精准捕捉用户真实意图。为缓解标注数据不足的挑战，我们借助大型语言模型生成合成数据，并据此微调两个模型：其一为嵌入模型，将语义相似的商品在表示空间中拉近距离；其二为生成模型，负责将自然语言查询转换为结构化约束条件。通过把基于相似度的召回与基于约束条件的重排序相结合，该框架在真实数据集上的多个设定中均显著优于基线方法，取得更高的准确率和召回率。"
    },
    {
        "title": "Segregation Before Polarization: How Recommendation Strategies Shape Echo Chamber Pathways",
        "summary": "Social media platforms facilitate echo chambers through feedback loops between user preferences and recommendation algorithms. While algorithmic homogeneity is well-documented, the distinct evolutionary pathways driven by content-based versus link-based recommendations remain unclear. Using an extended dynamic Bounded Confidence Model (BCM), we show that content-based algorithms--unlike their link-based counterparts--steer social networks toward a segregation-before-polarization (SbP) pathway. Along this trajectory, structural segregation precedes opinion divergence, accelerating individual isolation while delaying but ultimately intensifying collective polarization. Furthermore, we reveal a paradox in information sharing: Reposting increases the number of connections in the network, yet it simultaneously reinforces echo chambers because it amplifies small, latent opinion differences that would otherwise remain inconsequential. These findings suggest that mitigating polarization requires stage-dependent algorithmic interventions, shifting from content-centric to structure-centric strategies as networks evolve.",
        "entry_id": "http://arxiv.org/abs/2601.16457v1",
        "pub_date": "2026-01-23",
        "translated_summary": "社交媒体平台通过用户偏好与推荐算法之间的反馈回路形成了信息回音室。虽然算法同质化现象已被充分记录，但由基于内容的推荐与基于链接的推荐所驱动的差异化演化路径仍不清晰。本研究借助扩展的动态 Bounded Confidence 模型（BCM）发现：与基于链接的推荐相比，基于内容的算法会将社交网络推向“先隔离后极化”（segregation-before-polarization, SbP）的路径。在此路径上，结构隔离先于观点分歧出现，它不仅加速了个体的孤立，而且虽将集体极化的发生延后，却最终使其更加剧烈。此外，我们还发现信息分享中的一个悖论：转发行为虽然增加了网络中的连接数量，却通过放大原本微不足道且潜在的微小意见差异而强化了回音室效应。上述结果表明，要缓解极化，需要在网络演化的不同阶段采用差异化算法干预：随着网络不断演化，干预策略应由以内容为中心转向以结构为中心。"
    },
    {
        "title": "Self-Manager: Parallel Agent Loop for Long-form Deep Research",
        "summary": "Long-form deep research requires multi-faceted investigations over extended horizons to get a comprehensive report. When handling such complex tasks, existing agents manage context at the subtask level to overcome linear context accumulation and information loss. However, they still adhere to a single context window and sequential execution paradigm, which results in mutual interference and blocking behavior, restricting scalability and adaptability. To address this issue, this paper introduces Self-Manager, a parallel agent loop that enables asynchronous and concurrent execution. The main thread can create multiple subthreads, each with its own isolated context, and manage them iteratively through Thread Control Blocks, allowing for more focused and flexible parallel agent execution. To assess its effectiveness, we benchmark Self-Manager on DeepResearch Bench, where it consistently outperforms existing single-agent loop baselines across all metrics. Furthermore, we conduct extensive analytical experiments to demonstrate the necessity of Self-Manager's design choices, as well as its advantages in contextual capacity, efficiency, and generalization.",
        "entry_id": "http://arxiv.org/abs/2601.17879v1",
        "pub_date": "2026-01-25",
        "translated_summary": "长篇深度研究要求在广阔的时间范围内开展多维度调查，以形成综合报告。在处理这类复杂任务时，现有智能体通过在子任务层级进行上下文管理来缓解线性上下文累积和信息丢失问题。然而，它们仍固守在单一线性上下文窗口与顺序执行范式之内，导致任务间相互干扰和阻塞行为，严重限制了规模化能力与适应性。\n\n针对这一瓶颈，本文提出 Self-Manager，一种可并行执行的智能体循环机制，支持异步与并发运算。主线程能够创建带有独立上下文的多个子线程，并可通过「线程控制块」（Thread Control Blocks）进行迭代式管理，从而实现更加聚焦、灵活的并行代理执行。\n\n为验证其有效性，我们在 DeepResearch Benchmark 上对 Self-Manager 进行基准测试。结果表明，Self-Manager 在所有评测维度均一致超越现有的单智能体循环基线。此外，我们通过大量分析实验，系统验证了 Self-Manager 设计选择的必要性，并展示了其在上下文容量、计算效率及泛化能力方面的显著优势。"
    },
    {
        "title": "Unleashing the Potential of Sparse Attention on Long-term Behaviors for CTR Prediction",
        "summary": "In recent years, the success of large language models (LLMs) has driven the exploration of scaling laws in recommender systems. However, models that demonstrate scaling laws are actually challenging to deploy in industrial settings for modeling long sequences of user behaviors, due to the high computational complexity of the standard self-attention mechanism. Despite various sparse self-attention mechanisms proposed in other fields, they are not fully suited for recommendation scenarios. This is because user behaviors exhibit personalization and temporal characteristics: different users have distinct behavior patterns, and these patterns change over time, with data from these users differing significantly from data in other fields in terms of distribution. To address these challenges, we propose SparseCTR, an efficient and effective model specifically designed for long-term behaviors of users. To be precise, we first segment behavior sequences into chunks in a personalized manner to avoid separating continuous behaviors and enable parallel processing of sequences. Based on these chunks, we propose a three-branch sparse self-attention mechanism to jointly identify users' global interests, interest transitions, and short-term interests. Furthermore, we design a composite relative temporal encoding via learnable, head-specific bias coefficients, better capturing sequential and periodic relationships among user behaviors. Extensive experimental results show that SparseCTR not only improves efficiency but also outperforms state-of-the-art methods. More importantly, it exhibits an obvious scaling law phenomenon, maintaining performance improvements across three orders of magnitude in FLOPs. In online A/B testing, SparseCTR increased CTR by 1.72\\% and CPM by 1.41\\%. Our source code is available at https://github.com/laiweijiang/SparseCTR.",
        "entry_id": "http://arxiv.org/abs/2601.17836v1",
        "pub_date": "2026-01-25",
        "translated_summary": "近年来，大语言模型（LLMs）的成功促使人们重新审视推荐系统中的规模扩展律。然而，受限于标准自注意力机制高昂的计算复杂度，具备规模扩展性的模型在面向工业场景对长序列用户行为建模时难以实际落地。尽管诸多领域已提出多种稀疏自注意力机制，却未能充分契合推荐任务。根本原因在于用户行为具有个性化与时序特征：不同用户的行为模式差异显著，且随时间动态演化，导致其数据分布在跨领域间存在显著偏移。\n\n为破解上述难题，我们提出 SparseCTR——一个专门面向长周期用户行为的高效、有效模型。具体而言，首先以个性化方式将行为序列切分为块，避免割裂连续行为，同时实现序列的并行处理。基于这些“行为块”，我们设计了一种三分支稀疏自注意力机制，以联合建模用户的全局兴趣、兴趣迁移与短期兴趣。此外，借助可学习的头专属偏置系数，我们构建了复合相对时序编码，更精准地捕捉用户行为中的序列与周期性依赖。\n\n大量实验表明，SparseCTR 不仅显著提升了计算效率，还全面优于当前最优方法；更重要的是，模型呈现出明显的规模扩展律，在三个数量级的 FLOPs 范围内仍持续提升性能。在线 A/B 测试结果显示，SparseCTR 将 CTR 提升 1.72%，CPM 提升 1.41%。源代码已开源：https://github.com/laiweijiang/SparseCTR。"
    },
    {
        "title": "OwlerLite: Scope- and Freshness-Aware Web Retrieval for LLM Assistants",
        "summary": "Browser-based language models often use retrieval-augmented generation (RAG) but typically rely on fixed, outdated indices that give users no control over which sources are consulted. This can lead to answers that mix trusted and untrusted content or draw on stale information. We present OwlerLite, a browser-based RAG system that makes user-defined scopes and data freshness central to retrieval. Users define reusable scopes-sets of web pages or sources-and select them when querying. A freshness-aware crawler monitors live pages, uses a semantic change detector to identify meaningful updates, and selectively re-indexes changed content. OwlerLite integrates text relevance, scope choice, and recency into a unified retrieval model. Implemented as a browser extension, it represents a step toward more controllable and trustworthy web assistants.",
        "entry_id": "http://arxiv.org/abs/2601.17824v1",
        "pub_date": "2026-01-25",
        "translated_summary": "现有的浏览器端语言模型通常使用检索增强生成（RAG），但普遍依赖固定、过期的索引，用户无法决定检索应参考哪些来源。这导致模型给出的答案常常混杂可信与不可信信息，或使用过时的内容。我们提出 OwlerLite——一个以浏览器为中心的 RAG 系统，把用户自定义范围和数据的“新鲜度”置于检索核心。用户可以预先建立可复用的“范围组”（即网页或来源集合），并在提问时直接选用。系统内部的 freshness-aware 爬虫会实时监控页面变动；通过语义变化检测器识别有意义的内容更新，并只对发生实质变动的内容重新索引。OwlerLite 将文本相关性、范围选择以及时效性统一纳入检索评分。作为浏览器扩展实现，OwlerLite 朝着更可控、更可信的网络助理迈进了一步。"
    },
    {
        "title": "Token-Weighted Multi-Target Learning for Generative Recommenders with Curriculum Learning",
        "summary": "Generative recommender systems have recently attracted attention by formulating next-item prediction as an autoregressive sequence generation task. However, most existing methods optimize standard next-token likelihood and implicitly treat all tokens as equally informative, which is misaligned with semantic-ID-based generation. Accordingly, we propose two complementary information-gain-based token-weighting strategies tailored to generative recommendation with semantic IDs. Front-Greater Weighting captures conditional semantic information gain by prioritizing early tokens that most effectively reduce candidate-item uncertainty given their prefixes and encode coarse semantics. Frequency Weighting models marginal information gain under long-tailed item and token distributions, upweighting rare tokens to counteract popularity bias. Beyond individual strategies, we introduce a multi-target learning framework with curriculum learning that jointly optimizes the two token-weighted objectives alongside standard likelihood, enabling stable optimization and adaptive emphasis across training stages. Extensive experiments on benchmark datasets show that our method consistently outperforms strong baselines and existing token-weighting approaches, with improved robustness, strong generalization across different semantic-ID constructions, and substantial gains on both head and tail items. Code is available at https://github.com/CHIUWEINING/Token-Weighted-Multi-Target-Learning-for-Generative-Recommenders-with-Curriculum-Learning.",
        "entry_id": "http://arxiv.org/abs/2601.17787v1",
        "pub_date": "2026-01-25",
        "translated_summary": "生成式推荐系统通过将下一个物品的预测建模为自回归序列生成任务而备受关注。然而，现有方法大多仅优化标准下一个 token 的似然损失，并将所有 token 视作同等信息量，这与基于语义 ID（semantic-ID）的生成任务并不匹配。为解决这一问题，我们提出了两种互补的基于信息增益的 token 加权策略：\n\n1. **Front-Greater 加权（FGW）**：通过优先给予能最大程度减少候选物品不确定度的早期 token 更高权重，从而捕获给定前缀条件下的语义信息增益，并编码粗略的语义信息。\n\n2. **频率加权（FLW）**：针对长尾物品与 token 分布，建模边际信息增益，对罕见但信息量大的 token 赋予更高权重，以缓解流行度偏差。\n\n除单个策略外，我们引入了一个多任务学习框架，采用课程式学习（curriculum learning）将两种 token 加权目标与标准似然损失联合优化，实现训练过程中的稳定优化与自适应重点。在多个公开基准数据集上的大量实验表明，本文方法在鲁棒性、对不同语义 ID 构建方式的泛化能力以及头部/尾部物品性能上均显著优于主流基线和现有 token 加权方案。\n\n代码与模型已开源：https://github.com/CHIUWEINING/TOKEN-Weighted-Multi-Target-Learning-For-Generative-Recommenders-with-Curriculum-Learning"
    },
    {
        "title": "LegalMALR:Multi-Agent Query Understanding and LLM-Based Reranking for Chinese Statute Retrieval",
        "summary": "Statute retrieval is essential for legal assistance and judicial decision support, yet real-world legal queries are often implicit, multi-issue, and expressed in colloquial or underspecified forms. These characteristics make it difficult for conventional retrieval-augmented generation pipelines to recover the statutory elements required for accurate retrieval. Dense retrievers focus primarily on the literal surface form of the query, whereas lightweight rerankers lack the legal-reasoning capacity needed to assess statutory applicability. We present LegalMALR, a retrieval framework that integrates a Multi-Agent Query Understanding System (MAS) with a zero-shot large-language-model-based reranking module (LLM Reranker). MAS generates diverse, legally grounded reformulations and conducts iterative dense retrieval to broaden candidate coverage. To stabilise the stochastic behaviour of LLM-generated rewrites, we optimise a unified MAS policy using Generalized Reinforcement Policy Optimization(GRPO). The accumulated candidate set is subsequently evaluated by the LLM Reranker, which performs natural-language legal reasoning to produce the final ranking. We further construct CSAID, a dataset of 118 difficult Chinese legal queries annotated with multiple statutory labels, and evaluate LegalMALR on both CSAID and the public STARD benchmark. Experiments show that LegalMALR substantially outperforms strong Retrieval-augmented generation(RAG) baselines in both in-distribution and out-of-distribution settings, demonstrating the effectiveness of combining multi-perspective query interpretation, reinforcement-based policy optimisation, and large-model reranking for statute retrieval.",
        "entry_id": "http://arxiv.org/abs/2601.17692v1",
        "pub_date": "2026-01-25",
        "translated_summary": "法规检索对法律辅助和司法决策支持至关重要，然而真实世界的法律查询往往含蓄、多议题且用口语化或不完整的形式表达。这些特性使得传统的检索增强生成（RAG）流程难以召回判决所需的精确法规条文。\n\n稠密（dense）检索器主要关注查询的字面形式，而轻量级重排序器又缺乏判定法规适用性所需的法律推理能力。我们提出 **LegalMALR**，一个将多智能体查询理解系统（MAS）与基于零样本大语言模型的重排序模块（LLM Reranker）相结合的新型检索框架。MAS 为查询生成多样化、具法律依据的改写，并进行多轮稠密检索以扩大候选覆盖面。为稳定大语言模型改写带来的随机行为，我们用广义强化策略优化（GRPO）对统一的 MAS 策略进行优化。随后，LLM 重排序器对累积候选集进行自然语言法律推理，以生成最终排序。\n\n此外，我们构建了 **CSAID** 数据集，其中包含 118 条困难的法规查询及多项法律标签注释，并在 CSAID 与公开基准 STARD 上对 LegalMALR 进行评估。实验表明，无论是在分布内还是分布外场景下，LegalMALR 均显著优于现有 RAG 基线，证明了多视角查询解释、基于强化学习的策略优化以及大模型重排序在法规检索中的有效结合。"
    },
    {
        "title": "Segment Length Matters: A Study of Segment Lengths on Audio Fingerprinting Performance",
        "summary": "Audio fingerprinting provides an identifiable representation of acoustic signals, which can be later used for identification and retrieval systems. To obtain a discriminative representation, the input audio is usually segmented into shorter time intervals, allowing local acoustic features to be extracted and analyzed. Modern neural approaches typically operate on short, fixed-duration audio segments, yet the choice of segment duration is often made heuristically and rarely examined in depth. In this paper, we study how segment length affects audio fingerprinting performance. We extend an existing neural fingerprinting architecture to adopt various segment lengths and evaluate retrieval accuracy across different segment lengths and query durations. Our results show that short segment lengths (0.5-second) generally achieve better performance. Moreover, we evaluate LLM capacity in recommending the best segment length, which shows that GPT-5-mini consistently gives the best suggestions across five considerations among three studied LLMs. Our findings provide practical guidance for selecting segment duration in large-scale neural audio retrieval systems.",
        "entry_id": "http://arxiv.org/abs/2601.17690v1",
        "pub_date": "2026-01-25",
        "translated_summary": "音频指纹技术为声学信号提供一种可辨识的表征，可用于后续识别与检索系统。为了获得具有辨别力的描述，输入音频通常被划分为更短的时间段，从而提取并分析局部声学特征。现代神经网络方法一般在固定时长的短片段上操作，然而片段长度的选择往往依据经验，缺乏深入探讨。本文研究片段长度对音频指纹性能的影响。我们将现有的神经指纹架构扩展至可适配多种片段长度，并在不同片段长度与不同查询时长下评估检索准确率。实验结果显示，较短片段（0.5 秒）通常表现最佳。此外，我们评估了大语言模型在推荐最优片段长度方面的能力，发现 GPT-5-mini 在三大模型、五种考量下始终能提供最优建议。研究结果为大 规模神经音频检索系统选取片段时长提供了切实可行的指导。"
    },
    {
        "title": "Memento: Towards Proactive Visualization of Everyday Memories with Personal Wearable AR Assistant",
        "summary": "We introduce Memento, a conversational AR assistant that permanently captures and memorizes user's verbal queries alongside their spatiotemporal and activity contexts. By storing these \"memories,\" Memento discovers connections between users' recurring interests and the contexts that trigger them. Upon detection of similar or identical spatiotemporal activity, Memento proactively recalls user interests and delivers up-to-date responses through AR, seamlessly integrating AR experience into their daily routine. Unlike prior work, each interaction in Memento is not a transient event, but a connected series of interactions with coherent long--term perspective, tailored to the user's broader multimodal (visual, spatial, temporal, and embodied) context. We conduct preliminary evaluation through user feedbacks with participants of diverse expertise in immersive apps, and explore the value of proactive context-aware AR assistant in everyday settings. We share our findings and challenges in designing a proactive, context-aware AR system.",
        "entry_id": "http://arxiv.org/abs/2601.17622v1",
        "pub_date": "2026-01-24",
        "translated_summary": "我们推出了一款名为 Memento 的对话式增强现实（AR）助手。它能够永久性地记录用户在提出语音请求时的时空环境与活动情境，并将这些“记忆”一并保存。借助这些记忆，Memento 可以发现用户反复出现的兴趣点与触发此类兴趣的情境之间的关联。一旦检测到相似或一致的时空活动，Memento 便能主动回忆相关兴趣，并以 AR 方式提供最新的响应，无缝融入用户的日常。与既有工作不同，Memento 中的每一次交互都不是转瞬即逝的事件，而是以用户的多模态（视觉、空间、时间及体感）情境为纽带，构建起连续、一致、立足长期视角的互动序列。我们通过邀请了具备不同沉浸式应用经验的参与者进行用户反馈，完成了初步评估，并探讨了日常场景中主动式情境感知 AR 助手的价值。在此基础上，我们分享了构建主动情境感知 AR 系统过程中发现的经验与面临的挑战。"
    },
    {
        "title": "Agentic Search in the Wild: Intents and Trajectory Dynamics from 14M+ Real Search Requests",
        "summary": "LLM-powered search agents are increasingly being used for multi-step information seeking tasks, yet the IR community lacks empirical understanding of how agentic search sessions unfold and how retrieved evidence is used. This paper presents a large-scale log analysis of agentic search based on 14.44M search requests (3.97M sessions) collected from DeepResearchGym, i.e. an open-source search API accessed by external agentic clients. We sessionize the logs, assign session-level intents and step-wise query-reformulation labels using LLM-based annotation, and propose Context-driven Term Adoption Rate (CTAR) to quantify whether newly introduced query terms are traceable to previously retrieved evidence. Our analyses reveal distinctive behavioral patterns. First, over 90% of multi-turn sessions contain at most ten steps, and 89% of inter-step intervals fall under one minute. Second, behavior varies by intent. Fact-seeking sessions exhibit high repetition that increases over time, while sessions requiring reasoning sustain broader exploration. Third, agents reuse evidence across steps. On average, 54% of newly introduced query terms appear in the accumulated evidence context, with contributions from earlier steps beyond the most recent retrieval. The findings suggest that agentic search may benefit from repetition-aware early stopping, intent-adaptive retrieval budgets, and explicit cross-step context tracking. We plan to release the anonymized logs to support future research.",
        "entry_id": "http://arxiv.org/abs/2601.17617v1",
        "pub_date": "2026-01-24",
        "translated_summary": "I'm ready — how can I help you?"
    },
    {
        "title": "Why They Link: An Intent Taxonomy for Including Hyperlinks in Social Posts",
        "summary": "URLs serve as bridges between social media platforms and the broader web, linking user-generated content to external information resources. On Twitter (X), approximately one in five tweets contains at least one URL, underscoring their central role in information dissemination. While prior studies have examined the motivations of authors who share URLs, such author-centered intentions are difficult to observe in practice. To enable broader downstream use, this work investigates reader-centered interpretations, i.e., how users perceive the intentions behind hyperlinks included in posts. We develop an intent taxonomy for including hyperlinks in social posts through a hybrid approach that begins with a bottom-up, data-driven process using large-scale crowdsourced annotations, and is then refined using large language model assistance to generate descriptive category names and precise definitions. The final taxonomy comprises 6 top-level categories and 26 fine-grained intention classes, capturing diverse communicative purposes. Applying this taxonomy, we annotate and analyze 1000 user posts, revealing that advertising, arguing, and sharing are the most prevalent intentions. This resulting taxonomy provides a foundation for intent-aware information retrieval and NLP applications, enabling more accurate retrieval, recommendation, and understanding of social media content.",
        "entry_id": "http://arxiv.org/abs/2601.17601v1",
        "pub_date": "2026-01-24",
        "translated_summary": "URL 像一座座桥梁，把社交媒体平台和更广泛的网络连接起来，使用户生成内容与外部信息资源相互贯通。在 Twitter（X）上，大约每五条推文就含有一个 URL，凸显了超链接在信息传播中的核心作用。既往研究多聚焦于作者为何发布 URL，但这类以作者为中心的意图在实际中难以观测。为了便于下游大规模应用，本文转向以读者为中心的视角，探讨用户如何理解帖子中所含超链接的意图。我们采用混合方法构建超链接意图分类体系：先行基于大规模众包标注，以自下而上的数据驱动方式聚类；再借助大语言模型提炼类别命名与精确定义。最终分类体系包含 6 个顶层类别与 26 个细粒度意图类，全面覆盖多样的传播目的。在此体系下，我们对 1000 条用户帖子进行标注与分析，发现“广告宣传”“观点论证”与“资源分享”是最常见的三种意图。该分类体系为意图感知的信息检索和自然语言处理应用奠定了理论与数据基础，可提升社交媒体内容的检索、推荐与理解精度。"
    },
    {
        "title": "Improving User Privacy in Personalized Generation: Client-Side Retrieval-Augmented Modification of Server-Side Generated Speculations",
        "summary": "Personalization is crucial for aligning Large Language Model (LLM) outputs with individual user preferences and background knowledge. State-of-the-art solutions are based on retrieval augmentation, where relevant context from a user profile is retrieved for LLM consumption. These methods deal with a trade-off between exposing retrieved private data to cloud providers and relying on less capable local models. We introduce $P^3$, an interactive framework for high-quality personalization without revealing private profiles to server-side LLMs. In $P^3$, a large server-side model generates a sequence of $k$ draft tokens based solely on the user query, while a small client-side model, with retrieval access to the user's private profile, evaluates and modifies these drafts to better reflect user preferences. This process repeats until an end token is generated. Experiments on LaMP-QA, a recent benchmark consisting of three personalized question answering datasets, show that $P^3$ consistently outperforms both non-personalized server-side and personalized client-side baselines, achieving statistically significant improvements of $7.4%$ to $9%$ on average. Importantly, $P^3$ recovers $90.3%$ to $95.7%$ of the utility of a ``leaky'' upper-bound scenario in which the full profile is exposed to the large server-side model. Privacy analyses, including linkability and attribute inference attacks, indicate that $P^3$ preserves the privacy of a non-personalized server-side model, introducing only marginal additional leakage ($1.5%$--$3.5%$) compared to submitting a query without any personal context. Additionally, the framework is efficient for edge deployment, with the client-side model generating only $9.2%$ of the total tokens. These results demonstrate that $P^3$ provides a practical, effective solution for personalized generation with improved privacy.",
        "entry_id": "http://arxiv.org/abs/2601.17569v1",
        "pub_date": "2026-01-24",
        "translated_summary": "个性化对于使大型语言模型（LLM）输出与个体用户的偏好和背景知识保持一致至关重要。目前最先进的方案采用检索增强：先从用户画像中提取相关上下文，再交由 LLM 处理。然而，这类方法不得不在把私密数据暴露给云端模型的风险与依赖能力较弱的本地模型之间权衡。\n\n我们提出 **P³（Private Personalized Prompting）**，一个交互式框架，可在不向云侧 LLM 泄露私密画像的前提下实现高质量个性化。P³ 的工作原理如下：  \n1. 云端大模型仅根据用户原始查询生成 k 个“草稿 token”；  \n2. 端侧小型模型在本地检索并读取用户的私密画像后，对这些草稿进行评估和改写，使其更贴合用户偏好；  \n3. 该步骤往复进行，直到生成结束 token。\n\n在新近发布的个性化问答基准 LaMP-QA（包含 3 个问答数据集）上的实验表明，P³ 在保持云端模型无个人信息暴露的同时，性能稳定优于非个性化云端模型和本地化个性化基线，平均提升 7.4%–9%（统计显著）。更重要的是，P³ 达到了一种“泄密上限”情景（即服务器拥有完整画像）效果的 90.3%–95.7%。\n\n隐私分析（包括可关联性攻击和属性推理攻击）显示，P³ 的隐私泄露水平与完全不暴露个人信息的云侧模型基本相当，仅增加 1.5%–3.5% 的边际泄露。此外，端侧模型仅需生成总 token 的 9.2%，即可部署于边缘设备。综上，P³ 为隐私增强的个性化生成提供了一种实用、高效的解决方案。"
    },
    {
        "title": "Real-Time Trend Prediction via Continually-Aligned LLM Query Generation",
        "summary": "Trending news detection in low-traffic search environments faces a fundamental cold-start problem, where a lack of query volume prevents systems from identifying emerging or long-tail trends. Existing methods relying on keyword frequency or query spikes are inherently slow and ineffective in these sparse settings, lagging behind real-world shifts in attention. We introduce RTTP, a novel Real-Time Trending Prediction framework that generates search queries directly from news content instead of waiting for users to issue them. RTTP leverages a continual learning LLM (CL-LLM) that converts posts into search-style queries and scores them using engagement strength + creator authority, enabling early trend surfacing before search volume forms. To ensure adaptation without degrading reasoning, we propose Mix-Policy DPO, a new preference-based continual learning approach that combines on-policy stability with off-policy novelty to mitigate catastrophic forgetting during model upgrades. Deployed at production scale on Facebook and Meta AI products, RTTP delivers +91.4% improvement in tail-trend detection precision@500 and +19% query generation accuracy over industry baselines, while sustaining stable performance after multi-week online training. This work demonstrates that LLM-generated synthetic search signals, when aligned and continually updated, unlock timely trend understanding in low-traffic search environments.",
        "entry_id": "http://arxiv.org/abs/2601.17567v1",
        "pub_date": "2026-01-24",
        "translated_summary": "在低流量搜索环境中进行热点新闻探测时，会遭遇根深蒂固的冷启动困境：查询量稀少导致系统难以识别新兴或长尾趋势。现有的基于关键词频率或查询峰值的方法在这些稀疏场景下天然迟缓、收效甚微，往往滞后于现实世界的注意力迁移。我们提出 RTTP（Real-Time Trending Prediction），一种新的实时热点预测框架，可直接从新闻内容生成搜索查询，而无需等待用户发起。RTTP 采用持续学习大语言模型（CL-LLM），将新闻帖转化为搜索式查询，并综合互动强度与创作者权威度进行打分，使得在搜索量尚未形成之际就能提前发现趋势。为了在模型升级过程中保持适应性且不损伤推理能力，我们提出 Mix-Policy DPO——一种基于偏好的持续学习方法，融合“在线策略稳定”与“离线策略新颖”，显著缓解灾难性遗忘。RTTP 已在 Facebook 和 Meta AI 产品全面上线：相比业界基线，尾部热点检测 precision@500 提升 91.4%，查询生成准确率提升 19%，并在多周在线训练后仍保持稳定表现。本工作表明，经过持续对齐更新的 LLM 合成搜索信号，可为低流量搜索环境解锁及时的趋势洞察。"
    },
    {
        "title": "Pipeline Inspection, Visualization, and Interoperability in PyTerrier",
        "summary": "PyTerrier provides a declarative framework for building and experimenting with Information Retrieval (IR) pipelines. In this demonstration, we highlight several recent pipeline operations that improve their ability to be programmatically inspected, visualized, and integrated with other tools (via the Model Context Protocol, MCP). These capabilities aim to make it easier for researchers, students, and AI agents to understand and use a wide array of IR pipelines.",
        "entry_id": "http://arxiv.org/abs/2601.17502v1",
        "pub_date": "2026-01-24",
        "translated_summary": "PyTerrier 是一个用于构建与实验信息检索（IR）管道的声明式框架。本次演示重点介绍了近期新增的若干管道操作，这些操作使研究者、学生乃至 AI 智能体能够更容易地程序化检查、可视化 IR 管道，并通过模型上下文协议（MCP）将它们与其他工具无缝集成。"
    },
    {
        "title": "To Case or Not to Case: An Empirical Study in Learned Sparse Retrieval",
        "summary": "Learned Sparse Retrieval (LSR) methods construct sparse lexical representations of queries and documents that can be efficiently searched using inverted indexes. Existing LSR approaches have relied almost exclusively on uncased backbone models, whose vocabularies exclude case-sensitive distinctions, thereby reducing vocabulary mismatch. However, the most recent state-of-the-art language models are only available in cased versions. Despite this shift, the impact of backbone model casing on LSR has not been studied, potentially posing a risk to the viability of the method going forward. To fill this gap, we systematically evaluate paired cased and uncased versions of the same backbone models across multiple datasets to assess their suitability for LSR. Our findings show that LSR models with cased backbone models by default perform substantially worse than their uncased counterparts; however, this gap can be eliminated by pre-processing the text to lowercase. Moreover, our token-level analysis reveals that, under lowercasing, cased models almost entirely suppress cased vocabulary items and behave effectively as uncased models, explaining their restored performance. This result broadens the applicability of recent cased models to the LSR setting and facilitates the integration of stronger backbone architectures into sparse retrieval. The complete code and implementation for this project are available at: https://github.com/lionisakis/Uncased-vs-cased-models-in-LSR",
        "entry_id": "http://arxiv.org/abs/2601.17500v1",
        "pub_date": "2026-01-24",
        "translated_summary": "学会稀疏检索（LSR）方法通过为查询和文档构建可借助倒排索引高效搜索的稀疏词元表示。现有 LSR 研究几乎完全采用不分大小写的骨干模型，其词汇表忽略大小写差异，从而减轻了词汇失配。然而，前沿大模型通常只有大小写敏感版本。尽管领域已发生这一转变，骨干模型的大小写设定对 LSR 的影响尚未被探讨，这给该方法的可持续性带来潜在风险。为此，我们在多个数据集上系统评估同一骨干模型的大小写敏感与大小写不敏感版本组合，比较其 LSR 适用性。实验表明，默认情况下使用大小写敏感骨干的 LSR 性能显著弱于不分大小写版本；但若预先对文本统一小写处理，这一差距可完全消除。进一步词元级分析发现，经过小写后，大小写敏感模型的词汇几乎彻底抑制了带大小写词元，行为趋同于不分大小写模型，从而解释了性能恢复。该结果拓宽了最新大小写敏感模型在 LSR 中的应用范围，并为集成更强大的骨干架构铺平道路。项目完整代码与实现：https://github.com/lionisakis/Uncased-vs-cased-models-in-LSR"
    },
    {
        "title": "PEARL: Prototype-Enhanced Alignment for Label-Efficient Representation Learning with Deployment-Driven Insights from Digital Governance Communication Systems",
        "summary": "In many deployed systems, new text inputs are handled by retrieving similar past cases, for example when routing and responding to citizen messages in digital governance platforms. When these systems fail, the problem is often not the language model itself, but that the nearest neighbors in the embedding space correspond to the wrong cases. Modern machine learning systems increasingly rely on fixed, high-dimensional embeddings produced by large pretrained models and sentence encoders. In real-world deployments, labels are scarce, domains shift over time, and retraining the base encoder is expensive or infeasible. As a result, downstream performance depends heavily on embedding geometry. Yet raw embeddings are often poorly aligned with the local neighborhood structure required by nearest-neighbor retrieval, similarity search, and lightweight classifiers that operate directly on embeddings. We propose PEARL (Prototype-Enhanced Aligned Representation Learning), a label-efficient approach that uses limited supervision to softly align embeddings toward class prototypes. The method reshapes local neighborhood geometry while preserving dimensionality and avoiding aggressive projection or collapse. Its aim is to bridge the gap between purely unsupervised post-processing, which offers limited and inconsistent gains, and fully supervised projections that require substantial labeled data. We evaluate PEARL under controlled label regimes ranging from extreme label scarcity to higher-label settings. In the label-scarce condition, PEARL substantially improves local neighborhood quality, yielding 25.7% gains over raw embeddings and more than 21.1% gains relative to strong unsupervised post-processing, precisely in the regime where similarity-based systems are most brittle.",
        "entry_id": "http://arxiv.org/abs/2601.17495v1",
        "pub_date": "2026-01-24",
        "translated_summary": "在许多已部署的系统中，新的文本输入通过检索过往的相似案例来处理，例如在数字政务平台中路由并回复市民留言时出现的情形。当这些系统失灵时，问题往往不是语言模型本身，而是嵌入空间中最近的邻域对应了错误的案例。现代机器学习系统越来越依赖于由大型预训练模型和句子编码器生成的固定、高维嵌入。在实际部署场景中，标签稀缺，领域随时间漂移，且重新训练底层编码器既昂贵又不可行。因此，下游性能在很大程度上取决于嵌入几何。然而，未经处理的原始嵌入往往与最近邻检索、相似性搜索，以及直接以嵌入为输入的轻量级分类器所需的局部邻域结构对不齐。\n\n我们提出 PEARL（Prototype-Enhanced Aligned Representation Learning，原型增强的对齐表示学习），一种标签高效的策略，利用有限的监督数据使嵌入向类别原型软对齐。该方法重塑局部邻域几何，同时保持维度不变，避免激进的投影或坍缩。其目标是在纯无监督后处理（提升有限且不一致）和完全监督投影（需要大量标注）之间架起一座桥梁。\n\n我们在受控的标签稀缺到充足区间对 PEARL 进行评估。在标签极端稀缺的条件下，PEARL 显著提升了局部邻域质量，相对于原始嵌入带来 25.7% 的性能增益，较当前最强的无监督后处理也高出 21.1%，而这正是基于相似性的系统最易出错的关键场景。"
    },
    {
        "title": "Towards Fair Large Language Model-based Recommender Systems without Costly Retraining",
        "summary": "Large Language Models (LLMs) have revolutionized Recommender Systems (RS) through advanced generative user modeling. However, LLM-based RS (LLM-RS) often inadvertently perpetuates bias present in the training data, leading to severe fairness issues. Addressing these fairness problems in LLM-RS faces two significant challenges. 1) Existing debiasing methods, designed for specific bias types, lack the generality to handle diverse or emerging biases in real-world applications. 2) Debiasing methods relying on retraining are computationally infeasible given the massive parameter scale of LLMs. To overcome these challenges, we propose FUDLR (Fast Unified Debiasing for LLM-RS). The core idea is to reformulate the debiasing problem as an efficient machine unlearning task with two stages. First, FUDLR identifies bias-inducing samples to unlearn through a novel bias-agnostic mask, optimized to balance fairness improvement with accuracy preservation. Its bias-agnostic design allows adaptability to various or co-existing biases simply by incorporating different fairness metrics. Second, FUDLR performs efficient debiasing by estimating and removing the influence of identified samples on model parameters. Extensive experiments demonstrate that FUDLR effectively and efficiently improves fairness while preserving recommendation accuracy, offering a practical path toward socially responsible LLM-RS. The code and data are available at https://github.com/JinLi-i/FUDLR.",
        "entry_id": "http://arxiv.org/abs/2601.17492v1",
        "pub_date": "2026-01-24",
        "translated_summary": "大语言模型（LLMs）通过先进的生成式用户建模彻底革新了推荐系统（RS）。然而，基于 LLM 的推荐系统（LLM-RS）往往会在不经意间延续训练数据中的固有偏见，引发严重的公平性问题。解决 LLM-RS 中的公平性挑战面临两大关键难题：1）现有的去偏方法往往针对特定类型的偏见设计，缺乏通用性，难以应对实际应用中多样化或新出现的偏见；2）需要重新训练模型的去偏方法，在 LLM 庞大的参数量面前计算代价高得不可承受。\n\n为此，我们提出 FUDLR（Fast Unified Debiasing for LLM-RS），其核心理念是将去偏任务重新形式化为高效的机器“反学习”过程，并分为两阶段实施。首先，FUDLR 通过一个与偏见类型无关的全新掩码，识别需要“反学习”的偏见样本，并在提升公平性的同时尽可能保持准确性。该设计无需针对特定偏见，仅需替换不同的公平性指标即可灵活适配多种或共存的偏见。其次，FUDLR 通过估计并移除已识别样本对模型参数的影响，完成高效的去偏。大量实验表明，FUDLR 能够在显著提升公平性的同时保持推荐准确率，为构建更负责任的社会化 LLM-RS 提供了可行路径。代码与数据已开源：https://github.com/JinLi-i/FUDLR"
    },
    {
        "title": "Adversarial Alignment and Disentanglement for Cross-Domain CTR Prediction with Domain-Encompassing Features",
        "summary": "Cross-domain recommendation (CDR) has been increasingly explored to address data sparsity and cold-start issues. However, recent approaches typically disentangle domain-invariant features shared between source and target domains, as well as domain-specific features for each domain. However, they often rely solely on domain-invariant features combined with target domain-specific features, which can lead to suboptimal performance. To overcome the limitations, this paper presents the Adversarial Alignment and Disentanglement Cross-Domain Recommendation ($A^2DCDR$ ) model, an innovative approach designed to capture a comprehensive range of cross-domain information, including both domain-invariant and valuable non-aligned features. The $A^2DCDR$ model enhances cross-domain recommendation through three key components: refining MMD with adversarial training for better generalization, employing a feature disentangler and reconstruction mechanism for intra-domain disentanglement, and introducing a novel fused representation combining domain-invariant, non-aligned features with original contextual data. Experiments on real-world datasets and online A/B testing show that $A^2DCDR$ outperforms existing methods, confirming its effectiveness and practical applicability. The code is provided at https://github.com/youzi0925/A-2DCDR/tree/main.",
        "entry_id": "http://arxiv.org/abs/2601.17472v1",
        "pub_date": "2026-01-24",
        "translated_summary": "跨域推荐（CDR）被广泛研究以缓解数据稀疏及冷启动困境。近期方法通常将共享的域不变特征与各域特有的域特定特征进行解耦，但仅利用域不变特征与目标域的域特征进行下游推荐，往往导致次优效果。为此，本文提出对抗对齐与解耦跨域推荐模型（A²DCDR）。该模型系统全面地挖掘跨域信息，包括既有的域不变特征，也囊括潜在具有实用价值的非对齐特征。A²DCDR 以三大核心设计强化跨域迁移：1) 通过对抗训练精炼 MMD，实现更佳泛化；2) 部署特征解耦与重构机制，完成域内解耦；3) 创新性地融合域不变、非对齐特征与原始上下文信息，构建综合表征。在真实场景数据集实验及在线 A/B 测试中，A²DCDR 均显著优于现有方法，表明其有效性与落地潜力。代码开源地址：https://github.com/youzi0925/A-2DCDR/tree/main"
    },
    {
        "title": "UniGRec: Unified Generative Recommendation with Soft Identifiers for End-to-End Optimization",
        "summary": "Generative recommendation has recently emerged as a transformative paradigm that directly generates target items, surpassing traditional cascaded approaches. It typically involves two components: a tokenizer that learns item identifiers and a recommender trained on them. Existing methods often decouple tokenization from recommendation or rely on asynchronous alternating optimization, limiting full end-to-end alignment. To address this, we unify the tokenizer and recommender under the ultimate recommendation objective via differentiable soft item identifiers, enabling joint end-to-end training. However, this introduces three challenges: training-inference discrepancy due to soft-to-hard mismatch, item identifier collapse from codeword usage imbalance, and collaborative signal deficiency due to an overemphasis on fine-grained token-level semantics.\n  To tackle these challenges, we propose UniGRec, a unified generative recommendation framework that addresses them from three perspectives. UniGRec employs Annealed Inference Alignment during tokenization to smoothly bridge soft training and hard inference, a Codeword Uniformity Regularization to prevent identifier collapse and encourage codebook diversity, and a Dual Collaborative Distillation mechanism that distills collaborative priors from a lightweight teacher model to jointly guide both the tokenizer and the recommender. Extensive experiments on real-world datasets demonstrate that UniGRec consistently outperforms state-of-the-art baseline methods. Our codes are available at https://github.com/Jialei-03/UniGRec.",
        "entry_id": "http://arxiv.org/abs/2601.17438v1",
        "pub_date": "2026-01-24",
        "translated_summary": "生成式推荐最近已成为一种变革性范式，可直接生成目标物品，从而超越传统的级联方法。它通常包含两个部分：一是学习物品标识符的标记器，二是基于这些标识符训练的推荐器。现有方法通常将标记化与推荐解耦，或依赖异步交替优化，限制了全链路的端到端对齐。为此，我们以最终的推荐目标为核心，将标记器与推荐器统一起来，通过可微分的软物品标识符实现联合端到端训练。然而，这带来了三大挑战：因软、硬标识符不匹配导致的训练-推理差异；由于码字使用失衡引发的物品标识符崩溃；以及对细粒度 token 级语义过度强调而造成的协同信号不足。\n\n为应对上述难题，我们提出 UniGRec，一个统一生成式推荐框架，从三个维度系统解决：通过“退火推理对齐机制”在标记过程中平滑衔接软训练和硬推理；采用“码字均匀正则化”防止标识符崩溃并促进码本多样性；进一步引入“双重协同蒸馏机制”，让轻量级教师模型向标记器与推荐器联合蒸馏协同先验。在多个真实数据集的广泛实验表明，UniGRec 始终优于最新的基线方法。代码开源：https://github.com/Jialei-03/UniGRec"
    },
    {
        "title": "Breaking Flat: A Generalised Query Performance Prediction Evaluation Framework",
        "summary": "The traditional use-case of query performance prediction (QPP) is to identify which queries perform well and which perform poorly for a given ranking model. A more fine-grained and arguably more challenging extension of this task is to determine which ranking models are most effective for a given query. In this work, we generalize the QPP task and its evaluation into three settings: (i) SingleRanker MultiQuery (SRMQ-PP), corresponding to the standard use case; (ii) MultiRanker SingleQuery (MRSQ-PP), which evaluates a QPP model's ability to select the most effective ranker for a query; and (iii) MultiRanker MultiQuery (MRMQ-PP), which considers predictions jointly across all query ranker pairs. Our results show that (a) the relative effectiveness of QPP models varies substantially across tasks (SRMQ-PP vs. MRSQ-PP), and (b) predicting the best ranker for a query is considerably more difficult than predicting the relative difficulty of queries for a given ranker.",
        "entry_id": "http://arxiv.org/abs/2601.17359v1",
        "pub_date": "2026-01-24",
        "translated_summary": "传统查询性能预测（QPP）的常见用途是判定在一个给定排序模型下，哪些查询表现良好、哪些表现不佳。更细粒度也更具挑战性的任务扩展则是为单个查询确定最有效的排序模型。本文将 QPP 任务及其评估推广为三种设定：(i) 单一排序器、多类查询（Single-Ranker Multi-Query，SRMQ-PP），对应于最常见的标准任务；(ii) 多排序器、单类查询（Multi-Ranker Single-Query，MRSQ-PP），用来检验 QPP 模型能否为给定查询选到最合适的排序器；(iii) 多排序器、多类查询（Multi-Ranker Multi-Query，MRMQ-PP），对全部查询-排序器配对同时进行预测。实验结果表明：(a) 不同任务之间（SRMQ-PP 与 MRSQ-PP）QPP 模型的相对表现差异显著；(b) 为单个查询预测最佳排序器的难度，远高于为固定排序器预测查询相对难度。"
    },
    {
        "title": "Beyond Correlations: A Downstream Evaluation Framework for Query Performance Prediction",
        "summary": "The standard practice of query performance prediction (QPP) evaluation is to measure a set-level correlation between the estimated retrieval qualities and the true ones. However, neither this correlation-based evaluation measure quantifies QPP effectiveness at the level of individual queries, nor does this connect to a downstream application, meaning that QPP methods yielding high correlation values may not find a practical application in query-specific decisions in an IR pipeline. In this paper, we propose a downstream-focussed evaluation framework where a distribution of QPP estimates across a list of top-documents retrieved with several rankers is used as priors for IR fusion. While on the one hand, a distribution of these estimates closely matching that of the true retrieval qualities indicates the quality of the predictor, their usage as priors on the other hand indicates a predictor's ability to make informed choices in an IR pipeline. Our experiments firstly establish the importance of QPP estimates in weighted IR fusion, yielding substantial improvements of over 4.5% over unweighted CombSUM and RRF fusion strategies, and secondly, reveal new insights that the downstream effectiveness of QPP does not correlate well with the standard correlation-based QPP evaluation.",
        "entry_id": "http://arxiv.org/abs/2601.17339v1",
        "pub_date": "2026-01-24",
        "translated_summary": "查询性能预测（QPP）的传统评估做法是在集合层面测度估计的检索质量与真实值之间的相关性。然而，这种以相关性为核心的评估方式既无法在单条查询粒度上衡量 QPP 的效果，也无法与其在实际 IR 流程中的应用建立直接联系，因此即便某个 QPP 方法在此指标上表现优异，也可能在面向具体查询的决策环节中毫无实用价值。本文提出一种以“下游任务”为中心的评估框架：将若干排序器返回的 Top 文档所对应的 QPP 估计值构成的分布作为先验，用于 IR 融合。一方面，该分布愈接近真实检索质量分布，说明预测器越可靠；另一方面，其能否在融合时作为先验发挥作用，则直接体现预测器在真实 IR 流程中的决策价值。实验结果首先表明，在加权 IR 融合中引入 QPP 估计可将效果提升 4.5% 以上，显著优于无加权的 CombSUM 及 RRF 融合策略；其次发现，QPP 的下游任务有效性与传统相关性评估指标并不一致，为该领域提供了新的研究视角。"
    },
    {
        "title": "FinMetaMind: A Tech Blueprint on NLQ Systems for Financial Knowledge Search",
        "summary": "Natural Language Query (NLQ) allows users to search and interact with information systems using plain, human language instead of structured query syntax. This paper presents a technical blueprint on the design of a modern NLQ system tailored to financial knowledge search. The introduction of NLQ not only enhances the precision and recall of the knowledge search compared to traditional methods, but also facilitates deeper insights by efficiently linking disparate financial objects, events, and relationships. Using core constructs from natural language processing, search engineering, and vector data models, the proposed system aims to address key challenges in discovering, relevance ranking, data freshness, and entity recognition intrinsic to financial data retrieval. In this work, we detail the unique requirements of NLQ for financial datasets and documents, outline the architectural components for offline indexing and online retrieval, and discuss the real-world use cases of enhanced knowledge search in financial services. We delve into the theoretical underpinnings and experimental evidence supporting our proposed architecture, ultimately providing a comprehensive analysis on the subject matter. We also provide a detailed elaboration of our experimental methodology, the data used, the results and future optimizations in this study.",
        "entry_id": "http://arxiv.org/abs/2601.17333v1",
        "pub_date": "2026-01-24",
        "translated_summary": "自然语言查询（NLQ）让用户能以日常语⾔而非结构化查询语句来检索并与信息系统交互。本文就面向金融知识检索的现代 NLQ 系统给出了完备的技术蓝图。与传统方法相比，NLQ 的引入不仅在精度与召回率上显著提升知识检索效果，还能通过高效链接分散的金融对象、事件及其关系，带来更深层的洞察。本系统融合了自然语言处理、检索工程及向量数据模型的核心方法，致力于解决金融数据检索中固有的实体识别、相关性排序、数据时效性及发现性等关键难题。  \n本文首先分析了金融数据集和文档对 NLQ 提出的独特需求，继而阐释离线索引与在线检索的架构组件，并探讨 NLQ 在金融服务中知识检索提升的实际应用场景。我们对支撑该架构的理论基础及实验证据进行深入剖析，最终提供了关于该主题的全景式研究。文中亦详尽说明了实验方法、所用数据、实验结果，以及未来可进一步优化的方向。"
    },
    {
        "title": "Dep-Search: Learning Dependency-Aware Reasoning Traces with Persistent Memory",
        "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in complex reasoning tasks, particularly when augmented with search mechanisms that enable systematic exploration of external knowledge bases. The field has evolved from traditional retrieval-augmented generation (RAG) frameworks to more sophisticated search-based frameworks that orchestrate multi-step reasoning through explicit search strategies. However, existing search frameworks still rely heavily on implicit natural language reasoning to determine search strategies and how to leverage retrieved information across reasoning steps. This reliance on implicit reasoning creates fundamental challenges for managing dependencies between sub-questions, efficiently reusing previously retrieved knowledge, and learning optimal search strategies through reinforcement learning. To address these limitations, we propose Dep-Search, a dependency-aware search framework that advances beyond existing search frameworks by integrating structured reasoning, retrieval, and persistent memory through GRPO. Dep-Search introduces explicit control mechanisms that enable the model to decompose questions with dependency relationships, retrieve information when needed, access previously stored knowledge from memory, and summarize long reasoning contexts into reusable memory entries. Through extensive experiments on seven diverse question answering datasets, we demonstrate that Dep-Search significantly enhances LLMs' ability to tackle complex multi-hop reasoning tasks, achieving substantial improvements over strong baselines across different model scales.",
        "entry_id": "http://arxiv.org/abs/2601.18771v1",
        "pub_date": "2026-01-26",
        "translated_summary": "大型语言模型（LLM）在复杂推理任务中展现出非凡的能力，尤其是在通过搜索机制系统性调用外部知识库时表现尤甚。该领域已从传统的检索增强生成（RAG）框架，演进为通过显式搜索策略编排多步推理的精细搜索体系。然而，现有搜索框架仍严重依赖于隐含的自然语言推理来决定搜索策略以及如何在推理步骤间利用检索到的信息。这种对隐含推理的依赖带来根本性挑战：难以管理子问题间的依赖关系、难以高效复用已检索到的知识，也难以通过强化学习学得最优搜索策略。\n\n针对上述局限，我们提出 Dep-Search——一种具备依赖感知的搜索框架，借助 GRPO 实现结构化推理、检索与持久记忆的三重融合，从而突破现有搜索框架的上限。Dep-Search 引入了显式控制机制，使模型能够显式分解具有依赖关系的复合问题、按需检索信息，从预先存储的记忆中调取有用知识，并将冗长推理上下文凝练为可复用的记忆条目。\n\n在 7 个涵盖广泛主题的问答数据集上的大量实验表明，Dep-Search 显著提升了大模型处理复杂多跳推理任务的能力，并超越多个强基线，在不同模型规模上均实现实质性能跃升。"
    },
    {
        "title": "Capturing P: On the Expressive Power and Efficient Evaluation of Boolean Retrieval",
        "summary": "Modern information retrieval is transitioning from simple document filtering to complex, neuro-symbolic reasoning workflows. However, current retrieval architectures face a fundamental efficiency dilemma when handling the rigorous logical and arithmetic constraints required by this new paradigm. Standard iterator-based engines (Document-at-a-Time) do not natively support complex, nested logic graphs; forcing them to execute such queries typically results in intractable runtime performance. Conversely, naive recursive approaches (Term-at-a-Time), while capable of supporting these structures, suffer from prohibitive memory consumption when enforcing broad logical exclusions.\n  In this paper, we propose that a retrieval engine must be capable of ``Capturing $\\mathbf{P}$'' -- evaluating any polynomial-time property directly over its index in a computationally efficient manner. We define a formal Retrieval Language ($\\mathcal{L}_R$) based on Directed Acyclic Graphs (DAGs) and prove it precisely captures the complexity class $\\mathbf{P}$. We introduce \\texttt{ComputePN}, a novel evaluation algorithm that makes $\\mathcal{L}_R$ tractable. By combining native DAG traversal with a memory-efficient ``Positive-Negative'' response mechanism, \\texttt{ComputePN} ensures the efficient evaluation of any query in $\\mathcal{L}_R$. This work establishes the theoretical foundation for turning the search index into a general-purpose computational engine.",
        "entry_id": "http://arxiv.org/abs/2601.18747v1",
        "pub_date": "2026-01-26",
        "translated_summary": "现代信息检索正从简单的文档过滤转向复杂的神经符号推理工作流。然而，当前检索架构在应对这一新模式对严密逻辑和算术约束的需求时，面临着根本性的效率困境：标准基于迭代器的引擎（Document-at-a-Time）天生不支持复杂嵌套逻辑图，强迫执行此类查询通常会导致难以处理的运行时性能；反之，朴素的递归方法（Term-at-a-Time）虽然可以支撑这些结构，但在实施广泛逻辑排除时会带来极高的内存开销。本文断言，一个检索引擎必须具备“捕捉 **P**”的能力——以计算高效的方式直接在索引上评估任意多项式时间属性。我们定义了一种形式化的检索语言 L_R（基于有向无环图 DAG），并证明其恰恰刻画了复杂度类 **P**。我们提出 ComputePN，一种新颖的评估算法，通过将原生 DAG 遍历与内存高效的“正-负”响应机制相结合，确保 L_R 内任何查询的高效评估。此工作建立了将搜索索引转化为通用计算引擎的理论基础。"
    },
    {
        "title": "S$^2$GR: Stepwise Semantic-Guided Reasoning in Latent Space for Generative Recommendation",
        "summary": "Generative Recommendation (GR) has emerged as a transformative paradigm with its end-to-end generation advantages. However, existing GR methods primarily focus on direct Semantic ID (SID) generation from interaction sequences, failing to activate deeper reasoning capabilities analogous to those in large language models and thus limiting performance potential. We identify two critical limitations in current reasoning-enhanced GR approaches: (1) Strict sequential separation between reasoning and generation steps creates imbalanced computational focus across hierarchical SID codes, degrading quality for SID codes; (2) Generated reasoning vectors lack interpretable semantics, while reasoning paths suffer from unverifiable supervision. In this paper, we propose stepwise semantic-guided reasoning in latent space (S$^2$GR), a novel reasoning enhanced GR framework. First, we establish a robust semantic foundation via codebook optimization, integrating item co-occurrence relationship to capture behavioral patterns, and load balancing and uniformity objectives that maximize codebook utilization while reinforcing coarse-to-fine semantic hierarchies. Our core innovation introduces the stepwise reasoning mechanism inserting thinking tokens before each SID generation step, where each token explicitly represents coarse-grained semantics supervised via contrastive learning against ground-truth codebook cluster distributions ensuring physically grounded reasoning paths and balanced computational focus across all SID codes. Extensive experiments demonstrate the superiority of S$^2$GR, and online A/B test confirms efficacy on large-scale industrial short video platform.",
        "entry_id": "http://arxiv.org/abs/2601.18664v1",
        "pub_date": "2026-01-26",
        "translated_summary": "生成式推荐（GR）借助端到端生成的优势，已成为一种变革性范式。然而，现有 GR 方法直接从交互序列生成语义 ID（SID），缺乏类似大模型的深层推理能力，限制了性能上限。我们研究发现，现有推理增强型 GR 存在两大关键缺陷：  \n(1) 推理与生成步骤被强行序列分割，导致分层 SID 代码的计算资源分配失衡，进而降低代码质量；  \n(2) 产生的推理向量无显式语义，且整条推理路径缺乏可验证的监督信号。  \n\n为此，本文提出逐步语义引导的隐空间推理（S²GR）。  \n首先，通过码本优化建立坚实的语义地基：引入物品共现关系以捕捉行为模式，并设计负载均衡与一致性目标，在最大化码本利用率的同时强化粗→细层次语义。  \n核心创新在于逐步推理机制：在每个 SID 生成步骤前插入“思维”令牌，令牌显式表示粗粒度语义，并以对比学习方式与真实码本聚类分布对齐；这既确保推理路径物理可锚定，又令计算资源被均衡分配到所有 SID 代码。  \n\n大量实验验证 S²GR 的显著优势；在大型工业短视频平台的在线 A/B 测试中亦得到成效验证。"
    },
    {
        "title": "FastInsight: Fast and Insightful Retrieval via Fusion Operators for Graph RAG",
        "summary": "Existing Graph RAG methods aiming for insightful retrieval on corpus graphs typically rely on time-intensive processes that interleave Large Language Model (LLM) reasoning. To enable time-efficient insightful retrieval, we propose FastInsight. We first introduce a graph retrieval taxonomy that categorizes existing methods into three fundamental operations: vector search, graph search, and model-based search. Through this taxonomy, we identify two critical limitations in current approaches: the topology-blindness of model-based search and the semantics-blindness of graph search. FastInsight overcomes these limitations by interleaving two novel fusion operators: the Graph-based Reranker (GRanker), which functions as a graph model-based search, and Semantic-Topological eXpansion (STeX), which operates as a vector-graph search. Extensive experiments on broad retrieval and generation datasets demonstrate that FastInsight significantly improves both retrieval accuracy and generation quality compared to state-of-the-art baselines, achieving a substantial Pareto improvement in the trade-off between effectiveness and efficiency.",
        "entry_id": "http://arxiv.org/abs/2601.18579v1",
        "pub_date": "2026-01-26",
        "translated_summary": "现有的图RAG 方法为了在语料图谱上获取更具洞察力的检索结果，往往交替调用大型语言模型进行推理，导致时间开销巨大。为实现时间高效的洞察式检索，我们提出 FastInsight。首先，我们构建一个图检索分类法，将现有方法抽象为三类基本操作：向量搜索、图搜索和基于模型的搜索。借助该分类法，我们发现现有方法存在两大关键短板：基于模型的搜索忽视拓扑结构，而图搜索则缺乏语义理解。\n\nFastInsight 通过融合两项新颖操作来克服上述局限：\n1. Graph-based Reranker（GRanker）：充当图模型式搜索模块，兼顾语义与拓扑。\n2. Semantic-Topological eXpansion（STeX）：融合向量搜索与图搜索，持续扩展路径。\n\n在涵盖检索与生成的多组数据集上的大量实验表明，FastInsight 在检索精度和生成质量方面均优于当前最佳基线，并在效能与时间效率的权衡中实现了显著的帕累托改进。"
    },
    {
        "title": "Feature-Indexed Federated Recommendation with Residual-Quantized Codebooks",
        "summary": "Federated recommendation provides a privacy-preserving solution for training recommender systems without centralizing user interactions. However, existing methods follow an ID-indexed communication paradigm that transmit whole item embeddings between clients and the server, which has three major limitations: 1) consumes uncontrollable communication resources, 2) the uploaded item information cannot generalize to related non-interacted items, and 3) is sensitive to client noisy feedback. To solve these problems, it is necessary to fundamentally change the existing ID-indexed communication paradigm. Therefore, we propose a feature-indexed communication paradigm that transmits feature code embeddings as codebooks rather than raw item embeddings. Building on this paradigm, we present RQFedRec, which assigns each item a list of discrete code IDs via Residual Quantization (RQ)-Kmeans. Each client generates and trains code embeddings as codebooks based on discrete code IDs provided by the server, and the server collects and aggregates these codebooks rather than item embeddings. This design makes communication controllable since the codebooks could cover all items, enabling updates to propagate across related items in same code ID. In addition, since code embedding represents many items, which is more robust to a single noisy item. To jointly capture semantic and collaborative information, RQFedRec further adopts a collaborative-semantic dual-channel aggregation with a curriculum strategy that emphasizes semantic codes early and gradually increases the contribution of collaborative codes over training. Extensive experiments on real-world datasets demonstrate that RQFedRec consistently outperforms state-of-the-art federated recommendation baselines while significantly reducing communication overhead.",
        "entry_id": "http://arxiv.org/abs/2601.18570v1",
        "pub_date": "2026-01-26",
        "translated_summary": "联邦推荐为在不集中用户交互数据的情况下训练推荐系统提供了隐私保护的解决方案。然而，现有方法沿用基于 ID 的通信范式，在客户端与服务器之间完整传输项目嵌入向量，存在三大局限：1) 通信资源开销不可控；2) 上传的项目信息难以泛化到未曾交互的相关项目；3) 对客户端的含噪反馈敏感。为从根本上克服这些问题，我们提出以特征索引为核心的通信范式，用码本中的特征码嵌入取代原始项目嵌入进行传输。\n\n依托这一范式，我们设计了 RQFedRec，具体过程如下：首先通过残差量化（RQ）-Kmeans 为每个项目分配一组离散码 ID；服务器将这些码 ID 下发后，客户端利用这些离散码训练码本（并非项目嵌入），然后上传更新后的码本，由服务器聚合。该设计带来三点优势：其一，因码本可覆盖全部项目，通信量固定且可控；其二，共享同一代码 ID 的多个项目可同时受益，实现跨项目信息泛化；其三，单一项目的噪声对多个项目共享的码嵌入影响有限，鲁棒性更强。\n\n为融合语义与协同信息，RQFedRec 引入“协同-语义”双通道聚合，并以课程式训练策略逐步加大协同通道权重：训练早期侧重语义通道，后期逐步引入协同信息。大规模真实数据实验表明，RQFedRec 在显著降低通信开销的同时，准确率始终优于现有联邦推荐基线。"
    },
    {
        "title": "Token-level Collaborative Alignment for LLM-based Generative Recommendation",
        "summary": "Large Language Models (LLMs) have demonstrated strong potential for generative recommendation by leveraging rich semantic knowledge. However, existing LLM-based recommender systems struggle to effectively incorporate collaborative filtering (CF) signals, due to a fundamental mismatch between item-level preference modeling in CF and token-level next-token prediction (NTP) optimization in LLMs. Prior approaches typically treat CF as contextual hints or representation bias, and resort to multi-stage training to reduce behavioral semantic space discrepancies, leaving CF unable to explicitly regulate LLM generation. In this work, we propose Token-level Collaborative Alignment for Recommendation (TCA4Rec), a model-agnostic and plug-and-play framework that establishes an explicit optimization-level interface between CF supervision and LLM generation. TCA4Rec consists of (i) Collaborative Tokenizer, which projects raw item-level CF logits into token-level distributions aligned with the LLM token space, and (ii) Soft Label Alignment, which integrates these CF-informed distributions with one-hot supervision to optimize a soft NTP objective. This design preserves the generative nature of LLM training while enabling collaborative alignment with essential user preference of CF models. We highlight TCA4Rec is compatible with arbitrary traditional CF models and generalizes across a wide range of decoder-based LLM recommender architectures. Moreover, it provides an explicit mechanism to balance behavioral alignment and semantic fluency, yielding generative recommendations that are both accurate and controllable. Extensive experiments demonstrate that TCA4Rec consistently improves recommendation performance across a broad spectrum of CF models and LLM-based recommender systems.",
        "entry_id": "http://arxiv.org/abs/2601.18457v1",
        "pub_date": "2026-01-26",
        "translated_summary": "大型语言模型（LLM）通过利用丰富的语义知识，在生成式推荐中展现了巨大潜力。然而，现有的基于 LLM 的推荐系统难以有效纳入协同过滤（CF）信号，这是由于 CF 所建模的“物品级用户偏好”与 LLM 训练的“令牌级下一个令牌预测（NTP）”之间存在根本的不匹配。早期方法通常把 CF 结果仅当作上下文提示或表征偏差，并依赖多阶段训练来缩小行为-语义空间差异，导致 CF 无法直接干预 LLM 的生成过程。\n\n在该工作中，我们提出 Token-level Collaborative Alignment for Recommendation（TCA4Rec），一种与模型无关、即插即用的框架，可在 CF 监督与 LLM 生成之间构建明确的优化级接口。TCA4Rec 包括：\n(i) Collaborative Tokenizer，将原始物品级 CF logits 映射为与 LLM 令牌空间对齐的令牌级分布；\n(ii) Soft Label Alignment，将 CF 提供的分布与原始 one-hot 监督融合，以优化一个软 NTP 目标。\n\n该设计在完全不破坏 LLM 生成式训练特性的前提下，实现了与用户偏好的协同对齐。TCA4Rec 可与任意传统 CF 模型兼容，并泛化到多种解码器式 LLM 推荐架构；同时提供显式机制来调节“行为对齐”和“语义流畅性”，使生成的推荐既准确又可控。\n\n大量实验表明，TCA4Rec 在多种 CF 模型与 LLM 推荐系统上均持续提升推荐性能。"
    },
    {
        "title": "TopKGAT: A Top-K Objective-Driven Architecture for Recommendation",
        "summary": "Recommendation systems (RS) aim to retrieve the top-K items most relevant to users, with metrics such as Precision@K and Recall@K commonly used to assess effectiveness. The architecture of an RS model acts as an inductive bias, shaping the patterns the model is inclined to learn. In recent years, numerous recommendation architectures have emerged, spanning traditional matrix factorization, deep neural networks, and graph neural networks. However, their designs are often not explicitly aligned with the top-K objective, thereby limiting their effectiveness.\n  To address this limitation, we propose TopKGAT, a novel recommendation architecture directly derived from a differentiable approximation of top-K metrics. The forward computation of a single TopKGAT layer is intrinsically aligned with the gradient ascent dynamics of the Precision@K metric, enabling the model to naturally improve top-K recommendation accuracy. Structurally, TopKGAT resembles a graph attention network and can be implemented efficiently. Extensive experiments on four benchmark datasets demonstrate that TopKGAT consistently outperforms state-of-the-art baselines. The code is available at https://github.com/StupidThree/TopKGAT.",
        "entry_id": "http://arxiv.org/abs/2601.18432v1",
        "pub_date": "2026-01-26",
        "translated_summary": "推荐系统（RS）旨在为用户返回最相关的 top-K 个物品，常用 Precision@K 和 Recall@K 等指标进行评估。RS 模型的架构本身即是一种归纳偏置，决定了模型倾向于学习何种模式。近年来，众多推荐架构层出不穷，从传统的矩阵分解、深度神经网络到图神经网络，层出不穷。然而，这些架构的设计往往与 top-K 目标并未显式对齐，从而限制了它们的有效性。\n\n为克服该局限，我们提出一种全新的推荐架构——TopKGAT，它以 top-K 指标的端到端可微近似为直接出发点。单个 TopKGAT 层的前向计算在本质上对齐了 Precision@K 的梯度上升动态，使模型自然地优化 top-K 推荐精度。结构上，TopKGAT 类似图注意力网络，且可高效实现。在四个基准数据集的广泛实验表明，TopKGAT 一致地优于目前的最先进基线。代码已开源：https://github.com/StupidThree/TopKGAT。"
    },
    {
        "title": "Beyond the Checkbox: Strengthening DSA Compliance Through Social Media Algorithmic Auditing",
        "summary": "Algorithms of online platforms are required under the Digital Services Act (DSA) to comply with specific obligations concerning algorithmic transparency, user protection and privacy. To verify compliance with these requirements, DSA mandates platforms to undergo independent audits. Little is known about current auditing practices and their effectiveness in ensuring such compliance. To this end, we bridge regulatory and technical perspectives by critically examining selected audit reports across three critical algorithmic-related provisions: restrictions on profiling minors, transparency in recommender systems, and limitations on targeted advertising using sensitive data. Our analysis shows significant inconsistencies in methodologies and lack of technical depth when evaluating AI-powered systems. To enhance the depth, scale, and independence of compliance assessments, we propose to employ algorithmic auditing -- a process of behavioural assessment of AI algorithms by means of simulating user behaviour, observing algorithm responses and analysing them for audited phenomena.",
        "entry_id": "http://arxiv.org/abs/2601.18405v1",
        "pub_date": "2026-01-26",
        "translated_summary": "根据《数字服务法案》（DSA），在线平台的算法必须遵守关于算法透明度、用户保护与隐私的特定义务。为确保这些合规要求得以落实，DSA 强制平台接受独立审计。然而，目前尚不清楚现存的审计做法能否有效检验合规情况。\n\n为此，我们从监管与技术双重视角出发，对若干审计报告进行批判性分析，聚焦与之密切相关的三项条款：对未成年人画像的限制、推荐系统透明度，以及对敏感数据定向广告的限定。分析结果显示，现有方法在评估由 AI 驱动的系统时，方法论差异显著，技术深度不足。\n\n为了提升合规评估的深度、规模与独立性，我们提议采用“算法审计”——一种通过模拟用户行为、观察算法反应并对其审计现象进行分析，从而对 AI 算法开展行为评估的审核流程。"
    },
    {
        "title": "Corpus-Based Approaches to Igbo Diacritic Restoration",
        "summary": "With natural language processing (NLP), researchers aim to enable computers to identify and understand patterns in human languages. This is often difficult because a language embeds many dynamic and varied properties in its syntax, pragmatics and phonology, which need to be captured and processed. The capacity of computers to process natural languages is increasing because NLP researchers are pushing its boundaries. But these research works focus more on well-resourced languages such as English, Japanese, German, French, Russian, Mandarin Chinese, etc. Over 95% of the world's 7000 languages are low-resourced for NLP, i.e. they have little or no data, tools, and techniques for NLP work.\n  In this thesis, we present an overview of diacritic ambiguity and a review of previous diacritic disambiguation approaches on other languages. Focusing on the Igbo language, we report the steps taken to develop a flexible framework for generating datasets for diacritic restoration. Three main approaches, the standard n-gram model, the classification models and the embedding models were proposed. The standard n-gram models use a sequence of previous words to the target stripped word as key predictors of the correct variants. For the classification models, a window of words on both sides of the target stripped word was used. The embedding models compare the similarity scores of the combined context word embeddings and the embeddings of each of the candidate variant vectors.",
        "entry_id": "http://arxiv.org/abs/2601.18380v1",
        "pub_date": "2026-01-26",
        "translated_summary": "借助自然语言处理（NLP），研究者们力图让计算机识别并理解人类语言中的模式。然而，这一任务并不容易：语言的句法、语用与音系中嵌入了许多动态而各异的特性，这些都必须被有效捕获并处理。得益于NLP研究者不断拓展其边界，计算机处理自然语言的能力正持续提升。但目前的研究集中于英语、日语、德语、法语、俄语、普通话等资源丰富、被广泛使用的语言。全球约7000种语言中，还有95%以上在NLP领域属于“低资源语言”，缺乏可供研究的数据、工具与技术。\n\n本文首先概述了音调符号（diacritic）歧义问题，并回顾了其他语言的相关去歧义方法。聚焦于伊博语（Igbo），本研究记录了开发灵活数据集生成框架以进行音调符号复原的全过程。具体而言，我们提出了三种主要方案：传统 n-gram 模型、分类模型，以及词嵌入模型。n-gram 模型利用目标去掉音调符号的单词之前出现的一串词作为关键预测特征。分类模型则采用目标单词左右两侧的局部词窗。嵌入模型通过比较组合上下文向量与每个候选变体向量的相似度分数来进行决策。"
    },
    {
        "title": "Orchestrating Specialized Agents for Trustworthy Enterprise RAG",
        "summary": "Retrieval-Augmented Generation (RAG) shows promise for enterprise knowledge work, yet it often underperforms in high-stakes decision settings that require deep synthesis, strict traceability, and recovery from underspecified prompts. One-pass retrieval-and-write pipelines frequently yield shallow summaries, inconsistent grounding, and weak mechanisms for completeness verification. We introduce ADORE (Adaptive Deep Orchestration for Research in Enterprise), an agentic framework that replaces linear retrieval with iterative, user-steered investigation coordinated by a central orchestrator and a set of specialized agents. ADORE's key insight is that a structured Memory Bank (a curated evidence store with explicit claim-evidence linkage and section-level admissible evidence) enables traceable report generation and systematic checks for evidence completeness. Our contributions are threefold: (1) Memory-locked synthesis - report generation is constrained to a structured Memory Bank (Claim-Evidence Graph) with section-level admissible evidence, enabling traceable claims and grounded citations; (2) Evidence-coverage-guided execution - a retrieval-reflection loop audits section-level evidence coverage to trigger targeted follow-up retrieval and terminates via an evidence-driven stopping criterion; (3) Section-packed long-context grounding - section-level packing, pruning, and citation-preserving compression make long-form synthesis feasible under context limits. Across our evaluation suite, ADORE ranks first on DeepResearch Bench (52.65) and achieves the highest head-to-head preference win rate on DeepConsult (77.2%) against commercial systems.",
        "entry_id": "http://arxiv.org/abs/2601.18267v1",
        "pub_date": "2026-01-26",
        "translated_summary": "虽然检索增强生成（RAG）在企业级知识工作中展现出潜力，但在高风险决策场景——要求进行深度综合、严格可追溯并从不充分的提示中恢复——却常常表现不佳。单次“检索-生成”流水线往往只能产生浅层总结、证据引用不一致，且缺乏核查完整性的有效机制。我们提出 ADORE（企业研究自适应深度编排框架），它用迭代、用户引导的调查流程取代线性检索，通过一位中央协调器和若干专业智能体协同完成。ADORE的核心洞见在于：结构化记忆库（一个带有声明-证据显式映射并以“章节-级可采纳证据”为粒度管理的策划化证据仓库）可实现可追溯报告，并能系统性地验证证据完整性。我们的贡献有三：(1) 记忆锁定式综合——报告生成被约束到结构化记忆库（声明-证据图）且每章仅使用可采纳证据，实现声明可追溯、引文有根；(2) 证据覆盖引导的执行——检索-反思闭环先审章节级证据覆盖率，触发针对性补充检索，并以证据驱动的结束判据达成停；(3) 章节化长上下文接地——按章节打包、修剪并进行保留引文的压缩，使长篇综合在上下文长度限制内可行。在全面评估中，ADORE 在 DeepResearch Bench 上排名第一（52.65 分），并在 DeepConsult 上与商业系统对比时取得 77.2% 的头部偏好胜率。"
    },
    {
        "title": "GenCI: Generative Modeling of User Interest Shift via Cohort-based Intent Learning for CTR Prediction",
        "summary": "Click-through rate (CTR) prediction plays a pivotal role in online advertising and recommender systems. Despite notable progress in modeling user preferences from historical behaviors, two key challenges persist. First, exsiting discriminative paradigms focus on matching candidates to user history, often overfitting to historically dominant features and failing to adapt to rapid interest shifts. Second, a critical information chasm emerges from the point-wise ranking paradigm. By scoring each candidate in isolation, CTR models discard the rich contextual signal implied by the recalled set as a whole, leading to a misalignment where long-term preferences often override the user's immediate, evolving intent. To address these issues, we propose GenCI, a generative user intent framework that leverages semantic interest cohorts to model dynamic user preferences for CTR prediction. The framework first employs a generative model, trained with a next-item prediction (NTP) objective, to proactively produce candidate interest cohorts. These cohorts serve as explicit, candidate-agnostic representations of a user's immediate intent. A hierarchical candidate-aware network then injects this rich contextual signal into the ranking stage, refining them with cross-attention to align with both user history and the target item. The entire model is trained end-to-end, creating a more aligned and effective CTR prediction pipeline. Extensive experiments on three widely used datasets demonstrate the effectiveness of our approach.",
        "entry_id": "http://arxiv.org/abs/2601.18251v1",
        "pub_date": "2026-01-26",
        "translated_summary": "点击率（CTR）预测在网络广告和推荐系统中至关重要。尽管基于历史行为建模用户偏好的技术取得了显著进展，但仍面临两大核心难题。其一，现有的判别式范式侧重于将候选项目与用户历史匹配，极易过拟合于历史上占主导地位的特征，无法及时捕捉和适应兴趣的快速漂移。其二，逐点排序范式带来严峻的信息断崖：模型孤立地为每个候选打分，全然忽略召回结果整体蕴含的丰富上下文信号，从而造成长期偏好过度压制用户当下、瞬时的演化意图。\n\n为解决上述问题，我们提出 GenCI——一个利用语义兴趣同组（semantic interest cohorts）来建模动态用户意图的生成式 CTR 预测框架。该框架首先通过以“下一项目预测（Next-Item Prediction）”为目标的生成模型，主动产出候选兴趣同组。这些同组作为与用户当下意图相对应、且与任何具体候选项目无关的显式表征。随后，一个分层的候选感知网络在打分阶段注入该上下文信号，并通过交叉注意力将其与用户历史及目标项目共同对齐。整个模型端到端训练，构建起更高对齐度、更强效果的 CTR 预测流程。在三个公开基准数据集上的大量实验验证了该方法的有效性。"
    },
    {
        "title": "Generative Chain of Behavior for User Trajectory Prediction",
        "summary": "Modeling long-term user behavior trajectories is essential for understanding evolving preferences and enabling proactive recommendations. However, most sequential recommenders focus on next-item prediction, overlooking dependencies across multiple future actions. We propose Generative Chain of Behavior (GCB), a generative framework that models user interactions as an autoregressive chain of semantic behaviors over multiple future steps. GCB first encodes items into semantic IDs via RQ-VAE with k-means refinement, forming a discrete latent space that preserves semantic proximity. On top of this space, a transformer-based autoregressive generator predicts multi-step future behaviors conditioned on user history, capturing long-horizon intent transitions and generating coherent trajectories. Experiments on benchmark datasets show that GCB consistently outperforms state-of-the-art sequential recommenders in multi-step accuracy and trajectory consistency. Beyond these gains, GCB offers a unified generative formulation for capturing user preference evolution.",
        "entry_id": "http://arxiv.org/abs/2601.18213v1",
        "pub_date": "2026-01-26",
        "translated_summary": "对长期用户行为轨迹建模是理解用户偏好演化并实现主动推荐的关键。然而，现有序列推荐系统大多只关注“下一项”预测，忽视了用户在未来多个动作间的依赖关系。我们提出生成式行为链（Generative Chain of Behavior, GCB），一个将用户交互建模为多步未来语义行为自回归链的生成框架。GCB 首先利用配备 k-means 细化的 RQ-VAE 将物品编码成语义 ID，构建保留语义邻近性的离散潜空间。在此空间之上，基于 Transformer 的自回归生成器以用户历史为条件，预测多步未来行为，从而捕捉用户长期意图的转换并生成连贯的行为轨迹。在公开基准数据集上的实验表明，GCB 在多步预测准确率和轨迹一致性方面均显著优于现有序列推荐模型。除此之外，GCB 还提供了一种统一的生成式框架，可用于刻画用户偏好的动态演化。"
    },
    {
        "title": "PaperSearchQA: Learning to Search and Reason over Scientific Papers with RLVR",
        "summary": "Search agents are language models (LMs) that reason and search knowledge bases (or the web) to answer questions; recent methods supervise only the final answer accuracy using reinforcement learning with verifiable rewards (RLVR). Most RLVR search agents tackle general-domain QA, which limits their relevance to technical AI systems in science, engineering, and medicine. In this work we propose training agents to search and reason over scientific papers -- this tests technical question-answering, it is directly relevant to real scientists, and the capabilities will be crucial to future AI Scientist systems. Concretely, we release a search corpus of 16 million biomedical paper abstracts and construct a challenging factoid QA dataset called PaperSearchQA with 60k samples answerable from the corpus, along with benchmarks. We train search agents in this environment to outperform non-RL retrieval baselines; we also perform further quantitative analysis and observe interesting agent behaviors like planning, reasoning, and self-verification. Our corpus, datasets, and benchmarks are usable with the popular Search-R1 codebase for RLVR training and released on https://huggingface.co/collections/jmhb/papersearchqa. Finally, our data creation methods are scalable and easily extendable to other scientific domains.",
        "entry_id": "http://arxiv.org/abs/2601.18207v1",
        "pub_date": "2026-01-26",
        "translated_summary": "搜索智能体是一类基于语言模型（LM）的系统，它们通过推理并检索知识库（或网络）来回答问题；近期方法仅使用“可验证奖励的强化学习”（RLVR）针对最终答案的正确性进行监督。目前多数 RLVR 搜索智能体都面向通用领域问答，其相关性有限，难以覆盖科学、工程与医学等专业 AI 系统所需的场景。  \n本文提出训练智能体直接在科研文献中检索与推理——该任务不仅检验技术型问答能力，也与科研人员的真实需求紧密契合，对未来“AI 科学家”系统的能力构建至关重要。  \n\n具体而言，我们发布了一个包含 1600 万条生物医学论文摘要的检索语料库，并构建了一个高难度的事实验问答（factoid QA）数据集 PaperSearchQA，共 6 万条可完全在该语料内获得答案的样本及配套基准。我们在该环境中训练的搜索智能体显著优于非强化学习的检索基线；进一步定量分析表明，智能体展现了规划、推理与自验证等有趣行为。  \n\n我们的语料、数据集和基准均可与流行的 Search-R1 RLVR 代码库无缝配合使用，并在 https://huggingface.co/collections/jmhb/papersearchqa 全面开源。最后，所提出的数据构建流程高度可扩展，可轻松迁移到其他科学领域。"
    },
    {
        "title": "DMAP: Human-Aligned Structural Document Map for Multimodal Document Understanding",
        "summary": "Existing multimodal document question-answering (QA) systems predominantly rely on flat semantic retrieval, representing documents as a set of disconnected text chunks and largely neglecting their intrinsic hierarchical and relational structures. Such flattening disrupts logical and spatial dependencies - such as section organization, figure-text correspondence, and cross-reference relations, that humans naturally exploit for comprehension. To address this limitation, we introduce a document-level structural Document MAP (DMAP), which explicitly encodes both hierarchical organization and inter-element relationships within multimodal documents. Specifically, we design a Structured-Semantic Understanding Agent to construct DMAP by organizing textual content together with figures, tables, charts, etc. into a human-aligned hierarchical schema that captures both semantic and layout dependencies. Building upon this representation, a Reflective Reasoning Agent performs structure-aware and evidence-driven reasoning, dynamically assessing the sufficiency of retrieved context and iteratively refining answers through targeted interactions with DMAP. Extensive experiments on MMDocQA benchmarks demonstrate that DMAP yields document-specific structural representations aligned with human interpretive patterns, substantially enhancing retrieval precision, reasoning consistency, and multimodal comprehension over conventional RAG-based approaches. Code is available at https://github.com/Forlorin/DMAP",
        "entry_id": "http://arxiv.org/abs/2601.18203v1",
        "pub_date": "2026-01-26",
        "translated_summary": "现有的多模态文档问答（QA）系统主要依靠扁平化的语义检索，将文档视为一组互不关联的文本块，而忽略了其固有的层级和关系结构。这种扁平化破坏了人类在理解过程中自然依赖的逻辑与空间关联，如章节组织、图文对应及跨引用关系。为弥补这一缺陷，我们提出文档级结构表示——Document MAP（DMAP），显式编码多模态文档内部的层级结构与元素间关系。为此，我们设计了一种“结构-语义理解 Agent”，按照人类可理解的层级模式，将文本内容、图表、图示等有机组织起来，捕获其语义与版面依赖。在此基础上，再引入“反思推理 Agent”，在结构感知和证据驱动下进行推理，动态评估检索到的上下文是否充分，并通过对 DMAP 的定向交互不断精炼答案。我们在 MMDocQA 系列基准上进行的广泛实验表明，DMAP 生成的文档特定结构表示与人类理解模式高度一致，在检索精度、推理连贯性和多模态理解方面显著优于传统RAG方法。代码开源地址：https://github.com/Forlorin/DMAP"
    },
    {
        "title": "Think When Needed: Model-Aware Reasoning Routing for LLM-based Ranking",
        "summary": "Large language models (LLMs) are increasingly applied to ranking tasks in retrieval and recommendation. Although reasoning prompting can enhance ranking utility, our preliminary exploration reveals that its benefits are inconsistent and come at a substantial computational cost, suggesting that when to reason is as crucial as how to reason. To address this issue, we propose a reasoning routing framework that employs a lightweight, plug-and-play router head to decide whether to use direct inference (Non-Think) or reasoning (Think) for each instance before generation. The router head relies solely on pre-generation signals: i) compact ranking-aware features (e.g., candidate dispersion) and ii) model-aware difficulty signals derived from a diagnostic checklist reflecting the model's estimated need for reasoning. By leveraging these features before generation, the router outputs a controllable token that determines whether to apply the Think mode. Furthermore, the router can adaptively select its operating policy along the validation Pareto frontier during deployment, enabling dynamic allocation of computational resources toward instances most likely to benefit from Think under varying system constraints. Experiments on three public ranking datasets with different scales of open-source LLMs show consistent improvements in ranking utility with reduced token consumption (e.g., +6.3\\% NDCG@10 with -49.5\\% tokens on MovieLens with Qwen3-4B), demonstrating reasoning routing as a practical solution to the accuracy-efficiency trade-off.",
        "entry_id": "http://arxiv.org/abs/2601.18146v1",
        "pub_date": "2026-01-26",
        "translated_summary": "大型语言模型（LLM）正日益被用于检索与推荐中的排序任务。尽管推理式提示能够提升排序效用，我们初探发现其增益并不稳定，且伴随高昂的计算开销，从而表明“何时推理”与“如何推理”同等关键。针对该问题，本文提出一种推理路由框架：以轻量级、即插即用的路由头在生成前为每个实例决策采用直接推理（Non-Think）还是链式推理（Think）。路由头仅依赖两类生成前信号：1) 紧凑的排序感知特征（如候选项分散度）；2) 模型感知的难度信号——由反映模型对推理需求估计的诊断核查表导出。借助这些特征，路由头在生成前输出一个可控标记，指引是否进入Think模式。此外，路由头可在验证 Pareto 前沿上自适应选择运行策略，在系统约束变化时动态将计算资源分配给最有可能因推理而受益的实例。在三个公开排序数据集上，使用多种开源 LLM 进行实验，均证实本框架在提升排序效果的同时显著降低 token 消耗（如在 MovieLens 上使用 Qwen3-4B，NDCG@10 提升 6.3%，token 减少 49.5%），展示了推理路由在精度-效率权衡中的实用价值。"
    },
    {
        "title": "Enhancing LLM-based Recommendation with Preference Hint Discovery from Knowledge Graph",
        "summary": "LLMs have garnered substantial attention in recommendation systems. Yet they fall short of traditional recommenders when capturing complex preference patterns. Recent works have tried integrating traditional recommendation embeddings into LLMs to resolve this issue, yet a core gap persists between their continuous embedding and discrete semantic spaces. Intuitively, textual attributes derived from interactions can serve as critical preference rationales for LLMs' recommendation logic. However, directly inputting such attribute knowledge presents two core challenges: (1) Deficiency of sparse interactions in reflecting preference hints for unseen items; (2) Substantial noise introduction from treating all attributes as hints. To this end, we propose a preference hint discovery model based on the interaction-integrated knowledge graph, enhancing LLM-based recommendation. It utilizes traditional recommendation principles to selectively extract crucial attributes as hints. Specifically, we design a collaborative preference hint extraction schema, which utilizes semantic knowledge from similar users' explicit interactions as hints for unseen items. Furthermore, we develop an instance-wise dual-attention mechanism to quantify the preference credibility of candidate attributes, identifying hints specific to each unseen item. Using these item- and user-based hints, we adopt a flattened hint organization method to shorten input length and feed the textual hint information to the LLM for commonsense reasoning. Extensive experiments on both pair-wise and list-wise recommendation tasks verify the effectiveness of our proposed framework, indicating an average relative improvement of over 3.02% against baselines.",
        "entry_id": "http://arxiv.org/abs/2601.18096v1",
        "pub_date": "2026-01-26",
        "translated_summary": "大语言模型（LLM）在推荐系统领域虽备受瞩目，但其在捕捉复杂用户偏好模式方面仍不及传统推荐器。近期研究尝试将传统推荐的连续嵌入直接注入LLM，却难以弥补连续语义向量与离散文本符号之间的本质鸿沟。直观上，由交互行为衍生的文本属性可成为LLM理解用户偏好的关键线索，然而将这类属性直接注入模型会引发两大挑战：（1）稀疏交互难以在未见新商品上提供充分的偏好信号；（2）若把所有属性一概视作提示，会引入显著噪声。\n\n为此，本文提出一种基于交互式知识图谱的“偏好提示发现”模型，用以增强LLM 的推荐能力。该模型继承传统协同过滤思想，有选择性地提取出最具影响力的属性作为提示信息。具体而言，我们设计了“协同式偏好提示提取”范式：用相似用户在与新商品相似或关联商品上的显式交互，来生成面向未见商品的语义提示。此外，我们提出实例化的“双重注意力”机制，为每个候选属性计算其在此特定未观测商品上的“偏好可信度”，从而过滤出真正有价值的提示。\n\n随后，我们采用扁平化的提示组织方式压缩输入长度，将精炼后的文本提示注入LLM开展常识推理。我们在成对排序与列表排序两类推荐任务上的大量实验表明，本框架相较基线平均相对提升达 3.02% 以上，验证了其有效性。"
    },
    {
        "title": "Post-Training Denoising of User Profiles with LLMs in Collaborative Filtering Recommendation",
        "summary": "Implicit feedback -- the main data source for training Recommender Systems (RSs) -- is inherently noisy and has been shown to negatively affect recommendation effectiveness. Denoising has been proposed as a method for removing noisy implicit feedback and improving recommendations. Prior work has focused on in-training denoising, however this requires additional data, changes to the model architecture and training procedure or fine-tuning, all of which can be costly and data hungry. In this work, we focus on post-training denoising. Different from in-training denoising, post-training denoising does not involve changing the architecture of the model nor its training procedure, and does not require additional data. Specifically, we present a method for post-training denoising user profiles using Large Language Models (LLMs) for Collaborative Filtering (CF) recommendations. Our approach prompts LLMs with (i) a user profile (user interactions), (ii) a candidate item, and (iii) its rank as given by the CF recommender, and asks the LLM to remove items from the user profile to improve the rank of the candidate item. Experiments with a state-of-the-art CF recommender and 4 open and closed source LLMs in 3 datasets show that our denoising yields improvements up to 13% in effectiveness over the original user profiles. Our code is available at https://github.com/edervishaj/denoising-user-profiles-LLM.",
        "entry_id": "http://arxiv.org/abs/2601.18009v1",
        "pub_date": "2026-01-25",
        "translated_summary": "隐式反馈——训练推荐系统（RSs）时的最主要数据来源——与生俱来地带噪声，且已被证明会降低推荐的精度。为剔除这些噪声并提升效果，去噪技术应运而生。已有研究普遍采用“训练中”去噪策略，但这需要额外数据、修改模型架构与训练流程或在训练后进行微调，代价高昂且对数据量敏感。\n\n本文提出“训练后”去噪，与“训练中”的策略截然不同：既不改动模型架构与训练流程，也不依赖额外数据。具体而言，我们利用大语言模型（LLM），在协同过滤（CF）推荐场景中实现训练后的用户档案去噪。方法很简单：把（i）用户档案（即交互记录）、（ii）待推荐的候选物品，以及（iii）CF模型给出的该物品排名一起提示给LLM，并要求LLM从用户档案中删除某些物品，以便提升该候选物品的排名。\n\n我们在三种数据集上，用一款当前最优的CF推荐器与4个开源及闭源LLM进行了实验。结果显示，经过去噪后的用户档案，其推荐效果相比原始档案提升最高达13%。开源代码已发布：https://github.com/edervishaj/denoising-user-profiles-LLM"
    },
    {
        "title": "MedViz: An Agent-based, Visual-guided Research Assistant for Navigating Biomedical Literature",
        "summary": "Biomedical researchers face increasing challenges in navigating millions of publications in diverse domains. Traditional search engines typically return articles as ranked text lists, offering little support for global exploration or in-depth analysis. Although recent advances in generative AI and large language models have shown promise in tasks such as summarization, extraction, and question answering, their dialog-based implementations are poorly integrated with literature search workflows. To address this gap, we introduce MedViz, a visual analytics system that integrates multiple AI agents with interactive visualization to support the exploration of the large-scale biomedical literature. MedViz combines a semantic map of millions of articles with agent-driven functions for querying, summarizing, and hypothesis generation, allowing researchers to iteratively refine questions, identify trends, and uncover hidden connections. By bridging intelligent agents with interactive visualization, MedViz transforms biomedical literature search into a dynamic, exploratory process that accelerates knowledge discovery.",
        "entry_id": "http://arxiv.org/abs/2601.20709v1",
        "pub_date": "2026-01-28",
        "translated_summary": "生物医学研究人员在跨领域浏览数以百万计的文献时面临着日益增长的挑战。传统的搜索引擎通常只会以文本列表的形式返回按排名排序的文章，既无法支持全局探索，也难以为深度分析提供帮助。虽然在总结、信息抽取和问答等任务上，最新的生成式 AI 和大语言模型已显示出巨大潜力，但其基于对话的实现方式尚未很好地融入文献检索流程。为了解决这一缺口，我们提出了 MedViz——一套结合多智能体 AI 与交互可视化的视觉分析系统，用于大规模生物医学文献的探索。MedViz 将数百万篇文章构建成语义地图，并集成由智能体驱动的查询、总结与假设生成功能，使研究人员能够迭代地细化问题、识别趋势并挖掘隐性关联。通过把智能体与交互可视化紧密结合，MedViz 将传统的生物医学文献检索转变为一个动态而可探索的过程，从而加速知识的发现。"
    },
    {
        "title": "Overview of the TREC 2025 Tip-of-the-Tongue track",
        "summary": "Tip-of-the-tongue (ToT) known-item retrieval involves re-finding an item for which the searcher does not reliably recall an identifier. ToT information requests (or queries) are verbose and tend to include several complex phenomena, making them especially difficult for existing information retrieval systems. The TREC 2025 ToT track focused on a single ad-hoc retrieval task. This year, we extended the track to general domain and incorporated different sets of test queries from diverse sources, namely from the MS-ToT dataset, manual topic development, and LLM-based synthetic query generation. This year, 9 groups (including the track coordinators) submitted 32 runs.",
        "entry_id": "http://arxiv.org/abs/2601.20671v1",
        "pub_date": "2026-01-28",
        "translated_summary": "舌尖现象（Tip-of-the-tongue，ToT）的已知项检索指的是：用户需要重新找到某个对象，却无法可靠回忆其标识符。此类 ToT 信息需求（查询）表述冗长，常涵盖多种复杂现象，致使传统信息检索系统难以处理。TREC 2025 ToT 测试任务专设一项 ad-hoc 检索任务，今年我们将其扩展至通用领域，并从多元来源纳入测试查询集，包括 MS-ToT 数据集、人工开发的题目以及基于大语言模型的合成查询生成。今年共有 9 组单位（含任务协调方）提交了共 32 组结果。"
    },
    {
        "title": "TGSBM: Transformer-Guided Stochastic Block Model for Link Prediction",
        "summary": "Link prediction is a cornerstone of the Web ecosystem, powering applications from recommendation and search to knowledge graph completion and collaboration forecasting. However, large-scale networks present unique challenges: they contain hundreds of thousands of nodes and edges with heterogeneous and overlapping community structures that evolve over time. Existing approaches face notable limitations: traditional graph neural networks struggle to capture global structural dependencies, while recent graph transformers achieve strong performance but incur quadratic complexity and lack interpretable latent structure. We propose \\textbf{TGSBM} (Transformer-Guided Stochastic Block Model), a framework that integrates the principled generative structure of Overlapping Stochastic Block Models with the representational power of sparse Graph Transformers. TGSBM comprises three main components: (i) \\emph{expander-augmented sparse attention} that enables near-linear complexity and efficient global mixing, (ii) a \\emph{neural variational encoder} that infers structured posteriors over community memberships and strengths, and (iii) a \\emph{neural edge decoder} that reconstructs links via OSBM's generative process, preserving interpretability. Experiments across diverse benchmarks demonstrate competitive performance (mean rank 1.6 under HeaRT protocol), superior scalability (up to $6\\times$ faster training), and interpretable community structures. These results position TGSBM as a practical approach that strikes a balance between accuracy, efficiency, and transparency for large-scale link prediction.",
        "entry_id": "http://arxiv.org/abs/2601.20646v1",
        "pub_date": "2026-01-28",
        "translated_summary": "链路预测是 Web 生态系统的基石，支撑着从推荐与搜索，到知识图谱补全与合作预测等众多应用。然而，大规模网络带来了独特挑战：它们包含数十万量级的节点与边，其社区结构多元且重叠，并随时间演化。现有方法受两大制约：传统图神经网络难以捕捉全局结构性依赖；新兴图变换器虽性能强劲，却带来二次复杂度，且潜藏结构缺乏可解释性。\n\n我们提出 **TGSBM**（Transformer 引导的随机块模型）框架，将可解释的**重叠随机块模型（OSBM）**的生成式结构与**稀疏图变换器**的表征能力有机结合。TGSBM 由三大模块构成：\n1) **扩展图增强的稀疏注意力**，将近线性复杂度的全局混合能力付诸实践；\n2) **神经变分编码器**，推断节点所属社区及其强度的结构化后验；\n3) **神经边解码器**，通过 OSBM 的生成流程重构链接，从而保留可解释性。\n\n在多种基准数据集上的实验表明，TGSBM 在 HeaRT 协议下平均排名第 1.6，训练速度提升最高达 6 倍，并能显式地揭示社区结构。这些结果使 TGSBM 成为兼顾精度、效率和可解释性的大规模链路预测实用方案。"
    },
    {
        "title": "When Vision Meets Texts in Listwise Reranking",
        "summary": "Recent advancements in information retrieval have highlighted the potential of integrating visual and textual information, yet effective reranking for image-text documents remains challenging due to the modality gap and scarcity of aligned datasets. Meanwhile, existing approaches often rely on large models (7B to 32B parameters) with reasoning-based distillation, incurring unnecessary computational overhead while primarily focusing on textual modalities. In this paper, we propose Rank-Nexus, a multimodal image-text document reranker that performs listwise qualitative reranking on retrieved lists incorporating both images and texts. To bridge the modality gap, we introduce a progressive cross-modal training strategy. We first train modalities separately: leveraging abundant text reranking data, we distill knowledge into the text branch. For images, where data is scarce, we construct distilled pairs from multimodal large language model (MLLM) captions on image retrieval benchmarks. Subsequently, we distill a joint image-text reranking dataset. Rank-Nexus achieves outstanding performance on text reranking benchmarks (TREC, BEIR) and the challenging image reranking benchmark (INQUIRE, MMDocIR), using only a lightweight 2B pretrained visual-language model. This efficient design ensures strong generalization across diverse multimodal scenarios without excessive parameters or reasoning overhead.",
        "entry_id": "http://arxiv.org/abs/2601.20623v1",
        "pub_date": "2026-01-28",
        "translated_summary": "信息检索的最新进展表明，融合视觉与文本信息具有巨大潜力。然而，由于模态差异以及对齐数据稀缺，针对图文混合文档的重排仍面临挑战。现有方法通常依赖 7B–32B 的超大模型，并采用基于推理的知识蒸馏，既带来冗余算力开销，又主要聚焦于纯文本模态。\n\n本文提出 Rank-Nexus，一种轻量级 2B 参数的图文文档重排器，能够对包含图像与文本的候选列表进行列表级质量重排。为弥合模态鸿沟，我们设计了渐进式跨模态训练策略：首先分别训练两种模态——利用丰富的文本重排数据，将知识蒸馏至文本分支；针对数据稀缺但重要的图像分支，则在图像检索基准上，借助多模态大语言模型 (MLLM) 对图像生成描述，从而构造蒸馏样本对。随后，两路并进，提炼出联合图文重排训练集。\n\n实验结果显示，Rank-Nexus 不仅在文本重排基准（TREC、BEIR）上表现优异，在极具挑战性的图像重排基准（INQUIRE、MMDocIR）上亦同样出色。无需庞大参数量或昂贵推理开销，Rank-Nexus 即可在多模态场景中实现强泛化。"
    },
    {
        "title": "On Every Note a Griff: Looking for a Useful Representation of Basso Continuo Performance Style",
        "summary": "Basso continuo is a baroque improvisatory accompaniment style which involves improvising multiple parts above a given bass line in a musical score on a harpsichord or organ. Basso continuo is not merely a matter of history; moreover, it is a historically inspired living practice, and The Aligned Continuo Dataset (ACoRD) records the first sample of modern-day basso continuo playing in the symbolic domain. This dataset, containing 175 MIDI recordings of 5 basso continuo scores performed by 7 players, allows us to start observing and analyzing the variety that basso continuo improvisation brings. A recently proposed basso continuo performance-to-score alignment system provides a way of mapping improvised performance notes to score notes. In order to study aligned basso continuo performances, we need an appropriate feature representation. We propose griff, a representation inspired by historical basso continuo treatises. It enables us to encode both pitch content and structure of a basso continuo realization in a transposition-invariant way. Griffs are directly extracted from aligned basso continuo performances by grouping together performance notes aligned to the same score note in a onset-time ordered way, and they provide meaningful tokens that form a feature space in which we can analyze basso continuo performance styles. We statistically describe griffs extracted from the ACoRD dataset recordings, and show in two experiments how griffs can be used for statistical analysis of individuality of different players' basso continuo performance styles. We finally present an argument why it is desirable to preserve the structure of a basso continuo improvisation in order to conduct a refined analysis of personal performance styles of individual basso continuo practitioners, and why griffs can provide a meaningful historically informed feature space worthy of a more robust empirical validation.",
        "entry_id": "http://arxiv.org/abs/2601.20478v1",
        "pub_date": "2026-01-28",
        "translated_summary": "通奏低音是一种巴洛克即兴伴奏方式，演奏者在管风琴或羽管键琴上，依据乐谱给出的固定低音线条，即兴叠加多声部。通奏低音并非仅止于历史，而是一种仍在持续的“活传统”。对齐通奏低音数据集（ACoRD）首次在符号领域记录了当代通奏低音的实际演奏，包含 5 首通奏低音乐谱的 175 个 MIDI 演奏录音，由 7 位演奏者完成，为我们观察并量化即兴带来的多样性提供了样本。\n\n新近提出的“通奏低音演奏—乐谱对齐系统”可将即兴音符映射到对应的乐谱音符。为了研究对齐后的通奏低音演奏，我们需要一种合适的特征表示。本文提出“griff”：一种受历史通奏低音理论启发的符号化表示，能够以移调不变的方式编码通奏低音即兴的音高内容与结构。Griff 直接从对齐后的演奏中提取：将与同一乐谱音符对应的演奏音符按时值排序并组合成符号块，从而获得有意义的令牌，由此构成一个可用于分析通奏低音演奏风格的特征空间。\n\n我们统计分析 ACoRD 录音提取的 griff，并通过两项实验展示其如何区分不同演奏者的个人风格。最后论证：若要进行更精细的个人风格分析，就必须保留通奏低音即兴的内部结构；而 griff 则提供了一条兼具历史依据且值得进一步实证检验的特征化路径。"
    },
    {
        "title": "Eliminating Hallucination in Diffusion-Augmented Interactive Text-to-Image Retrieval",
        "summary": "Diffusion-Augmented Interactive Text-to-Image Retrieval (DAI-TIR) is a promising paradigm that improves retrieval performance by generating query images via diffusion models and using them as additional ``views'' of the user's intent. However, these generative views can be incorrect because diffusion generation may introduce hallucinated visual cues that conflict with the original query text. Indeed, we empirically demonstrate that these hallucinated cues can substantially degrade DAI-TIR performance. To address this, we propose Diffusion-aware Multi-view Contrastive Learning (DMCL), a hallucination-robust training framework that casts DAI-TIR as joint optimization over representations of query intent and the target image. DMCL introduces semantic-consistency and diffusion-aware contrastive objectives to align textual and diffusion-generated query views while suppressing hallucinated query signals. This yields an encoder that acts as a semantic filter, effectively mapping hallucinated cues into a null space, improving robustness to spurious cues and better representing the user's intent. Attention visualization and geometric embedding-space analyses corroborate this filtering behavior. Across five standard benchmarks, DMCL delivers consistent improvements in multi-round Hits@10, reaching as high as 7.37\\% over prior fine-tuned and zero-shot baselines, which indicates it is a general and robust training framework for DAI-TIR.",
        "entry_id": "http://arxiv.org/abs/2601.20391v1",
        "pub_date": "2026-01-28",
        "translated_summary": "扩散增强交互式文本到图像检索（DAI-TIR）是一种前景广阔的范式：它通过扩散模型生成查询图像、并将这些图像作为用户意图的额外“视图”，从而提升检索性能。然而，这类生成视图可能并不正确——扩散模型生成的视觉线索会出现幻觉，与原始查询文本产生冲突。我们在实验中证实的幻觉线索会显著拉低 DAI-TIR 性能。为此，我们提出“扩散感知的多视角对比学习”（DMCL），一种对幻觉具备鲁棒性的训练框架，将 DAI-TIR 视为对“查询意图”表示与目标图像表示的联合优化。DMCL 引入语义一致性目标和扩散感知对比目标，使文本与扩散生成的查询视图对齐，同时抑制幻觉查询信号。由此得到的编码器充当语义过滤器，将幻觉线索有效映射到“空”空间，从而提高对虚假线索的鲁棒性，并更准确地传达用户意图。注意力可视化和嵌入空间几何分析都验证了该过滤机制。在五个标准基准数据集上，DMCL 在多轮检索 Hits@10 指标上带来持续提升，相比此前的微调与零样本基线最高可提高 7.37%，证明 DMCL 是一种通用且稳健的 DAI-TIR 训练框架。"
    },
    {
        "title": "Less is More: Benchmarking LLM Based Recommendation Agents",
        "summary": "Large Language Models (LLMs) are increasingly deployed for personalized product recommendations, with practitioners commonly assuming that longer user purchase histories lead to better predictions. We challenge this assumption through a systematic benchmark of four state of the art LLMs GPT-4o-mini, DeepSeek-V3, Qwen2.5-72B, and Gemini 2.5 Flash across context lengths ranging from 5 to 50 items using the REGEN dataset.\n  Surprisingly, our experiments with 50 users in a within subject design reveal no significant quality improvement with increased context length. Quality scores remain flat across all conditions (0.17--0.23). Our findings have significant practical implications: practitioners can reduce inference costs by approximately 88\\% by using context (5--10 items) instead of longer histories (50 items), without sacrificing recommendation quality. We also analyze latency patterns across providers and find model specific behaviors that inform deployment decisions. This work challenges the existing ``more context is better'' paradigm and provides actionable guidelines for cost effective LLM based recommendation systems.",
        "entry_id": "http://arxiv.org/abs/2601.20316v1",
        "pub_date": "2026-01-28",
        "translated_summary": "大型语言模型（LLM）越来越多地被用于个性化商品推荐，业界普遍假设用户购买历史越长，预测效果越好。我们在 REGEN 数据集上对四种最先进的 LLM（GPT-4o-mini、DeepSeek-V3、Qwen2.5-72B 与 Gemini 2.5 Flash）进行系统基准测试，考察的上下文长度从 5 到 50 条商品不等，直接质疑了这一假设。\n\n出人意料的是，在采用 50 名用户的被试内设计方案中，我们发现随着上下文长度增加，推荐质量并未显著提升：各条件下的质量得分始终维持在 0.17–0.23 之间。该结果具有重要现实意义：从业者只需使用 5–10 条商品的短上下文，就能在不牺牲推荐质量的前提下把推理成本降低约 88%。我们进一步分析了不同提供商的延迟模式，揭示了因模型而异的行为特征，为部署决策提供依据。\n\n本研究打破了“上下文越长越好”的传统信条，为打造经济高效的 LLM 推荐系统提供了可操作的指导。"
    },
    {
        "title": "One Word is Enough: Minimal Adversarial Perturbations for Neural Text Ranking",
        "summary": "Neural ranking models (NRMs) achieve strong retrieval effectiveness, yet prior work has shown they are vulnerable to adversarial perturbations. We revisit this robustness question with a minimal, query-aware attack that promotes a target document by inserting or substituting a single, semantically aligned word - the query center. We study heuristic and gradient-guided variants, including a white-box method that identifies influential insertion points. On TREC-DL 2019/2020 with BERT and monoT5 re-rankers, our single-word attacks achieve up to 91% success while modifying fewer than two tokens per document on average, achieving competitive rank and score boosts with far fewer edits under a comparable white-box setup to ensure fair evaluation against PRADA. We also introduce new diagnostic metrics to analyze attack sensitivity beyond aggregate success rates. Our analysis reveals a Goldilocks zone in which mid-ranked documents are most vulnerable. These findings demonstrate practical risks and motivate future defenses for robust neural ranking.",
        "entry_id": "http://arxiv.org/abs/2601.20283v1",
        "pub_date": "2026-01-28",
        "translated_summary": "神经排序模型（NRMs）虽然取得了优异的检索效果，但已有研究表明它们容易受到对抗扰动的影响。本文用一种极简且依赖查询的攻击重新审视其鲁棒性问题：通过插入或替换一个与查询高度语义对齐的单词——查询中心词——来提升目标文档的排名。我们研究了启发式与基于梯度的多种变体，包括可访问模型的白盒方法，可精确定位最具影响的插入位置。在 TREC-DL 2019/2020 数据集上使用 BERT 和 monoT5 重排器的实验表明，单次单词攻击成功率最高可达 91%，平均每篇文档修改不到两个 token；在与先前 PRADA 一致的公平白盒设置下，我们的方法以远少于对方的编辑次数就达到了相当的排名与得分提升。此外，我们还提出新的诊断指标，突破整体成功率的局限，深入分析模型对攻击的敏感度。分析结果显示存在一个“金发女孩区”（Goldilocks zone）：中等排名的文档最易受到攻击。这些发现揭示了神经排序模型在实际中的风险，为推进鲁棒神经排序的防御机制提供了动机。"
    },
    {
        "title": "MALLOC: Benchmarking the Memory-aware Long Sequence Compression for Large Sequential Recommendation",
        "summary": "The scaling law, which indicates that model performance improves with increasing dataset and model capacity, has fueled a growing trend in expanding recommendation models in both industry and academia. However, the advent of large-scale recommenders also brings significantly higher computational costs, particularly under the long-sequence dependencies inherent in the user intent of recommendation systems. Current approaches often rely on pre-storing the intermediate states of the past behavior for each user, thereby reducing the quadratic re-computation cost for the following requests. Despite their effectiveness, these methods often treat memory merely as a medium for acceleration, without adequately considering the space overhead it introduces. This presents a critical challenge in real-world recommendation systems with billions of users, each of whom might initiate thousands of interactions and require massive memory for state storage. Fortunately, there have been several memory management strategies examined for compression in LLM, while most have not been evaluated on the recommendation task. To mitigate this gap, we introduce MALLOC, a comprehensive benchmark for memory-aware long sequence compression. MALLOC presents a comprehensive investigation and systematic classification of memory management techniques applicable to large sequential recommendations. These techniques are integrated into state-of-the-art recommenders, enabling a reproducible and accessible evaluation platform. Through extensive experiments across accuracy, efficiency, and complexity, we demonstrate the holistic reliability of MALLOC in advancing large-scale recommendation. Code is available at https://anonymous.4open.science/r/MALLOC.",
        "entry_id": "http://arxiv.org/abs/2601.20234v1",
        "pub_date": "2026-01-28",
        "translated_summary": "随着数据集与模型规模的扩大，推荐系统在学术与工业界均兴起了一股“扩张”热潮。然而，超大规模的推荐模型也带来了前所未有的计算开销，尤其是对必须处理长序列用户意图的场景更为突出。为缓解这一问题，主流做法预先将每个用户的历史行为中间状态缓存下来，从而将后续请求的二次重复计算成本降至线性。这些方法虽有效，却普遍把记忆体仅视为加速工具，忽视其带来的庞大空间开销——在真实系统中，面对数十亿用户、每人可能产生数以千计交互的情境，其存储需求将呈指数级膨胀。值得庆幸的是，关于大语言模型（LLM）的压缩式记忆管理策略近年已有诸多研究，但其在推荐任务上的效果仍缺乏系统验证。\n\n为填补这一空白，我们提出 MALLOC：一个面向记忆高效的长序列压缩的综合基准。MALLOC 首次对可应用于大规模序列推荐系统的各类记忆管理技术进行了全面梳理、系统分类，并将其无缝嵌入当前最先进的推荐模型，构建出可复现且易于使用的评估平台。通过对准确性、效率和复杂度三大维度的详尽实验，我们验证了 MALLOC 在推进超大规模推荐系统稳健发展方面的整体可靠性。\n\n代码开源：https://anonymous.4open.science/r/MALLOC"
    },
    {
        "title": "Towards End-to-End Alignment of User Satisfaction via Questionnaire in Video Recommendation",
        "summary": "Short-video recommender systems typically optimize ranking models using dense user behavioral signals, such as clicks and watch time. However, these signals are only indirect proxies of user satisfaction and often suffer from noise and bias. Recently, explicit satisfaction feedback collected through questionnaires has emerged as a high-quality direct alignment supervision, but is extremely sparse and easily overwhelmed by abundant behavioral data, making it difficult to incorporate into online recommendation models. To address these challenges, we propose a novel framework which is towards End-to-End Alignment of user Satisfaction via Questionaire, named EASQ, to enable real-time alignment of ranking models with true user satisfaction. Specifically, we first construct an independent parameter pathway for sparse questionnaire signals by combining a multi-task architecture and a lightweight LoRA module. The multi-task design separates sparse satisfaction supervision from dense behavioral signals, preventing the former from being overwhelmed. The LoRA module pre-inject these preferences in a parameter-isolated manner, ensuring stability in the backbone while optimizing user satisfaction. Furthermore, we employ a DPO-based optimization objective tailored for online learning, which aligns the main model outputs with sparse satisfaction signals in real time. This design enables end-to-end online learning, allowing the model to continuously adapt to new questionnaire feedback while maintaining the stability and effectiveness of the backbone. Extensive offline experiments and large-scale online A/B tests demonstrate that EASQ consistently improves user satisfaction metrics across multiple scenarios. EASQ has been successfully deployed in a production short-video recommendation system, delivering significant and stable business gains.",
        "entry_id": "http://arxiv.org/abs/2601.20215v1",
        "pub_date": "2026-01-28",
        "translated_summary": "短视频推荐系统通常以用户的密集行为信号（如点击与观看时长）来训练排序模型。但这些信号只是用户满意度的间接代理，常常伴随噪声与偏差。近年，通过问卷收集的显式满意度反馈被视为高质量直接对齐监督，却极度稀疏，易被大量行为数据淹没，难以融入在线推荐模型。为应对此挑战，本文提出“端到端问卷满意度对齐”框架——EASQ，使排序模型实时逼近用户真实满意度。具体地，我们通过多任务架构结合轻量级 LoRA 模块，为稀疏问卷信号建立独立参数通道。多任务设计把稀少满意度监督与密集行为信号隔离，防止前者被淹没；LoRA 模块以参数隔离方式预先“注入”问卷偏好，既保障主干网络稳定，又提升满意度。进一步，我们设计面向在线学习的 DPO 优化目标，实时令主模型输出对齐稀疏满意度信号，实现端到端的在线更新，在新问卷回流时持续进化而不失稳定性。大量离线实验和大规模在线 A/B 验证表明，EASQ能在多场景中显著提高满意度指标。EASQ已在生产级短视频推荐系统落地，带来了显著且稳定的业务增益。"
    },
    {
        "title": "High-Resolution Mapping of Port Dynamics from Open-Access AIS Data in Tokyo Bay",
        "summary": "Knowledge about vessel activity in port areas and around major industrial zones provides insights into economic trends, supports decision-making for shipping and port operators, and contributes to maritime safety. Vessel data from terrestrial receivers of the Automatic Identification System (AIS) have become increasingly openly available, and we demonstrate that such data can be used to infer port activities at high resolution and with precision comparable to official statistics. We analyze open-access AIS data from a three-month period in 2024 for Tokyo Bay, located in Japan's most densely populated urban region. Accounting for uneven data coverage, we reconstruct vessel activity in Tokyo Bay at $\\sim\\,$30~m resolution and identify 161 active berths across seven major port areas in the bay. During the analysis period, we find an average of $35\\pm17_{\\text{stat}}$ vessels moving within the bay at any given time, and $293\\pm22_{\\text{stat}}+65_{\\text{syst}}-10_{\\text{syst}}$ vessels entering or leaving the bay daily, with an average gross tonnage of $11{,}860^{+280}_{-\\;\\,50}$. These figures indicate an accelerating long-term trend toward fewer but larger vessels in Tokyo Bay's commercial traffic. Furthermore, we find that in dense urban environments, radio shadows in vessel AIS data can reveal the precise locations of inherently passive receiver stations.",
        "entry_id": "http://arxiv.org/abs/2601.20211v1",
        "pub_date": "2026-01-28",
        "translated_summary": "了解港口区域和主要工业地带周边船舶的动态，能够洞察经济趋势，为航运与港口运营商的决策提供支持，并对保障海上安全具有重要意义。来自自动识别系统（AIS）地面接收机的船舶数据日趋开放可用；我们证明，依据这类开放数据可以高分辨率地推断港口活动，其结果精度能与官方统计相媲美。我们以日本人口最稠密的都市区域——东京湾2024年历时三个月的公开AIS数据为例展开分析。针对数据覆盖不均的问题，我们重建了东京湾内约30米分辨率的船舶活动图景，并在港湾七大主要港区识别出161个活跃泊位。\n\n在分析时段内，湾内平均每次同时有 35±17（统计误差）艘船舶移动；每天进出湾区的船舶数量为 293±22（统计误差）+65（系统涨差）-10（系统跌差）艘，其平均总吨位为 11,860（上限误差+280，下限误差-50）。上述数字显示，东京湾商业运输的长期趋势正在加速向“船数减少、吨位增大”演变。此外，在人口稠密的都市环境中，AIS无线电阴影区的出现可反推出原本被动的接收站精准位置。"
    },
    {
        "title": "MERGE: Next-Generation Item Indexing Paradigm for Large-Scale Streaming Recommendation",
        "summary": "Item indexing, which maps a large corpus of items into compact discrete representations, is critical for both discriminative and generative recommender systems, yet existing Vector Quantization (VQ)-based approaches struggle with the highly skewed and non-stationary item distributions common in streaming industry recommenders, leading to poor assignment accuracy, imbalanced cluster occupancy, and insufficient cluster separation. To address these challenges, we propose MERGE, a next-generation item indexing paradigm that adaptively constructs clusters from scratch, dynamically monitors cluster occupancy, and forms hierarchical index structures via fine-to-coarse merging. Extensive experiments demonstrate that MERGE significantly improves assignment accuracy, cluster uniformity, and cluster separation compared with existing indexing methods, while online A/B tests show substantial gains in key business metrics, highlighting its potential as a foundational indexing approach for large-scale recommendation.",
        "entry_id": "http://arxiv.org/abs/2601.20199v1",
        "pub_date": "2026-01-28",
        "translated_summary": "项目索引（Item indexing）通过将庞大语料中的项目映射为紧致的离散表示，对判别式和生成式推荐系统都至关重要。然而，现有的基于矢量量化（Vector Quantization, VQ）的方法在面对流媒体行业推荐器中高倾斜、非平稳的项目分布时，往往存在指派不准、簇占用失衡及簇间区分不足等缺陷。为解决这些难题，我们提出下一代项目索引范式 MERGE：它能够从零开始自适应地构建簇，实时监测簇的占用情况，并通过从细到粗的顺序合并形成层次化索引结构。大量实验表明，与现有索引方法相比，MERGE 在指派精度、簇均匀度和簇分离度上均有显著提升；在线 A/B 测试更在关键业务指标上取得大幅增长，彰显了其作为大规模推荐基础索引方案的潜力。"
    },
    {
        "title": "Taxonomy of the Retrieval System Framework: Pitfalls and Paradigms",
        "summary": "Designing an embedding retrieval system requires navigating a complex design space of conflicting trade-offs between efficiency and effectiveness. This work structures these decisions as a vertical traversal of the system design stack. We begin with the Representation Layer by examining how loss functions and architectures, specifically Bi-encoders and Cross-encoders, define semantic relevance and geometric projection. Next, we analyze the Granularity Layer and evaluate how segmentation strategies like Atomic and Hierarchical chunking mitigate information bottlenecks in long-context documents. Moving to the Orchestration Layer, we discuss methods that transcend the single-vector paradigm, including hierarchical retrieval, agentic decomposition, and multi-stage reranking pipelines to resolve capacity limitations. Finally, we address the Robustness Layer by identifying architectural mitigations for domain generalization failures, lexical blind spots, and the silent degradation of retrieval quality due to temporal drift. By categorizing these limitations and design choices, we provide a comprehensive framework for practitioners to optimize the efficiency-effectiveness frontier in modern neural search systems.",
        "entry_id": "http://arxiv.org/abs/2601.20131v1",
        "pub_date": "2026-01-27",
        "translated_summary": "设计嵌入检索系统需要在效率与效果这对矛盾之间寻找平衡，设计空间纷繁复杂。本文将相关决策按系统栈自顶向下的顺序进行结构化梳理。首先，在表示层中，我们通过讨论损失函数与网络架构（特别是 Bi-encoder 和 Cross-encoder）如何定义语义相关性的同时，也塑造了其在向量空间的投影形式。其次，在粒度层探讨分段策略——原子级切分（Atomic）与层次化切分（Hierarchical）——如何缓解长文档中的信息瓶颈。随后，在编排层，我们超越了单向量范式，讨论层次化检索、受代理分解、多阶段重排流水线等方法，以突破容量限制。最后，在鲁棒性层，我们指出并给出架构层面的缓解方案，以应对领域泛化失败、词汇盲区以及因时间漂移而导致的检索质量静默退化。通过对这些限制因素与设计选择进行归类，本文为从业者提供了一个整体框架，以在现代神经搜索系统优化“效率–效果”边界。"
    },
    {
        "title": "Look in the Middle: Structural Anchor Pruning for Scalable Visual RAG Indexing",
        "summary": "Recent Vision-Language Models (e.g., ColPali) enable fine-grained Visual Document Retrieval (VDR) but incur prohibitive index vector size overheads. Training-free pruning solutions (e.g., EOS-attention based methods) can reduce index vector size by approximately 60% without model adaptation, but often underperform random selection in high-compression scenarios (> 80%). Prior research (e.g., Light-ColPali) attributes this to the conclusion that visual token importance is inherently query-dependent, thereby questioning the feasibility of training-free pruning. In this work, we propose Structural Anchor Pruning (SAP), a training-free pruning method that identifies key visual patches from middle layers to achieve high performance compression. We also introduce Oracle Score Retention (OSR) protocol to evaluate how layer-wise information affects compression efficiency. Evaluations on the ViDoRe benchmark demonstrate that SAP reduces index vectors by over 90% while maintaining robust retrieval fidelity, providing a highly scalable solution for Visual RAG. Furthermore, our OSR-based analysis reveals that semantic structural anchor patches persist in the middle layers, unlike traditional pruning solutions that focus on the final layer where structural signals dissipate.",
        "entry_id": "http://arxiv.org/abs/2601.20107v1",
        "pub_date": "2026-01-27",
        "translated_summary": "近期的视觉-语言模型（如 ColPali）虽已实现细粒度视觉文档检索（VDR），却带来难以承受的索引向量开销。无需训练的剪枝策略（如基于 EOS-注意力的方法）可将索引向量减少约 60%，且无需模型参数调整；然而在压缩率高于 80% 的极限场景下，其性能往往劣于随机选择。先有研究（如 Light-ColPali）将此归因于“视觉 token 的重要性本质上依赖查询”，从而质疑无训练剪枝的可行性。\n\n本工作提出结构锚点剪枝（SAP）——一种无需训练的剪枝方法，通过定位中间层的关键视觉块，在极高压缩率下仍保持优异检索质量。我们还引入 Oracle Score Retention（OSR）协议，以评估各层信息如何影响压缩效率。在 ViDoRe 基准上的实验表明，SAP 可将索引向量压缩超过 90%，同时保持检索精度，为视觉 RAG 提供极具扩展性的解决方案。此外，基于 OSR 的分析揭示：语义结构锚点视觉块持续存在于中间层，与传统剪枝方法聚焦的结构信号已退化的末层截然不同。"
    },
    {
        "title": "IMRNNs: An Efficient Method for Interpretable Dense Retrieval via Embedding Modulation",
        "summary": "Interpretability in black-box dense retrievers remains a central challenge in Retrieval-Augmented Generation (RAG). Understanding how queries and documents semantically interact is critical for diagnosing retrieval behavior and improving model design. However, existing dense retrievers rely on static embeddings for both queries and documents, which obscures this bidirectional relationship. Post-hoc approaches such as re-rankers are computationally expensive, add inference latency, and still fail to reveal the underlying semantic alignment. To address these limitations, we propose Interpretable Modular Retrieval Neural Networks (IMRNNs), a lightweight framework that augments any dense retriever with dynamic, bidirectional modulation at inference time. IMRNNs employ two independent adapters: one conditions document embeddings on the current query, while the other refines the query embedding using corpus-level feedback from initially retrieved documents. This iterative modulation process enables the model to adapt representations dynamically and expose interpretable semantic dependencies between queries and documents. Empirically, IMRNNs not only enhance interpretability but also improve retrieval effectiveness. Across seven benchmark datasets, applying our method to standard dense retrievers yields average gains of +6.35% nDCG, +7.14% recall, and +7.04% MRR over state-of-the-art baselines. These results demonstrate that incorporating interpretability-driven modulation can both explain and enhance retrieval in RAG systems.",
        "entry_id": "http://arxiv.org/abs/2601.20084v1",
        "pub_date": "2026-01-27",
        "translated_summary": "可解释的黑盒稠密检索器仍是检索增强生成（RAG）中的核心难题。要诊断检索行为并改进模型设计，就必须理解查询与文档之间的语义交互方式。然而，现有稠密检索器依赖静态嵌入分别表示查询和文档，掩盖了二者之间的双向关系。诸如重排序器这类事后解释方法则计算代价高昂，延迟推理时间，却仍无法揭示底层的语义对齐。\n\n为克服上述局限，本文提出可解释模块式检索神经网络（IMRNNs），一种轻量级框架，可在推理阶段为任意稠密检索器加入动态、双向的调制机制。IMRNNs 采用两个独立适配器：其一以当前查询为条件调整文档嵌入；其二利用初步检索到的文档在语料层面的反馈精炼查询嵌入。通过这一迭代调制过程，模型可动态调整表示并显式地呈现查询与文档之间的可解释语义依赖。\n\n实验表明，IMRNNs 不仅提升了解释性，也增强了检索效果。在七个基准数据集上，将本方法应用于标准稠密检索器，可在 nDCG、召回率和 MRR 上较最优基线分别平均提升 6.35%、7.14% 和 7.04%。这些结果说明，受可解释性驱动的调制机制能够同时解释并提升 RAG 系统中的检索性能。"
    },
    {
        "title": "LLaTTE: Scaling Laws for Multi-Stage Sequence Modeling in Large-Scale Ads Recommendation",
        "summary": "We present LLaTTE (LLM-Style Latent Transformers for Temporal Events), a scalable transformer architecture for production ads recommendation. Through systematic experiments, we demonstrate that sequence modeling in recommendation systems follows predictable power-law scaling similar to LLMs. Crucially, we find that semantic features bend the scaling curve: they are a prerequisite for scaling, enabling the model to effectively utilize the capacity of deeper and longer architectures. To realize the benefits of continued scaling under strict latency constraints, we introduce a two-stage architecture that offloads the heavy computation of large, long-context models to an asynchronous upstream user model. We demonstrate that upstream improvements transfer predictably to downstream ranking tasks. Deployed as the largest user model at Meta, this multi-stage framework drives a 4.3\\% conversion uplift on Facebook Feed and Reels with minimal serving overhead, establishing a practical blueprint for harnessing scaling laws in industrial recommender systems.",
        "entry_id": "http://arxiv.org/abs/2601.20083v1",
        "pub_date": "2026-01-27",
        "translated_summary": "我们提出 LLaTTE（用于时序事件的 LLM 风格隐层 Transformer），这是一种可扩展的 Transformer 架构，专为生产环境广告推荐而设计。通过系统实验，我们证明推荐系统中的序列建模遵循与 LLM 相似的幂律缩放规律。关键发现是，**语义特征能够“弯曲”缩放曲线**：它们不仅是规模化的前置条件，更使模型可以有效地利用更深、更长的架构所带来的容量优势。为了在严格延迟约束下持续享受规模化带来的益处，我们设计了两阶段架构，将大型长上下文本模型的重计算部分**异步卸载**到上游的用户模型。实验显示，上游改进可以可预测地迁移到下游排序任务。该多级框架已作为 Meta 最大的用户模型上线，在 Facebook Feed 与 Reels 上带来 **4.3% 的转化提升**，且几乎不增加在线服务开销，为工业级推荐系统如何实践利用扩展规律树立了可行范本。"
    },
    {
        "title": "When Iterative RAG Beats Ideal Evidence: A Diagnostic Study in Scientific Multi-hop Question Answering",
        "summary": "Retrieval-Augmented Generation (RAG) extends large language models (LLMs) beyond parametric knowledge, yet it is unclear when iterative retrieval-reasoning loops meaningfully outperform static RAG, particularly in scientific domains with multi-hop reasoning, sparse domain knowledge, and heterogeneous evidence. We provide the first controlled, mechanism-level diagnostic study of whether synchronized iterative retrieval and reasoning can surpass an idealized static upper bound (Gold Context) RAG. We benchmark eleven state-of-the-art LLMs under three regimes: (i) No Context, measuring reliance on parametric memory; (ii) Gold Context, where all oracle evidence is supplied at once; and (iii) Iterative RAG, a training-free controller that alternates retrieval, hypothesis refinement, and evidence-aware stopping. Using the chemistry-focused ChemKGMultiHopQA dataset, we isolate questions requiring genuine retrieval and analyze behavior with diagnostics spanning retrieval coverage gaps, anchor-carry drop, query quality, composition fidelity, and control calibration. Across models, Iterative RAG consistently outperforms Gold Context, with gains up to 25.6 percentage points, especially for non-reasoning fine-tuned models. Staged retrieval reduces late-hop failures, mitigates context overload, and enables dynamic correction of early hypothesis drift, but remaining failure modes include incomplete hop coverage, distractor latch trajectories, early stopping miscalibration, and high composition failure rates even with perfect retrieval. Overall, staged retrieval is often more influential than the mere presence of ideal evidence; we provide practical guidance for deploying and diagnosing RAG systems in specialized scientific settings and a foundation for more reliable, controllable iterative retrieval-reasoning frameworks.",
        "entry_id": "http://arxiv.org/abs/2601.19827v1",
        "pub_date": "2026-01-27",
        "translated_summary": "检索增强生成（RAG）使大语言模型（LLM）突破了参数知识的局限，但在多跳推理、领域知识稀疏且证据异质的科学领域中，何时使用迭代检索-推理循环才能明显优于静态 RAG，仍缺乏明确结论。我们通过首次受控的、机制层面对比实验，检验同步迭代检索与推理能否超越“理想化静态上限”（Gold Context）RAG。我们在三种设置下对 11 个前沿 LLM 进行基准测试：（i）无上下文，仅依赖参数记忆；（ii）Gold Context，一次性提供全部 oracle 证据；（iii）迭代 RAG，采用无需训练的控制器，按检索 ↔ 假设精炼 ↔ 证据感知式停止的顺序交替进行。利用聚焦化学领域的 ChemKGMultiHopQA 数据集，我们抽取真正需要外部检索的问题，并通过覆盖缺口、锚点传递失效（anchor-carry drop）、查询质量、组合保真度和控制校准等多项诊断工具分析模型行为。\n\n跨模型结果表明，迭代 RAG 普遍超越 Gold Context，最高带来 25.6 个百分点的提升，尤其是在未经推理专门微调的模型中更明显。分阶段式检索减轻了后期跳数失败，缓解了上下文超载，并能动态修正早期假设漂移。然而，残留失败模式包括跳数覆盖不完整、干扰锚轨迹（distractor latch）卡住、提前停止失准，以及即使检索全部正确时的组合失败率仍较高。总体而言，分阶段检索往往比“理想证据一次性提供”本身更具决定性。我们针对专业科学场景，给出了部署与诊断 RAG 系统的实操指南，并为构建更可靠、可控的迭代检索-推理框架奠定了方法论基础。"
    },
    {
        "title": "An Interpretable Recommendation Model for Psychometric Data, With an Application to Gerontological Primary Care",
        "summary": "There are challenges that must be overcome to make recommender systems useful in healthcare settings. The reasons are varied: the lack of publicly available clinical data, the difficulty that users may have in understanding the reasons why a recommendation was made, the risks that may be involved in following that recommendation, and the uncertainty about its effectiveness. In this work, we address these challenges with a recommendation model that leverages the structure of psychometric data to provide visual explanations that are faithful to the model and interpretable by care professionals. We focus on a narrow healthcare niche, gerontological primary care, to show that the proposed recommendation model can assist the attending professional in the creation of personalised care plans. We report results of a comparative offline performance evaluation of the proposed model on healthcare datasets that were collected by research partners in Brazil, as well as the results of a user study that evaluates the interpretability of the visual explanations the model generates. The results suggest that the proposed model can advance the application of recommender systems in this healthcare niche, which is expected to grow in demand , opportunities, and information technology needs as demographic changes become more pronounced.",
        "entry_id": "http://arxiv.org/abs/2601.19824v1",
        "pub_date": "2026-01-27",
        "translated_summary": "要在医疗场景中有效应用推荐系统，必须克服一系列挑战：临床数据缺乏公开获取途径，用户难以理解推荐依据，执行推荐可能带来的风险，以及对其疗效的不确定性。为此，本文提出的推荐模型利用心理测评数据的内在结构，生成忠实于模型且易于医护人员解读的可视化解释。我们以极为细分的老年基层医疗领域为切口，验证了该模型如何辅助临床医生制定个性化照护计划。\n\n我们使用由巴西合作研究团队收集的医疗数据集，对新模型进行了离线性能对比评估；同时通过用户实验检验其可视化解释的可读性。结果表明，该模型能够有效推动推荐系统在老年基层医疗——这一因人口结构快速演变而在需求、机遇和信息技术需求方面持续增长的专业领域——的实际落地应用。"
    },
    {
        "title": "Reimagining Social Robots as Recommender Systems: Foundations, Framework, and Applications",
        "summary": "Personalization in social robots refers to the ability of the robot to meet the needs and/or preferences of an individual user. Existing approaches typically rely on large language models (LLMs) to generate context-aware responses based on user metadata and historical interactions or on adaptive methods such as reinforcement learning (RL) to learn from users' immediate reactions in real time. However, these approaches fall short of comprehensively capturing user preferences-including long-term, short-term, and fine-grained aspects-, and of using them to rank and select actions, proactively personalize interactions, and ensure ethically responsible adaptations. To address the limitations, we propose drawing on recommender systems (RSs), which specialize in modeling user preferences and providing personalized recommendations. To ensure the integration of RS techniques is well-grounded and seamless throughout the social robot pipeline, we (i) align the paradigms underlying social robots and RSs, (ii) identify key techniques that can enhance personalization in social robots, and (iii) design them as modular, plug-and-play components. This work not only establishes a framework for integrating RS techniques into social robots but also opens a pathway for deep collaboration between the RS and HRI communities, accelerating innovation in both fields.",
        "entry_id": "http://arxiv.org/abs/2601.19761v1",
        "pub_date": "2026-01-27",
        "translated_summary": "社交机器人的个性化，指的是机器人满足单个用户需求与/或偏好的能力。现有方案通常依赖大语言模型（LLM）根据用户元数据与历史交互生成情境感知回复，或借助强化学习（RL）等自适应方法，基于用户的实时反馈在线学习。然而，这些方法难以全面捕捉用户偏好（包括长期、短期及细粒度层面），也难以据此对行为进行排序和选择，也无法主动实现交互的个性化与确保符合伦理的自适应。为此，本文借鉴专注于建模用户偏好并提供个性化推荐的推荐系统（RS）。为确保 RS 技术在整个社交机器人流程中切实落地、无缝集成，我们（i）对齐社会机器人与推荐系统的范式，（ii）锁定可强化机器人个性化的关键技术，并以模块化、即插即用的形式进行设计。这不仅为社会机器人引入推荐系统建立了框架，也开启了 RS 与 HRI（人机交互）领域的深度合作之路，从而加速两大领域的创新。"
    },
    {
        "title": "Benchmarking Multimodal Large Language Models for Missing Modality Completion in Product Catalogues",
        "summary": "Missing-modality information on e-commerce platforms, such as absent product images or textual descriptions, often arises from annotation errors or incomplete metadata, impairing both product presentation and downstream applications such as recommendation systems. Motivated by the multimodal generative capabilities of recent Multimodal Large Language Models (MLLMs), this work investigates a fundamental yet underexplored question: can MLLMs generate missing modalities for products in e-commerce scenarios? We propose the Missing Modality Product Completion Benchmark (MMPCBench), which consists of two sub-benchmarks: a Content Quality Completion Benchmark and a Recommendation Benchmark.\n  We further evaluate six state-of-the-art MLLMs from the Qwen2.5-VL and Gemma-3 model families across nine real-world e-commerce categories, focusing on image-to-text and text-to-image completion tasks. Experimental results show that while MLLMs can capture high-level semantics, they struggle with fine-grained word-level and pixel- or patch-level alignment. In addition, performance varies substantially across product categories and model scales, and we observe no trivial correlation between model size and performance, in contrast to trends commonly reported in mainstream benchmarks. We also explore Group Relative Policy Optimization (GRPO) to better align MLLMs with this task. GRPO improves image-to-text completion but does not yield gains for text-to-image completion. Overall, these findings expose the limitations of current MLLMs in real-world cross-modal generation and represent an early step toward more effective missing-modality product completion.",
        "entry_id": "http://arxiv.org/abs/2601.19750v2",
        "pub_date": "2026-01-27",
        "translated_summary": "电商场景中，诸如商品图片或文字描述缺失的模态缺失问题，往往源于标注错误或元数据不全，既影响商品呈现，也损害推荐系统等下游应用。受近期多模态大语言模型（MLLM）生成能力的启发，本研究探讨了一个基础却鲜有人触及的问题：MLLM能否在电商情境下为商品补全缺失的模态？我们提出缺失模态商品补全基准（MMPCBench），下设两个子基准：内容质量补全基准与推荐效果基准。\n\n我们在九个真实商品类别上，针对图文和文图双向补全任务，对来自 Qwen2.5-VL 与 Gemma-3 家族的六种前沿 MLLM 进行了系统评测。实验表明，这些模型虽能捕捉高层语义，却在细粒度的词级对齐以及像素/子块级对齐上力不从心。此外，性能在不同商品类别与模型规模间差异显著，且与模型大小并无单调正相关，这与主流基准普遍观察到的趋势相左。我们还探索了 Group Relative Policy Optimization（GRPO）以提升任务适配度：GRPO 在文生图补全有所提升，却对图生文补全无增益。整体而言，这些发现揭示了当前 MLLM 在真实跨模态补全中的局限，并为更有效的商品缺失模态补全迈出了早期一步。"
    }
]